[{"uri":"https://thienluhoan.github.io/workshop-template/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":"SportsCapital launches real-time event detection for sports trading powered by AWS By: James Lockwood and Asim Jalis | Date: 03 JUN 2025\nCategories: Amazon Bedrock, Amazon EC2, Amazon Machine Learning, Amazon RDS, Amazon SageMaker, Amazon Transcribe, Artificial Intelligence, AWS Lambda, Betting and Gaming, Compute, Database, Games, Industries, RDS for PostgreSQL\nThis blog was coauthored by Aaron Riccio, Co-Founder and CEO of SportsCapital, and Pravin Santhanam, CTO of SportsCapital.\nThe Challenge in Sports Trading Sportsbooks rely on trading teams to manage odds and prevent sharp bettors from exploiting inefficiencies in their pricing. News events, such as reports of player injuries or lineup changes, introduce volatility that can shift the market at any moment and require traders to make adjustments in real time. Any delay in this process can expose sportsbooks to millions in liabilities.\nHowever, with live news and reporting inherently unstructured, efficiently detecting and programmatically using these events in a real-time environment isn\u0026rsquo;t simple. The challenge is further compounded by the sheer volume of reporting that stems from thousands of local and national sources across all major leagues and college athletics.\nSportsCapital\u0026rsquo;s Solution SportsCapital\u0026rsquo;s event detection system, built on top of Amazon Web Services (AWS) such as Amazon SageMaker and Amazon Bedrock, delivers an innovative solution. It uses cloud-based data processing pipelines and generative AI to turn real-time content into structured feeds for pricing models and trading applications. Top sportsbooks use the technology for real-time injury alerting and, more recently, it\u0026rsquo;s been leveraged to build automated trading systems.\n\u0026ldquo;Our alerts allow traders to be among the first to know about an injury event before the rest of the market reacts. We\u0026rsquo;re now starting to see more investment from sportsbooks into trading automation, but it\u0026rsquo;s only viable if you can effectively use these news reports to dynamically adjust your pricing and projections.\u0026rdquo;\n‚Äî Aaron Riccio, CEO of SportsCapital\nThe Cloud Advantage SportsCapital\u0026rsquo;s cloud-powered infrastructure enables real-time data processing for short and longform content online. It transforms live news from a broad range of media formats into enriched metadata, such as news classification, linked entities, and relevancy.\n\u0026ldquo;Managed services from AWS are central to our architecture, providing the scalability and reliability needed to process thousands of news items each day while maintaining strict latency requirements. They provide an efficient solution to deliver our real-time services to clients.\u0026rdquo;\n‚Äî Pravin Santhanam, CTO of SportsCapital\nImage 1: Real-time event detection in SportsCapital‚Äôs system built on AWS.\nSystem Architecture Using Amazon Elastic Cloud Compute (Amazon EC2) instances, SportsCapital\u0026rsquo;s event detection system pipeline continuously monitors sources to detect relevant events. New data is stored in its database infrastructure through the MongoDB Atlas cloud developer data platform on Amazon EC2 and managed with Amazon Relational Database Service (Amazon RDS) for PostgreSQL.\nAs new reports enter the system, database triggers initiate serverless processing through AWS Lambda. Lambda functions perform text clean up and entity linking, such as identifying the player, team, staff, or agent mentioned in the text.\nAmazon SageMaker hosts machine learning (ML) models trained by SportsCapital to perform these enrichment tasks, allowing them to scale processing based on demand. Content triggers match algorithms that route relevant information to the appropriate destinations based on any custom filtering.\nThe current latency, or time-to-availability, from when a report is published to when it is fully processed averages about seven seconds.\nProcessing Longform Content Longer form content requires additional processing, for which SportsCapital depends on large language models (LLMs) in Amazon Bedrock. These LLMs parse the content into multiple snippets with independent pieces of information. The pipeline also converts audio to text using speech-to-text technology from Amazon Transcribe. This segmentation allows them to maintain the same downstream processing pipeline regardless of the source.\nThe Underlying AI Infrastructure Maintaining a competitive edge with AI requires the ability to rapidly innovate without infrastructure getting in the way. AWS helps reduce the need for custom infrastructure development at SportsCapital. At the same time, it provides the flexibility and low latency requirements needed to meet the company\u0026rsquo;s real-time data processing needs.\n\u0026ldquo;With Amazon SageMaker, we can bring in our own container images to implement custom inference pipelines. Comprehensive logging capabilities also provide critical visibility into system performance, helping us quickly identify and resolve any issues. Plus, the provisioned concurrency feature in Amazon SageMaker reduces our processing latency, which is huge in a business where every second counts.\u0026rdquo;\n‚Äî Pravin Santhanam, CTO of SportsCapital\nUsing Amazon Bedrock SportsCapital is also using Amazon Bedrock to experiment with foundation models, including LLMs like Anthropic\u0026rsquo;s Claude Sonnet 3.5. The generative AI service provides the team with a unified API that makes foundation model integration more seamless. Built-in logging capabilities allow SportsCapital\u0026rsquo;s team to create a consistent operational experience across its ML stack.\nClaude Sonnet 3.5 also plays a key role in enabling the pipeline to summarize longform content. SportsCapital built a training dataset to quantify the performance of this task and will continue to test new ones to improve evaluation metrics.\n\u0026ldquo;Amazon Bedrock handles complex deployment infrastructure for LLMs in an invaluable way. We can incorporate advanced natural language processing [NLP] capabilities into our real-time workflows without worrying about the underlying infrastructure. This will remain crucial as our needs change, and we\u0026rsquo;re excited about the potential to fine-tune custom LLMs through Amazon Bedrock as our pipeline evolves.\u0026rdquo;\n‚Äî Pravin Santhanam, CTO of SportsCapital\nNext Steps In the future, SportsCapital plans to scale the number of short- and long-form sources it ingests across a full calendar year of sports.\n\u0026ldquo;Our team is focused on scaling ingestion across thousands of sources throughout the year and processing breaking news with a level of precision and speed this industry hasn\u0026rsquo;t seen before.\u0026rdquo;\n‚Äî Aaron Riccio, CEO of SportsCapital\nStay up to date with SportsCapital\u0026rsquo;s latest developments, and reach out to an AWS representative to find out how generative AI services like Amazon SageMaker and Amazon Bedrock can enhance your AI projects.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":" ‚ö†Ô∏è Note: The information below is for reference purposes only. Please do not copy verbatim for your report, including this warning.\nGetting Started with Healthcare Data Lakes: Using Microservices Data lakes can help hospitals and healthcare facilities turn data into business insights, maintain business continuity, and protect patient privacy. A data lake is a centralized, managed, and secure repository to store all your data, both in its raw and processed forms for analysis. Data lakes allow you to break down data silos and combine different types of analytics to gain insights and make better business decisions.\nThis blog post is part of a larger series on getting started with setting up a healthcare data lake. In my final post of the series, ‚ÄúGetting Started with Healthcare Data Lakes: Diving into Amazon Cognito‚Äù, I focused on the specifics of using Amazon Cognito and Attribute Based Access Control (ABAC) to authenticate and authorize users in the healthcare data lake solution. In this blog, I detail how the solution evolved at a foundational level, including the design decisions I made and the additional features used. You can access the code samples for the solution in this Git repo for reference.\nArchitecture Guidance The main change since the last presentation of the overall architecture is the decomposition of a single service into a set of smaller services to improve maintainability and flexibility. Integrating a large volume of diverse healthcare data often requires specialized connectors for each format; by keeping them encapsulated separately as microservices, we can add, remove, and modify each connector without affecting the others. The microservices are loosely coupled via publish/subscribe messaging centered in what I call the ‚Äúpub/sub hub.‚Äù\nThis solution represents what I would consider another reasonable sprint iteration from my last post. The scope is still limited to the ingestion and basic parsing of HL7v2 messages formatted in Encoding Rules 7 (ER7) through a REST interface.\nThe solution architecture is now as follows:\nFigure 1. Overall architecture; colored boxes represent distinct services.\nWhile the term microservices has some inherent ambiguity, certain traits are common:\nSmall, autonomous, loosely coupled Reusable, communicating through well-defined interfaces Specialized to do one thing well Often implemented in an event-driven architecture When determining where to draw boundaries between microservices, consider:\nIntrinsic: technology used, performance, reliability, scalability Extrinsic: dependent functionality, rate of change, reusability Human: team ownership, managing cognitive load Technology Choices and Communication Scope Communication scope Technologies / patterns to consider Within a single microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Between microservices in a single service AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Between services Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The Pub/Sub Hub Using a hub-and-spoke architecture (or message broker) works well with a small number of tightly related microservices.\nEach microservice depends only on the hub Inter-microservice connections are limited to the contents of the published message Reduces the number of synchronous calls since pub/sub is a one-way asynchronous push Drawback: coordination and monitoring are needed to avoid microservices processing the wrong message.\nCore Microservice Provides foundational data and communication layer, including:\nAmazon S3 bucket for data Amazon DynamoDB for data catalog AWS Lambda to write messages into the data lake and catalog Amazon SNS topic as the hub Amazon S3 bucket for artifacts such as Lambda code Only allow indirect write access to the data lake through a Lambda function ‚Üí ensures consistency.\nFront Door Microservice Provides an API Gateway for external REST interaction Authentication \u0026amp; authorization based on OIDC via Amazon Cognito Self-managed deduplication mechanism using DynamoDB instead of SNS FIFO because: SNS deduplication TTL is only 5 minutes SNS FIFO requires SQS FIFO Ability to proactively notify the sender that the message is a duplicate Staging ER7 Microservice Lambda ‚Äútrigger‚Äù subscribed to the pub/sub hub, filtering messages by attribute Step Functions Express Workflow to convert ER7 ‚Üí JSON Two Lambdas: Fix ER7 formatting (newline, carriage return) Parsing logic Result or error is pushed back into the pub/sub hub New Features in the Solution 1. AWS CloudFormation Cross-Stack References Example outputs in the core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "},{"uri":"https://thienluhoan.github.io/workshop-template/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":" ‚ö†Ô∏è Note: The information below is for reference purposes only. Please do not copy verbatim for your report, including this warning.\nGetting Started with Healthcare Data Lakes: Using Microservices Data lakes can help hospitals and healthcare facilities turn data into business insights, maintain business continuity, and protect patient privacy. A data lake is a centralized, managed, and secure repository to store all your data, both in its raw and processed forms for analysis. Data lakes allow you to break down data silos and combine different types of analytics to gain insights and make better business decisions.\nThis blog post is part of a larger series on getting started with setting up a healthcare data lake. In my final post of the series, ‚ÄúGetting Started with Healthcare Data Lakes: Diving into Amazon Cognito‚Äù, I focused on the specifics of using Amazon Cognito and Attribute Based Access Control (ABAC) to authenticate and authorize users in the healthcare data lake solution. In this blog, I detail how the solution evolved at a foundational level, including the design decisions I made and the additional features used. You can access the code samples for the solution in this Git repo for reference.\nArchitecture Guidance The main change since the last presentation of the overall architecture is the decomposition of a single service into a set of smaller services to improve maintainability and flexibility. Integrating a large volume of diverse healthcare data often requires specialized connectors for each format; by keeping them encapsulated separately as microservices, we can add, remove, and modify each connector without affecting the others. The microservices are loosely coupled via publish/subscribe messaging centered in what I call the ‚Äúpub/sub hub.‚Äù\nThis solution represents what I would consider another reasonable sprint iteration from my last post. The scope is still limited to the ingestion and basic parsing of HL7v2 messages formatted in Encoding Rules 7 (ER7) through a REST interface.\nThe solution architecture is now as follows:\nFigure 1. Overall architecture; colored boxes represent distinct services.\nWhile the term microservices has some inherent ambiguity, certain traits are common:\nSmall, autonomous, loosely coupled Reusable, communicating through well-defined interfaces Specialized to do one thing well Often implemented in an event-driven architecture When determining where to draw boundaries between microservices, consider:\nIntrinsic: technology used, performance, reliability, scalability Extrinsic: dependent functionality, rate of change, reusability Human: team ownership, managing cognitive load Technology Choices and Communication Scope Communication scope Technologies / patterns to consider Within a single microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Between microservices in a single service AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Between services Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The Pub/Sub Hub Using a hub-and-spoke architecture (or message broker) works well with a small number of tightly related microservices.\nEach microservice depends only on the hub Inter-microservice connections are limited to the contents of the published message Reduces the number of synchronous calls since pub/sub is a one-way asynchronous push Drawback: coordination and monitoring are needed to avoid microservices processing the wrong message.\nCore Microservice Provides foundational data and communication layer, including:\nAmazon S3 bucket for data Amazon DynamoDB for data catalog AWS Lambda to write messages into the data lake and catalog Amazon SNS topic as the hub Amazon S3 bucket for artifacts such as Lambda code Only allow indirect write access to the data lake through a Lambda function ‚Üí ensures consistency.\nFront Door Microservice Provides an API Gateway for external REST interaction Authentication \u0026amp; authorization based on OIDC via Amazon Cognito Self-managed deduplication mechanism using DynamoDB instead of SNS FIFO because: SNS deduplication TTL is only 5 minutes SNS FIFO requires SQS FIFO Ability to proactively notify the sender that the message is a duplicate Staging ER7 Microservice Lambda ‚Äútrigger‚Äù subscribed to the pub/sub hub, filtering messages by attribute Step Functions Express Workflow to convert ER7 ‚Üí JSON Two Lambdas: Fix ER7 formatting (newline, carriage return) Parsing logic Result or error is pushed back into the pub/sub hub New Features in the Solution 1. AWS CloudFormation Cross-Stack References Example outputs in the core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "},{"uri":"https://thienluhoan.github.io/workshop-template/4-eventparticipated/4.1-event1/","title":"Event 1","tags":[],"description":"","content":" ‚ö†Ô∏è Note: The information below is for reference purposes only. Please do not copy it verbatim into your report, including this warning.\nSummary Report: ‚ÄúGenAI-powered App-DB Modernization workshop‚Äù Event Objectives Share best practices in modern application design Introduce Domain-Driven Design (DDD) and event-driven architecture Provide guidance on selecting the right compute services Present AI tools to support the development lifecycle Speakers Jignesh Shah ‚Äì Director, Open Source Databases Erica Liu ‚Äì Sr. GTM Specialist, AppMod Fabrianne Effendi ‚Äì Assc. Specialist SA, Serverless Amazon Web Services Key Highlights Identifying the drawbacks of legacy application architecture Long product release cycles ‚Üí Lost revenue/missed opportunities Inefficient operations ‚Üí Reduced productivity, higher costs Non-compliance with security regulations ‚Üí Security breaches, loss of reputation Transitioning to modern application architecture ‚Äì Microservices Migrating to a modular system ‚Äî each function is an independent service communicating via events, built on three core pillars:\nQueue Management: Handle asynchronous tasks Caching Strategy: Optimize performance Message Handling: Flexible inter-service communication Domain-Driven Design (DDD) Four-step method: Identify domain events ‚Üí arrange timeline ‚Üí identify actors ‚Üí define bounded contexts Bookstore case study: Demonstrates real-world DDD application Context mapping: 7 patterns for integrating bounded contexts Event-Driven Architecture 3 integration patterns: Publish/Subscribe, Point-to-point, Streaming Benefits: Loose coupling, scalability, resilience Sync vs async comparison: Understanding the trade-offs Compute Evolution Shared Responsibility Model: EC2 ‚Üí ECS ‚Üí Fargate ‚Üí Lambda Serverless benefits: No server management, auto-scaling, pay-for-value Functions vs Containers: Criteria for appropriate choice Amazon Q Developer SDLC automation: From planning to maintenance Code transformation: Java upgrade, .NET modernization AWS Transform agents: VMware, Mainframe, .NET migration Key Takeaways Design Mindset Business-first approach: Always start from the business domain, not the technology Ubiquitous language: Importance of a shared vocabulary between business and tech teams Bounded contexts: Identifying and managing complexity in large systems Technical Architecture Event storming technique: Practical method for modeling business processes Use event-driven communication instead of synchronous calls Integration patterns: When to use sync, async, pub/sub, streaming Compute spectrum: Criteria for choosing between VM, containers, and serverless Modernization Strategy Phased approach: No rushing ‚Äî follow a clear roadmap 7Rs framework: Multiple modernization paths depending on the application ROI measurement: Cost reduction + business agility Applying to Work Apply DDD to current projects: Event storming sessions with business teams Refactor microservices: Use bounded contexts to define service boundaries Implement event-driven patterns: Replace some sync calls with async messaging Adopt serverless: Pilot AWS Lambda for suitable use cases Try Amazon Q Developer: Integrate into the dev workflow to boost productivity Event Experience Attending the ‚ÄúGenAI-powered App-DB Modernization‚Äù workshop was extremely valuable, giving me a comprehensive view of modernizing applications and databases using advanced methods and tools. Key experiences included:\nLearning from highly skilled speakers Experts from AWS and major tech organizations shared best practices in modern application design. Through real-world case studies, I gained a deeper understanding of applying DDD and Event-Driven Architecture to large projects. Hands-on technical exposure Participating in event storming sessions helped me visualize how to model business processes into domain events. Learned how to split microservices and define bounded contexts to manage large-system complexity. Understood trade-offs between synchronous and asynchronous communication and integration patterns like pub/sub, point-to-point, streaming. Leveraging modern tools Explored Amazon Q Developer, an AI tool for SDLC support from planning to maintenance. Learned to automate code transformation and pilot serverless with AWS Lambda to improve productivity. Networking and discussions The workshop offered opportunities to exchange ideas with experts, peers, and business teams, enhancing the ubiquitous language between business and tech. Real-world examples reinforced the importance of the business-first approach rather than focusing solely on technology. Lessons learned Applying DDD and event-driven patterns reduces coupling while improving scalability and resilience. Modernization requires a phased approach with ROI measurement; rushing the process can be risky. AI tools like Amazon Q Developer can significantly boost productivity when integrated into the current workflow. Some event photos Add your event photos here\nOverall, the event not only provided technical knowledge but also helped me reshape my thinking about application design, system modernization, and cross-team collaboration.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/4-eventparticipated/4.2-event2/","title":"Event 2","tags":[],"description":"","content":" ‚ö†Ô∏è Note: The information below is for reference purposes only. Please do not copy it verbatim into your report, including this warning.\nSummary Report: ‚ÄúGenAI-powered App-DB Modernization workshop‚Äù Event Objectives Share best practices in modern application design Introduce Domain-Driven Design (DDD) and event-driven architecture Provide guidance on selecting the right compute services Present AI tools to support the development lifecycle Speakers Jignesh Shah ‚Äì Director, Open Source Databases Erica Liu ‚Äì Sr. GTM Specialist, AppMod Fabrianne Effendi ‚Äì Assc. Specialist SA, Serverless Amazon Web Services Key Highlights Identifying the drawbacks of legacy application architecture Long product release cycles ‚Üí Lost revenue/missed opportunities Inefficient operations ‚Üí Reduced productivity, higher costs Non-compliance with security regulations ‚Üí Security breaches, loss of reputation Transitioning to modern application architecture ‚Äì Microservices Migrating to a modular system ‚Äî each function is an independent service communicating via events, built on three core pillars:\nQueue Management: Handle asynchronous tasks Caching Strategy: Optimize performance Message Handling: Flexible inter-service communication Domain-Driven Design (DDD) Four-step method: Identify domain events ‚Üí arrange timeline ‚Üí identify actors ‚Üí define bounded contexts Bookstore case study: Demonstrates real-world DDD application Context mapping: 7 patterns for integrating bounded contexts Event-Driven Architecture 3 integration patterns: Publish/Subscribe, Point-to-point, Streaming Benefits: Loose coupling, scalability, resilience Sync vs async comparison: Understanding the trade-offs Compute Evolution Shared Responsibility Model: EC2 ‚Üí ECS ‚Üí Fargate ‚Üí Lambda Serverless benefits: No server management, auto-scaling, pay-for-value Functions vs Containers: Criteria for appropriate choice Amazon Q Developer SDLC automation: From planning to maintenance Code transformation: Java upgrade, .NET modernization AWS Transform agents: VMware, Mainframe, .NET migration Key Takeaways Design Mindset Business-first approach: Always start from the business domain, not the technology Ubiquitous language: Importance of a shared vocabulary between business and tech teams Bounded contexts: Identifying and managing complexity in large systems Technical Architecture Event storming technique: Practical method for modeling business processes Use event-driven communication instead of synchronous calls Integration patterns: When to use sync, async, pub/sub, streaming Compute spectrum: Criteria for choosing between VM, containers, and serverless Modernization Strategy Phased approach: No rushing ‚Äî follow a clear roadmap 7Rs framework: Multiple modernization paths depending on the application ROI measurement: Cost reduction + business agility Applying to Work Apply DDD to current projects: Event storming sessions with business teams Refactor microservices: Use bounded contexts to define service boundaries Implement event-driven patterns: Replace some sync calls with async messaging Adopt serverless: Pilot AWS Lambda for suitable use cases Try Amazon Q Developer: Integrate into the dev workflow to boost productivity Event Experience Attending the ‚ÄúGenAI-powered App-DB Modernization‚Äù workshop was extremely valuable, giving me a comprehensive view of modernizing applications and databases using advanced methods and tools. Key experiences included:\nLearning from highly skilled speakers Experts from AWS and major tech organizations shared best practices in modern application design. Through real-world case studies, I gained a deeper understanding of applying DDD and Event-Driven Architecture to large projects. Hands-on technical exposure Participating in event storming sessions helped me visualize how to model business processes into domain events. Learned how to split microservices and define bounded contexts to manage large-system complexity. Understood trade-offs between synchronous and asynchronous communication and integration patterns like pub/sub, point-to-point, streaming. Leveraging modern tools Explored Amazon Q Developer, an AI tool for SDLC support from planning to maintenance. Learned to automate code transformation and pilot serverless with AWS Lambda to improve productivity. Networking and discussions The workshop offered opportunities to exchange ideas with experts, peers, and business teams, enhancing the ubiquitous language between business and tech. Real-world examples reinforced the importance of the business-first approach rather than focusing solely on technology. Lessons learned Applying DDD and event-driven patterns reduces coupling while improving scalability and resilience. Modernization requires a phased approach with ROI measurement; rushing the process can be risky. AI tools like Amazon Q Developer can significantly boost productivity when integrated into the current workflow. Some event photos Add your event photos here\nOverall, the event not only provided technical knowledge but also helped me reshape my thinking about application design, system modernization, and cross-team collaboration.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/","title":"Internship Report","tags":[],"description":"","content":"Internship Report Student Information: Full Name: Tran Minh Thien\nPhone Number: 0972935140\nEmail: thien.tm2727@gmail.com\nUniversity: FPT University Ho Chi Minh City Campus\nMajor: Information Technology\nClass:\nInternship Company:\nInternship Position:\nInternship Duration:\nReport Content Worklog Proposal Translated Blogs Events Participated Workshop Self-evaluation Sharing and Feedback "},{"uri":"https://thienluhoan.github.io/workshop-template/5-workshop/5.1-frontend-deployment/","title":"Part 1: Frontend Deployment with CloudFront, WAF, and S3","tags":[],"description":"","content":"Introduction Welcome to the first workshop in our serverless application series! In this hands-on session, you\u0026rsquo;ll learn how to deploy a secure, high-performance static website using AWS\u0026rsquo;s content delivery and storage services.\nModern web applications require fast, reliable, and secure content delivery to users worldwide. In this workshop, you\u0026rsquo;ll build the frontend infrastructure that forms the foundation of a production-ready serverless application. You\u0026rsquo;ll configure Amazon S3 to host your static website files, set up Amazon CloudFront to distribute your content globally with low latency, and implement AWS WAF (Web Application Firewall) to protect your application from common web exploits.\nWhat You\u0026rsquo;ll Build By the end of this workshop, you\u0026rsquo;ll have deployed a complete frontend infrastructure featuring:\nStatic Website Hosting: An S3 bucket configured to serve your HTML, CSS, and JavaScript files Global Content Delivery: A CloudFront distribution that caches and delivers your content from edge locations worldwide Security Layer: AWS WAF rules protecting your application from common threats like SQL injection, cross-site scripting (XSS), and DDoS attacks HTTPS Security: SSL/TLS certificate configuration for secure communication Custom Domain (Optional): Your website accessible via a custom domain name Why This Architecture? This architecture offers several key benefits:\nPerformance: CloudFront edge locations ensure fast load times for users regardless of their geographic location Scalability: Automatically handles traffic spikes without manual intervention Cost-Effective: Pay only for what you use, with no servers to manage Security: Multiple layers of protection including WAF, DDoS protection, and encryption Reliability: Built on AWS\u0026rsquo;s highly available infrastructure with 99.9% uptime SLA Workshop Structure This workshop is divided into the following sections:\nPart 1: S3 Static Website Hosting\nCreate and configure S3 bucket Upload website files Configure bucket for static website hosting Test basic website access Part 2: CloudFront Distribution Setup\nCreate CloudFront distribution Configure origin settings Set up cache behaviors Test global content delivery Part 3: AWS WAF Configuration\nCreate Web ACL Configure security rules Associate WAF with CloudFront Test security rules Part 4: Cleanup (Optional)\nRemove resources to avoid charges Save configuration for future use Workshop Duration Estimated Time: 2-3 hours\nSetup and preparation: 15 minutes S3 configuration: 30 minutes CloudFront setup: 45 minutes WAF implementation: 45 minutes Testing and validation: 30 minutes "},{"uri":"https://thienluhoan.github.io/workshop-template/5-workshop/5.1-frontend-deployment/5.1.1-prerequisite/","title":"Prerequisites","tags":[],"description":"","content":"Required AWS Knowledge AWS Console Navigation: Ability to navigate the AWS Management Console and find services Basic AWS Concepts: Understanding of AWS regions, availability zones, and basic service interactions No prior experience with S3, CloudFront, or WAF required - we\u0026rsquo;ll cover everything step by step Required Technical Skills Basic Web Development: Understanding of HTML, CSS, and JavaScript File System Operations: Ability to create, edit, and organize files and folders Command Line Basics: Comfortable running basic terminal/command prompt commands Text Editing: Familiarity with any code editor or IDE Required AWS Account Setup Before starting this workshop, ensure you have:\nAWS Account\nActive AWS account with administrative access Credit card on file (required even for Free Tier) MFA (Multi-Factor Authentication) enabled on root account (strongly recommended) IAM User (Recommended)\nIAM user with appropriate permissions instead of using root account Required permissions: AmazonS3FullAccess CloudFrontFullAccess WAFv2FullAccess AWSCertificateManagerFullAccess (if using custom domain) Access key and secret key generated (for CLI access) Billing Alerts\nSet up AWS Budgets or billing alerts to monitor costs Recommended: Set alert at $10 threshold Required Tools and Software Install the following tools on your local machine:\nText Editor or IDE\nVS Code (recommended): https://code.visualstudio.com/ Or any editor of your choice (Sublime Text, Atom, etc.) Web Browser\nModern browser (Chrome, Firefox, Safari, or Edge) Multiple tabs recommended for console navigation Git (Optional but recommended)\nDownload: https://git-scm.com/ Used for version control and sample code retrieval Sample Application We\u0026rsquo;ll provide a simple static website for this workshop.\nOptional: Custom Domain Setup If you want to use a custom domain (e.g., www.yoursite.com):\nDomain Name: Registered domain (can use Route 53 or external registrar) DNS Access: Ability to modify DNS records for your domain Note: This is optional; you can complete the workshop using CloudFront\u0026rsquo;s default domain Cost Expectations for Part 1: Frontend Deployment Free Tier Eligible Services:\nS3: 5GB storage, 20,000 GET requests, 2,000 PUT requests (first 12 months) CloudFront: 1TB data transfer out, 10,000,000 HTTP/HTTPS requests (first 12 months) AWS WAF: No Free Tier, but minimal cost for basic rules Estimated Costs (if exceeding Free Tier):\nS3 storage: $0.023 per GB per month CloudFront data transfer: $0.085 per GB (varies by region) WAF: $5.00 per month per web ACL + $1.00 per rule per month Total estimated cost for this workshop: $0-$2 (within Free Tier) or $5-$10 (with WAF) Cost Saving Tips:\nDelete resources immediately after workshop if not continuing Use small sample files to minimize storage and transfer costs Start with basic WAF rules and expand later Ready to Begin? Once you\u0026rsquo;ve completed all prerequisites and verified your setup, you\u0026rsquo;re ready to start building your secure, globally distributed frontend infrastructure!\nLet\u0026rsquo;s move on to Part 1: S3 Static Website Hosting.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/5-workshop/5.2-serverless-backend/5.2.1-prerequisite/","title":"Prerequisites","tags":[],"description":"","content":"Required AWS Knowledge Part 1: Frontend Deployment Completion: Understanding of AWS console navigation and basic services; Having a frontend application ready to connect HTTP/REST APIs: Knowledge of HTTP methods (GET, POST, PUT, DELETE) and REST principles Database Basics: Understanding of relational databases, tables, and SQL queries JSON: Familiarity with JSON format for API requests/responses Basic Networking: Understanding of concepts like VPC, subnets, and security groups IAM: Familiarity with IAM roles and policies. Apply best practice of least-privileges to resources Required Technical Skills Programming: Intermediate knowledge of either: Node.js (JavaScript/ TypeScript) - Recommended for this workshop SQL Queries: Basic SELECT, INSERT, UPDATE, DELETE statements API Testing: Using tools like Postman or curl Command Line: Comfortable with terminal commands Environment Variables: Understanding of configuration management Required AWS Account Setup Before starting this workshop, ensure you have:\nAWS Account\nActive AWS account with administrative access or permissions for: Lambda API Gateway RDS Cognito Secrets Manager VPC IAM CloudWatch Logs IAM User/Role Permissions\nRequired managed policies: AWSLambda_FullAccess AmazonAPIGatewayAdministrator AmazonRDSFullAccess AmazonCognitoPowerUser SecretsManagerReadWrite AmazonVPCFullAccess IAMFullAccess (for creating Lambda execution roles) CloudWatchLogsFullAccess Billing Alerts Configured\nSet up AWS Budgets or billing alerts Recommended threshold: $20-30 for this workshop RDS can incur higher costs than previous workshop Required Tools and Software Install the following tools on your local machine:\nAWS CLI (Version 2) (optional)\nDownload: https://aws.amazon.com/cli/ Verify installation: aws --version Ensure credentials are configured: aws configure Node.js and npm (if using Node.js for Lambda)\nDownload: https://nodejs.org/ (LTS version recommended) Minimum version: Node.js 18.x or higher Verify: node --version and npm --version Python (if using Python for Lambda)\nDownload: https://www.python.org/ Minimum version: Python 3.9 or higher Verify: python --version or python3 --version pip installed: pip --version Git\nDownload: https://git-scm.com/ Verify: git --version Text Editor or IDE\nVS Code (recommended): https://code.visualstudio.com/ Extensions recommended: AWS Toolkit ESLint (for JavaScript) Python (if using Python) API Testing Tool\nPostman (recommended): https://www.postman.com/downloads/ Or Insomnia: https://insomnia.rest/download Or curl (command line) Database Client (Optional but helpful)\nDBeaver (free, supports PostgreSQL): https://dbeaver.io/ Or pgAdmin: https://www.pgadmin.org/ Or psql command line tool Sample Application Code We\u0026rsquo;ll provide sample Lambda function code and SQL scripts:\nOption 1: Clone the workshop repository\ngit clone https://github.com/your-workshop/serverless-app-backend.git cd serverless-app-backend Option 2: Write code from scratch following the workshop\nWe\u0026rsquo;ll provide all code snippets in the tutorial Good for learning and understanding each component Optional: Completed Part 1: Frontend Deployment While not strictly required, having completed Part 1: Frontend Deployment provides context:\nYou\u0026rsquo;ll understand how the frontend will consume these APIs You\u0026rsquo;ll have a complete end-to-end application If you skipped Part 1: Frontend Deployment:\nYou can still complete this workshop independently We\u0026rsquo;ll test APIs using Postman instead of the frontend You can integrate with any frontend later Cost Expectations for Workshop 2 Estimated Costs for this Workshop:\nWithin Free Tier (first 12 months):\nRDS (single-AZ, limited hours): $0-5 Lambda: $0 API Gateway: $0 Cognito: $0 Secrets Manager: $0 (30-day trial) Total: $0-5 Pre-Workshop Checklist Before beginning, verify you have:\nAWS account with appropriate permissions AWS CLI installed and configured Node.js/Python installed (based on your preference) Git installed Code editor/IDE installed API testing tool installed (Postman recommended) Billing alerts configured at $20 Sample code repository cloned (or ready to write from scratch) At least 3-4 hours available for focused work Understanding of REST APIs and databases What You\u0026rsquo;ll Learn By completing this workshop, you will:\nDesign and implement serverless API architectures Create and configure Lambda functions with proper permissions Set up and secure RDS databases in VPC Implement API Gateway REST APIs with multiple endpoints Configure Cognito user pools and authentication flows Integrate Cognito authorizers with API Gateway Manage secrets securely with AWS Secrets Manager Restrict API Gateway access with Lambda functions and AWS Secrets Manager Connect Lambda functions to RDS databases Implement proper error handling and logging Test APIs with authentication tokens Ready to Begin? Once you\u0026rsquo;ve completed all prerequisites and verified your setup, you\u0026rsquo;re ready to start building your secure, scalable serverless backend infrastructure!\nExpected Outcomes By the end of this workshop, you\u0026rsquo;ll have:\nA fully functional REST API with multiple endpoints Secure user authentication and authorization Database-backed data persistence Professional logging and monitoring Production-ready security practices A backend that integrates with your Part 1: Frontend Deployment frontend (if completed) Next Step Let\u0026rsquo;s move on to Part 1: VPC and Network Setup to create the secure network foundation for your database and Lambda functions.\nLet\u0026rsquo;s build your serverless backend! üöÄ\n"},{"uri":"https://thienluhoan.github.io/workshop-template/1-worklog/1.1-week1/","title":"Week 1 Worklog","tags":[],"description":"","content":"Week 1 Objectives: Connect and get acquainted with members of First Cloud Journey. Understand basic AWS services, how to manage costs and budget. Understand access management practices on AWS Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Get acquainted with FCJ members, establish project group - Read and take note of internship unit rules and regulations 09/08/2025 09/08/2025 3 - Learn about AWS and its types of services 09/09/2025 09/10/2025 https://cloudjourney.awsstudygroup.com/ https://aws.amazon.com/ 4 - Learn about AWS and its types of services 09/09/2025 09/10/2025 https://cloudjourney.awsstudygroup.com/ https://aws.amazon.com/ 5 - Learn how to manage usage costs on AWS with AWS Budgets - Learn about access management with AWS IAM and AWS Identity Center Practice: - Create cost budget, usage budget, reservation budget and savings plans budget 09/11/2025 09/12/2025 https://000007.awsstudygroup.com/ https://docs.aws.amazon.com/cost-management/latest/userguide/what-is-costmanagement.html 6 Practice: - AWS IAM + Create an IAM user + Create policies + Create roles + Make an IAM user assume a role + Log in and test authorization with assumed role - IAM Identity Center + Create user group + Assign user to group + Create and attach permission set to group and account + Log in and test authorization 09/12/2025 09/14/2025 https://000002.awsstudygroup.com/ https://docs.aws.amazon.com/IAM/latest/UserGuide/introduction.html https://docs.aws.amazon.com/singlesignon/latest/userguide/what-is.html https://www.youtube.com/watch?v=gpquYmcpZpo https://www.youtube.com/watch?v=_KhrGFV_Npw\u0026t=659s Week 1 Achievements: Made new friends\nLearned about AWS services and explored different service categories.\nGained knowledge of cost management on AWS using AWS Budgets.\nCreated cost budgets Created usage budgets Created reservation budgets Created savings plans budgets Become more conscious about costs and budgets. Make habit of checking the docs for cost policies before using any of AWS services Learned and practiced AWS IAM:\nCreated IAM users Created and attached policies Created roles Made an IAM user assume a role Logged in and tested authorization with assumed roles Learned and practiced AWS Identity Center:\nCreated user groups Assigned users to groups Created and attached permission sets to groups and accounts Logged in and tested authorization with assigned permissions Studied the differences between AWS IAM and AWS IAM Identity Center:\nAWS IAM and AWS IAM Identity Center are two separate services for access management. AWS IAM focuses on managing individual users with their own set of credentials and permissions. AWS IAM Identity Center (formerly AWS SSO) provides centralized sign-in, allowing users to access multiple AWS accounts and roles with a single login. IAM Identity Center is generally preferred in organizational environments for easier user and access management. Strengthened understanding of access management and security in AWS through hands-on practice.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/1-worklog/1.2-week2/","title":"Week 2 Worklog","tags":[],"description":"","content":"Week 2 Objectives: Discuss with teammates on the first project. Explore and practice on AWS VPC, EC2 and S3. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Meet up with teamates to discuss about the first project 09/15/2025 09/15/2025 3 - Learn basic AWS networking + VPS + Subnet + Security groups + Gateways + Endpoints + Route tables 09/16/2025 09/16/2025 https://docs.aws.amazon.com/vpc/?icmpid=docs_homepage_networking https://www.youtube.com/watch?v=2doSoMN2xvI\u0026t=127s https://www.youtube.com/watch?v=7_NNlnH7sAg https://000003.awsstudygroup.com/ 4 - Learn basic EC2 + All about instances + Managing security groups + SSH methods to instance + Session manager + AMI + EBS Volume 09/17/2025 09/17/2025 https://docs.aws.amazon.com/ec2/?icmpid=docs_homepage_compute https://www.youtube.com/watch?v=-t148tYgnJU\u0026pp=ygUDZWMy https://www.youtube.com/watch?v=eaicwmnSdCs\u0026pp=ygUDZWMy https://000004.awsstudygroup.com/ 5 - Practice: + Create fully-functional VPC + Create working EC2 instance on top of created VPC + Explore methods to connect to EC2 instance + Reachability analyzer 09/18/2025 09/18/2025 https://www.youtube.com/watch?v=-t148tYgnJU\u0026pp=ygUDZWMy https://www.youtube.com/watch?v=eaicwmnSdCs\u0026pp=ygUDZWMy https://000004.awsstudygroup.com/ 6 - Learn basic S3 + Data storage + Static hosting + Bucket security practices 09/19/2025 09/20/2025 https://docs.aws.amazon.com/s3/?icmpid=docs_homepage_serverless https://000057.awsstudygroup.com/ Week 2 Achievements: Met with teammates and discussed the first project plan.\nDetermined the theme of project: a type racing game called TypeRush Created team Figma Debated on architecture and tech stack: microservices. Stack: React, Tailwind, Typescript, NodeJS, with Websocket for multiplayer Distributed initial task: I got designing game logic, setting up Websocket and build prototype Initialized Github repo Learned the basics of AWS Networking:\nUnderstood the role of VPC in isolating and securing resources. Set up and configured Subnets. Managed Security groups to control inbound and outbound traffic. Learned about Gateways, Endpoints, and Route tables and how they direct traffic inside and outside the VPC. Gained in-depth knowledge of Amazon EC2:\nUnderstood what EC2 instances are and explored different instance families (General Purpose, Compute Optimized, Memory Optimized, etc.) along with their use cases. Learned about instance types and how they differ in vCPU, RAM, and network performance. Understood cost models: On-Demand, Reserved Instances, and Spot Instances. Practiced managing security groups for controlling access. Explored different connection methods: Using SSH key pairs for secure login. Using Session Manager to access EC2 instances directly from the AWS Console without exposing SSH ports. Assigned Elastic IPs to maintain a static IP for an EC2 instance. Attached and managed EBS volumes to expand storage capacity. Learned the basics of AMIs (Amazon Machine Images) to launch new instances from existing images. Hands-on practice with networking and compute:\nCreated a fully-functional VPC. Launched and configured an EC2 instance within the VPC. Tested multiple connection methods to the EC2 instance. Used Reachability Analyzer to analyze and troubleshoot connectivity paths. Learned the fundamentals of Amazon S3:\nStored and managed data in S3 buckets. Practiced static website hosting with S3. Applied bucket security best practices to protect data. Strengthened knowledge of networking, compute, and storage on AWS through direct hands-on practice, building a solid foundation for real-world project work.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/1-worklog/1.3-week3/","title":"Week 3 Worklog","tags":[],"description":"","content":"Week 3 Objectives: Learn and practice intermediate AWS services. Gain hands-on experience with managed database, compute optimization, autoscaling, and monitoring. Start building the first project main game prototype Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Learn about Amazon RDS and supported engines (MySQL, PostgreSQL, etc.) - Practice: + Create RDS instance + Configure security groups + Connect via client + Create DB, insert data 09/22/2025 09/22/2025 https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Welcome.html https://www.youtube.com/watch?v=GvUaA9cygUk\u0026pp=ygUHYXdzIHJkcw%3D%3D https://www.youtube.com/watch?v=GvUaA9cygUk\u0026pp=ygUHYXdzIHJkcw%3D%3D https://000045.awsstudygroup.com/ 3 - Learn about Amazon Lightsail and how it differs from EC2 - Practice: + Launch Lightsail instance (Linux or WordPress) + Connect via SSH + Deploy static website + Explore pricing 09/23/2025 09/23/2025 https://lightsail.aws.amazon.com/ https://www.youtube.com/watch?v=COK3ko4np-0\u0026t=305s\u0026pp=ygUNYXdzIGxpZ2h0c2FpbA%3D%3D https://000045.awsstudygroup.com/ 4 - Learn about Amazon EC2 Autoscaling concepts (launch templates, scaling groups, policies) - Practice: + Create Launch Template + Create Auto Scaling Group + Configure scaling policy + Stress test and observe scaling 09/24/2025 09/24/2025 https://docs.aws.amazon.com/autoscaling/ec2/userguide/what-is-amazon-ec2-auto-scaling.html https://000045.awsstudygroup.com/ 5 - Weekly team meetup - Start working on the main game prototype 09/25/2025 09/25/2025 6 - Continue on building the first prototype 09/26/2025 09/26/2025 Week 3 Achievements: Weekly meetup: Designed together the app\u0026rsquo;s UI Come up with more business rules Design more game mode Project prototype building: Installed libraries: antd, socket.io, idv4\u0026hellip; Dived-deep into game mechanics and logic Built simple UI Built basic game logic for the main game Each word will have its own field Press space to proceed to the next word Understood the differences between managed database (RDS) and self-managed EC2-hosted databases. Deployed a working application on Amazon Lightsail, compared cost and use cases with EC2. Successfully created an EC2 Auto Scaling Group with scaling policies that respond to load. Gained hands-on skills with services beyond basic EC2, moving closer to production-grade AWS infrastructure. "},{"uri":"https://thienluhoan.github.io/workshop-template/1-worklog/1.4-week4/","title":"Week 4 Worklog","tags":[],"description":"","content":"Week 4 Objectives: Learn more AWS services. Continue on FCJ project prototype. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Learn about AWS CloudWatch 09/29/2025 09/29/2025 https://000008.awsstudygroup.com/1-introduction/ https://docs.aws.amazon.com/cloudwatch/ https://www.youtube.com/watch?v=ZCHwJLqPLj8 https://www.youtube.com/watch?v=Yxl7e88cTAQ 3 - Learn about AWS Elasti Cache 09/30/2025 09/30/2025 https://docs.aws.amazon.com/elasticache/ https://redis.io/ https://www.youtube.com/watch?v=jgpVdJB2sKQ 4 - Continue on FCJ project development 10/01/2025 10/01/2025 5 - Participate in AWS event: [AWS GenAI Builder Club] AI-Driven Development Life Cycle: Reimagining Software Engineering - Continue on FCJ project development 10/02/2025 10/02/2025 6 - Continue on FCJ project development 10/03/2025 10/03/2025 Week 4 Achievements: Learned about AWS CloudWatch What CloudWatch does: It collects metrics, logs, and events from AWS resources and applications. Core concepts: Metrics, Logs, Events, the Dashboard, Alarms, CloudWatch Agent Practice: Launched and watched EC2 instance metrics (CPU, Memory, Network, Disk) Created an alarm when EC2 CPU \u0026gt; 70% then link to an SNS topic to get email alerts Viewed EC2 instance\u0026rsquo;s logs in CloudWatch Logs Viewed logs with queries in Logs Insight Added widgets showing EC2 CPU Utilization, NetworkIn/Out then add to the dashboard Learned about AWS Elasti Cache Learned about caching in general in web applications Discovered about Redis Learned Elasti Cache key concepts: nodes, clusters, shards, replication groups Practice: Created a Redis Cluster with cluster mode disabled in a VPC with an EC2 instance Ran a small Node.js app on EC2 that checks for cached data and fetch from API if missed Monitoring with CloudWatch: viewed metrics like CPUUtilization, CurrConnections, Evictions Replication group and failover: created a replication group with multi-AZ and 1 replica per shard Simulate failover to see new primary taking over FCJ project development Refine main game logic: Add practice mode (singleplayer mode) Add player\u0026rsquo;s caret with smooth animation when moving between characters Add color indicator for each character Add game duration Add logic for handling overflow characters at the end of each word Introduced multiplayer built on WebSocket Add room concept: Players can create rooms, other players can join rooms with roomId Add carets for each player that moves in real-time reflecting other players typing progress AWS event participation: Participated in AWS GenAI Builder Club: AI-Driven Development Life Cycle: Reimagining Software Engineering Learned about AI in development concepts: How to leverage AI in the development cycle to improve software quality Current state of AI in software developing Learned about AI-driven development Learned about Kiro IDE through demos "},{"uri":"https://thienluhoan.github.io/workshop-template/1-worklog/1.5-week5/","title":"Week 5 Worklog","tags":[],"description":"","content":"Week 5 Objectives: Learn about AWS Lambda Learn about Amazon Cognito and modern authorization and authentication in web apps Learn about API Gateway Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Learn about AWS Lambda 10/06/2025 10/06/2025 https://000078.awsstudygroup.com/ https://aws.amazon.com/lambda/ https://www.youtube.com/watch?v=e1tkFsFOBHA https://www.youtube.com/watch?v=jgpRAiar2LQ 3 - Learn about modern authen/authorize in modern web apps- Learn about Amazon Cognito 10/07/2025 10/07/2025 https://dev.to/ifechukwuobiezue/mastering-modern-authentication-in-web-applications-oauth-20-demystified-2b8b https://aws.amazon.com/pm/cognito/?trk=246e27b6-9b79-45af-ba59-fdf3f8be64f8\u0026sc_channel=ps\u0026ef_id=CjwKCAiA86_JBhAIEiwA4i9Ju4vtraj9L5zlL1SabX8bG7JmTWk4rdIX4ehPV0jJd8BKZlIMymtVdhoCunwQAvD_BwE:G:s\u0026s_kwcid=AL!4422!3!785574083501!e!!g!!amazon%20cognito!23300619811!193013719910\u0026gad_campaignid=23300619811\u0026gbraid=0AAAAADjHtp9IwNbHJlX1E1BUO5b4ZKeV_\u0026gclid=CjwKCAiA86_JBhAIEiwA4i9Ju4vtraj9L5zlL1SabX8bG7JmTWk4rdIX4ehPV0jJd8BKZlIMymtVdhoCunwQAvD_BwE https://www.youtube.com/watch?v=tCNcG1lcCHY https://www.youtube.com/watch?v=UBUNrFtufWo https://www.youtube.com/watch?v=fyTxwIa-1U0 4 - Learn about API Gateway 10/08/2025 10/08/2025 https://www.youtube.com/watch?v=6ULyxuHKxg8 https://www.youtube.com/watch?v=jgpRAiar2LQ 5 - Continue with FCJ Final Project 10/09/2025 10/09/2025 6 - Continue with FCJ Final Project 10/10/2025 10/10/2025 Week 5 Achievements: Learned the fundamentals of AWS Lambda:\nUnderstood the serverless compute model and its benefits (no server management, pay-per-use, automatic scaling). Explored Lambda function anatomy: handler, event, context, and runtime environments. Learned about Lambda execution environments and how they work (cold starts vs warm starts). Understood Lambda pricing model: free tier (1M requests + 400K GB-seconds), then pay per request and compute time. Explored different Lambda runtimes: Node.js, Python, Java, Go, and custom runtimes. Hands-on practice with Lambda functions:\nCreated first Lambda function using Node.js runtime. Configured function settings: memory allocation, timeout, and environment variables. Tested Lambda functions directly in the console with test events. Explored Lambda logs in CloudWatch to debug and monitor executions. Learned about Lambda layers for sharing code and dependencies across functions. Gained comprehensive understanding of modern authentication:\nLearned OAuth 2.0 and OpenID Connect protocols and their role in modern web applications. Understood the difference between authentication (who you are) and authorization (what you can do). Explored JWT (JSON Web Tokens) structure: header, payload, signature. Learned about token types: ID tokens (identity), Access tokens (API access), Refresh tokens (get new tokens). Understood token-based authentication flow and security best practices. Mastered Amazon Cognito for user management:\nCreated and configured Cognito User Pools for user directory and authentication. Set up user attributes: email, username, phone number, custom attributes. Configured password policies and security settings (MFA options, account recovery). Implemented email verification flow for user sign-ups. Created app clients and configured OAuth 2.0 settings (grant types, scopes, callback URLs). Set up Cognito Hosted UI for quick authentication testing. Integrated Cognito with API Gateway as an authorizer to secure API endpoints. Hands-on authentication implementation:\nRegistered test users through Cognito Hosted UI. Tested complete authentication flow: sign-up, email verification, sign-in. Obtained and decoded JWT tokens to understand user claims. Configured API Gateway Cognito authorizer to validate JWT tokens. Tested authenticated API calls with Bearer tokens in Authorization headers. Extracted user information from JWT claims in Lambda functions (event.requestContext.authorizer.claims). Implemented auto-population of user data (cognitoSub, email) from authenticated tokens. Understood production-ready authentication patterns:\nLearned about token refresh mechanism to maintain user sessions without re-authentication. Explored token expiration handling and security implications. Understood the importance of HTTPS and secure token storage. Learned Cognito pricing model: first 50,000 MAU (Monthly Active Users) free. Learned Amazon API Gateway fundamentals:\nUnderstood API Gateway role as the \u0026ldquo;front door\u0026rdquo; for backend services. Explored different API types: REST API, HTTP API, WebSocket API. Learned REST API concepts: resources, methods, stages, deployments. Understood Lambda proxy integration vs custom integration patterns. Explored API Gateway pricing: $3.50 per million requests (REST API). Built complete REST API infrastructure:\nCreated REST API with multiple resources and methods (GET, POST, PUT, DELETE). Designed RESTful endpoints following best practices (/users, /users/{id}). Configured Lambda proxy integration for seamless Lambda function invocation. Set up path parameters for dynamic routing ({id}). Implemented proper HTTP status codes for different scenarios (200, 201, 400, 404, 500). Configured CORS (Cross-Origin Resource Sharing):\nUnderstood CORS and why it\u0026rsquo;s needed for browser-based applications calling APIs from different domains. Enabled CORS on API Gateway resources to allow frontend integration. Configured allowed origins, headers, and methods for secure cross-origin requests. Set up OPTIONS method for CORS preflight requests. Implemented API security and monitoring:\nDeployed API to stages (dev, prod) for environment management. Configured request throttling to protect backend from abuse (rate: 1000 req/s, burst: 2000). Enabled CloudWatch Logs for request/response logging and debugging. Set up detailed CloudWatch metrics for monitoring API performance. Created CloudWatch alarms for 4XX errors, 5XX errors, and high latency. Hands-on API testing:\nTested API endpoints using API Gateway console test feature. Made authenticated API calls using curl with Bearer tokens. Used Postman to create complete API collection for all CRUD operations. Verified proper error handling and status codes for various scenarios. Exported API documentation in OpenAPI/Swagger format. Applied serverless knowledge to final project:\nDesigned and implemented serverless backend architecture for project requirements. Integrated authentication, API Gateway, Lambda, and database components. Tested end-to-end workflows and refined implementation. Documented architecture decisions and implementation details. Prepared project presentation and demonstration materials. "},{"uri":"https://thienluhoan.github.io/workshop-template/1-worklog/1.6-week6/","title":"Week 6 Worklog","tags":[],"description":"","content":"Week 6 Objectives: Connect and get acquainted with members of First Cloud Journey. Understand basic AWS services, how to use the console \u0026amp; CLI. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Study on security on AWS Cloud: + How to privately access to S3 with VPC Endpoints - Continue on build FCJ project 10/06/2025 10/06/2025 https://000111.awsstudygroup.com/ 3 - Continue on security: + AWS WAF - Study about AWS cloud through AWS Certified Cloud Practitioner questions 10/07/2025 10/07/2025 https://000026.awsstudygroup.com/1-introduction/ https://www.udemy.com/course/6-tests-aws-certified-cloud-practitioner-clf-c02-2025/ https://aws.amazon.com/waf/ 4 - Continue on security: + AWS WAF - Continue building FCJ project 10/08/2025 10/08/2025 https://aws.amazon.com/waf/ 5 - Weekly FCJ team meeting 10/09/2025 10/09/2025 6 - Continue building FCJ project 10/10/2025 10/10/2025 Week 6 Achievements: Learned about Accessing Private S3 Buckets via VPC Endpoints Concepts learned: Gateway and Interface Endpoints allow access to AWS services privately without traversing the public internet. Gateway Endpoints: Used for S3 and DynamoDB to route traffic from inside a VPC to the service securely. Interface Endpoints (AWS PrivateLink): Enable private connections to AWS services, partner services, or custom services using private IPs inside a VPC. AWS Direct Connect: Provides a dedicated private connection between on-premises data centers and AWS, bypassing the public internet. AWS Site-to-Site VPN: Establishes a secure encrypted connection between on-premises and AWS VPCs over the public internet (cheaper and easier than Direct Connect). Key takeaways: Gateway endpoints only handle outbound traffic from within the VPC. On-prem environments must use Interface Endpoints combined with VPN or Direct Connect for private S3 access. AWS-managed services such as CloudFront, Bedrock, SNS, SQS, and Lambda (non-VPC) operate outside the VPC plane, so they can communicate with services like S3 without endpoints. VPC-based resources (e.g., EC2, ECS, VPC-attached Lambda) require VPC endpoints or a NAT gateway to reach S3 securely. Practice: Created a private S3 bucket and configured a Gateway VPC Endpoint for S3. Verified EC2 instances in a private subnet could access S3 without using an Internet Gateway. Tested S3 uploads from ECS to confirm correct routing through the VPC endpoint. Observed failed connections when S3 bucket and instance were in different regions, fixed by aligning regions. Reviewed CloudFront and pre-signed URL approaches for securely serving S3 content in web applications. Simulate the on-prem environment by setting up a separate VPC and connect it to S3 by using AWS Direct Connect. Learned about web applications security concepts Practice: Explore and exploit common security risks on web applications on OWASP Juice Shop Explore about AWS WAF Study 66 questions of AWS Certified Cloud Practitioner exam "},{"uri":"https://thienluhoan.github.io/workshop-template/1-worklog/1.7-week7/","title":"Week 7 Worklog","tags":[],"description":"","content":"Week 7 Objectives: Get ready for mid-term exam Study AWS Certified Practitioner questions Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Get ready for mid-term exam: Study AWS Certified Cloud Practitioner questions 13/10/2025 13/10/2025 \u0026lt;udemy.com/course/6-tests-aws-certified-cloud-practitioner-clf-c02-2025/\u0026gt; https://github.com/kananinirav/AWS-Certified-Cloud-Practitioner-Notes/tree/master/practice-exam 3 - Get ready for mid-term exam: Study AWS Certified Cloud Practitioner questions 14/10/2025 14/10/2025 \u0026lt;udemy.com/course/6-tests-aws-certified-cloud-practitioner-clf-c02-2025/\u0026gt; https://github.com/kananinirav/AWS-Certified-Cloud-Practitioner-Notes/tree/master/practice-exam 4 - Get ready for mid-term exam: Study AWS Certified Cloud Practitioner questions 15/10/2025 15/10/2025 \u0026lt;udemy.com/course/6-tests-aws-certified-cloud-practitioner-clf-c02-2025/\u0026gt; https://github.com/kananinirav/AWS-Certified-Cloud-Practitioner-Notes/tree/master/practice-exam 5 - Get ready for mid-term exam: Study AWS Certified Cloud Practitioner questions 16/10/2025 16/10/2025 https://github.com/kananinirav/AWS-Certified-Cloud-Practitioner-Notes/tree/master/practice-exam 6 - Get ready for mid-term exam: Study AWS Certified Cloud Practitioner questions 17/10/2025 17/10/2025 https://github.com/kananinirav/AWS-Certified-Cloud-Practitioner-Notes/tree/master/practice-exam Week 7 Achievements: AWS Certified Cloud Practitioner Exam Preparation\nComprehensive exam preparation for mid-term:\nCompleted multiple practice exams from Udemy course (6 full-length tests). Practiced with AWS Certified Cloud Practitioner practice questions from GitHub repository. Reviewed incorrect answers and strengthened understanding of weak areas. Focused on exam-specific question patterns and time management strategies. Solidified understanding of AWS Cloud Concepts:\nMastered AWS Well-Architected Framework pillars: Operational Excellence, Security, Reliability, Performance Efficiency, Cost Optimization, and Sustainability. Understood AWS Cloud value proposition: cost savings, agility, elasticity, and global reach. Learned cloud computing models: IaaS, PaaS, SaaS and their use cases. Explored cloud deployment models: Public Cloud, Private Cloud, Hybrid Cloud. Understood the AWS shared responsibility model and security boundaries. Deepened knowledge of AWS Security and Compliance:\nLearned AWS security services: IAM, AWS Organizations, CloudTrail, Config, GuardDuty. Understood IAM best practices: MFA, least privilege, password policies, role-based access. Explored AWS compliance programs: HIPAA, PCI-DSS, SOC, ISO certifications. Learned about encryption at rest and in transit using KMS and SSL/TLS. Understood network security: Security Groups, NACLs, AWS WAF, Shield. Expanded knowledge of Core AWS Services:\nCompute: EC2 instance types, pricing models (On-Demand, Reserved, Spot), Lambda, ECS, EKS, Fargate. Storage: S3 storage classes, EBS volume types, EFS, S3 Glacier, Storage Gateway. Database: RDS engines (MySQL, PostgreSQL, Oracle, SQL Server), DynamoDB, Aurora, ElastiCache, Redshift. Networking: VPC components, Route 53, CloudFront, Direct Connect, VPN. Management: CloudWatch, CloudFormation, Systems Manager, Trusted Advisor, AWS Organizations. Mastered AWS Billing and Pricing:\nUnderstood AWS pricing models: pay-as-you-go, save when you reserve, pay less by using more. Learned cost management tools: Cost Explorer, Budgets, Cost and Usage Reports. Explored AWS Free Tier: 12 months free, always free, and trials. Understood pricing for key services: EC2, S3, RDS, Lambda, data transfer costs. Learned Total Cost of Ownership (TCO) calculator for comparing on-premises vs AWS costs. Explored cost optimization strategies: right-sizing, reserved instances, savings plans, spot instances. Strengthened understanding of AWS Support Plans:\nLearned support tiers: Basic (free), Developer ($29/month), Business ($100/month), Enterprise ($15,000/month). Understood response times and support channels for each tier. Explored AWS Trusted Advisor checks available at different support levels. Learned about AWS Professional Services and Partner Network (APN). Gained insights into AWS Architecture Best Practices:\nLearned design principles for resilient architectures: loose coupling, stateless applications, fault tolerance. Understood high availability patterns: multi-AZ deployments, auto-scaling, load balancing. Explored disaster recovery strategies: backup and restore, pilot light, warm standby, hot site. Learned about AWS global infrastructure: Regions, Availability Zones, Edge Locations. Understood when to use which AWS service based on requirements. Enhanced knowledge of AWS Migration and Innovation:\nLearned AWS migration strategies (6 R\u0026rsquo;s): Rehost, Replatform, Refactor, Repurchase, Retire, Retain. Explored AWS migration services: Server Migration Service (SMS), Database Migration Service (DMS), Snow family. Understood AWS innovation services: Machine Learning (SageMaker), IoT, Analytics (Athena, Kinesis), AR/VR. Learned about AWS managed services to reduce operational overhead. Practiced exam-taking strategies:\nDeveloped time management skills for 65 questions in 90 minutes. Learned to identify question types: scenario-based, service-specific, best practices. Practiced elimination technique for multiple-choice questions. Improved ability to understand AWS terminology and service names. Built confidence through repeated practice exams and score improvements. "},{"uri":"https://thienluhoan.github.io/workshop-template/1-worklog/1.8-week8/","title":"Week 8 Worklog","tags":[],"description":"","content":"Week 8 Objectives: Get ready for mid-term exam Study AWS Certified Solution Architect questions Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Get ready for mid-term exam: Study AWS Certified Solution Architect questions 20/10/2025 20/10/2025 https://www.udemy.com/course/aws-certified-solutions-architect-associate-saa-c03 https://www.examtopics.com/exams/amazon/aws-certified-solutions-architect-associate-saa-c03/ 3 - Get ready for mid-term exam: Study AWS Certified Solution Architect questions 21/10/2025 21/10/2025 https://www.udemy.com/course/aws-certified-solutions-architect-associate-saa-c03 https://www.examtopics.com/exams/amazon/aws-certified-solutions-architect-associate-saa-c03/ 4 - Get ready for mid-term exam: Study AWS Certified Solution Architect questions 22/10/2025 22/10/2025 https://www.udemy.com/course/aws-certified-solutions-architect-associate-saa-c03 https://www.examtopics.com/exams/amazon/aws-certified-solutions-architect-associate-saa-c03/ 5 - Get ready for mid-term exam: Study AWS Certified Solution Architect questions 23/10/2025 23/10/2025 https://www.udemy.com/course/aws-certified-solutions-architect-associate-saa-c03 https://www.examtopics.com/exams/amazon/aws-certified-solutions-architect-associate-saa-c03/ 6 - Get ready for mid-term exam: Study AWS Certified Solution Architect questions 24/10/2025 24/10/2025 https://www.udemy.com/course/aws-certified-solutions-architect-associate-saa-c03 https://www.examtopics.com/exams/amazon/aws-certified-solutions-architect-associate-saa-c03/ Week 8 Achievements: Focused AWS Solutions Architect Exam Preparation\nDedicated the entire week (20/10/2025‚Äì24/10/2025) to studying AWS Certified Solutions Architect Associate (SAA-C03) exam questions using ExamTopics resources. Completed daily practice question sets to build familiarity with real exam patterns and scenario-based questions. Reviewed explanations for both correct and incorrect answers to deepen conceptual understanding and eliminate misconceptions. Strengthened time-management strategies by simulating exam-style timed sessions. Enhanced Understanding of Core AWS Architecture Principles\nReinforced AWS Well-Architected Framework pillars: Operational Excellence, Security, Reliability, Performance Efficiency, and Cost Optimization. Studied best practices for designing scalable, resilient, and fault-tolerant systems. Understood principles of decoupling, stateless architecture, distributed design, and elasticity. Improved Knowledge Across Key AWS Compute Services\nDeepened understanding of EC2 instance families, use cases, and pricing models (On-Demand, Reserved, Spot, Savings Plans). Studied serverless compute patterns involving AWS Lambda, event sources, and execution environment behaviors. Reviewed ECS, EKS, and Fargate container orchestration models and their architectural trade-offs. Explored Auto Scaling strategies, health checks, scaling policies, and load balancing (ALB, NLB, CLB). Strengthened Expertise in AWS Storage \u0026amp; Database Services\nMastered S3 features: storage classes, lifecycle policies, versioning, replication, encryption, and performance optimization. Reviewed EBS volume types, throughput vs IOPS considerations, and snapshot lifecycle. Studied relational and non-relational database options including RDS, Aurora, DynamoDB, and ElastiCache. Understood backup, multi-AZ failover, read replicas, and high-availability configurations. Advanced VPC, Networking, and Security Knowledge\nAnalyzed VPC design components: subnets, route tables, NAT gateways, IGWs, VPC peering, and Transit Gateway. Clarified differences between Security Groups vs NACLs, public vs private subnets, and common network patterns. Studied Route 53 routing policies, DNS failover strategies, and global routing behaviors. Strengthened understanding of AWS KMS, encryption standards, IAM best practices, and cross-account access design. Expanded Knowledge of AWS Distributed Systems, HA \u0026amp; DR Strategies\nReviewed multi-AZ and multi-Region architectures for high availability. Studied disaster recovery strategies: backup-and-restore, pilot light, warm standby, and multi-site active-active. Learned techniques for building loosely coupled systems using SQS, SNS, EventBridge, and decoupled microservices. Deepened Understanding of Monitoring, Management \u0026amp; Automation\nStudied CloudWatch metrics, logs, custom dashboards, and alarms. Reviewed CloudTrail audit logging and integration with security services. Explored CloudFormation IaC fundamentals, stack lifecycle, drift detection, and modularization. Understood Systems Manager capabilities for patching, inventory, and resource automation. Improved Cost Optimization \u0026amp; Billing Awareness\nReviewed architectural decisions that reduce cost while maintaining performance. Understood S3 Intelligent-Tiering, EC2 right-sizing, RI vs Savings Plans, and Spot instance strategies. Analyzed AWS cost visibility tools such as Cost Explorer, Budgets, and CUR. Practiced Exam-Focused Strategies\nIdentified common scenario patterns in SAA-C03 questions (migration, high availability, performance bottlenecks, security hardening). Applied elimination techniques for multi-answer questions and scenario interpretation. Learned to map AWS services to architectural use cases quickly and confidently. Improved ability to evaluate trade-offs between cost, performance, and reliability. "},{"uri":"https://thienluhoan.github.io/workshop-template/1-worklog/1.9-week9/","title":"Week 9 Worklog","tags":[],"description":"","content":" ‚ö†Ô∏è Note: The following information is for reference purposes only. Please do not copy verbatim for your own report, including this warning.\nWeek 9 Objectives: Connect and get acquainted with members of First Cloud Journey. Understand basic AWS services, how to use the console \u0026amp; CLI. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Get acquainted with FCJ members - Read and take note of internship unit rules and regulations 08/11/2025 08/11/2025 3 - Learn about AWS and its types of services + Compute + Storage + Networking + Database + \u0026hellip; 08/12/2025 08/12/2025 https://cloudjourney.awsstudygroup.com/ 4 - Create AWS Free Tier account - Learn about AWS Console \u0026amp; AWS CLI - Practice: + Create AWS account + Install \u0026amp; configure AWS CLI + How to use AWS CLI 08/13/2025 08/13/2025 https://cloudjourney.awsstudygroup.com/ 5 - Learn basic EC2: + Instance types + AMI + EBS + \u0026hellip; - SSH connection methods to EC2 - Learn about Elastic IP 08/14/2025 08/15/2025 https://cloudjourney.awsstudygroup.com/ 6 - Practice: + Launch an EC2 instance + Connect via SSH + Attach an EBS volume 08/15/2025 08/15/2025 https://cloudjourney.awsstudygroup.com/ Week 9 Achievements: Understood what AWS is and mastered the basic service groups:\nCompute Storage Networking Database \u0026hellip; Successfully created and configured an AWS Free Tier account.\nBecame familiar with the AWS Management Console and learned how to find, access, and use services via the web interface.\nInstalled and configured AWS CLI on the computer, including:\nAccess Key Secret Key Default Region \u0026hellip; Used AWS CLI to perform basic operations such as:\nCheck account \u0026amp; configuration information Retrieve the list of regions View EC2 service Create and manage key pairs Check information about running services \u0026hellip; Acquired the ability to connect between the web interface and CLI to manage AWS resources in parallel.\n\u0026hellip;\n"},{"uri":"https://thienluhoan.github.io/workshop-template/1-worklog/","title":"Worklog","tags":[],"description":"","content":"Week 1: Getting familiar with AWS. Learned about costs and budgets, access management.\nWeek 2: Getting familiar with basic AWS services: VPC, EC2, S3\nWeek 3: Getting familiar with intermediate AWS services: RDS, Lightsail, EC2 auto Scaling, CloudWatch. Start building FCJ project\nWeek 4: Continue to learn AWS services: CloudWatch, Elasti Cache. Continue on building FCJ project\nWeek 5: Doing task D\u0026hellip;\nWeek 6: Doing task E\u0026hellip;\nWeek 7: Doing task G\u0026hellip;\nWeek 8: Doing task H\u0026hellip;\nWeek 9: Doing task I\u0026hellip;\nWeek 10: Doing task L\u0026hellip;\nWeek 11: Doing task M\u0026hellip;\nWeek 12: Doing task N\u0026hellip;\n"},{"uri":"https://thienluhoan.github.io/workshop-template/5-workshop/5.2-serverless-backend/","title":"Part 2: Backend Deployment with API Gateway, Lambda, RDS, and Cognito","tags":[],"description":"","content":"Introduction Welcome to the second part in our workshop building serverless application series! In this hands-on session, you\u0026rsquo;ll build a complete, secure backend infrastructure for your serverless application using AWS managed services.\nYou will then learn how to connect our serverless backend to frontend that we previously built in Part 1\nModern applications require robust, scalable backend systems that can handle business logic, manage data securely, and authenticate users. In this workshop, you\u0026rsquo;ll create a fully serverless backend architecture using AWS Lambda for compute, Amazon RDS for data persistence, API Gateway for RESTful APIs, Amazon Cognito for user authentication, and AWS Secrets Manager for secure credential management.\nWhat You\u0026rsquo;ll Build By the end of this part, you\u0026rsquo;ll have deployed a complete backend infrastructure featuring:\nRESTful APIs: API Gateway endpoints that handle HTTP requests and route them to appropriate Lambda functions Serverless Computing: Lambda functions written in Node.js/Python that execute your business logic Managed Database: Amazon RDS PostgreSQL database for reliable data storage User Authentication: Amazon Cognito user pools for sign-up, sign-in, and user management API Security: Cognito authorizers protecting your API endpoints. Furthermore, enforce API Gateway to only accept requests originated from CloudFront Secrets Management: AWS Secrets Manager securely storing database credentials and generate a secure value to embed to CloudFront custom header to restrict access to the API Gateway Network Security: VPC configuration isolating your database from public internet Why This Architecture? This serverless backend architecture offers several key benefits:\nNo Server Management: AWS handles provisioning, patching, and scaling Pay-Per-Use: Only pay for actual compute time and storage used Auto-Scaling: Automatically handles traffic spikes from 0 to thousands of requests Built-in Security: Multiple layers including IAM, Cognito, VPC, and secrets management Developer Productivity: Focus on code, not infrastructure Workshop Duration Estimated Time: 3-4 hours\nVPC and networking setup: 20 minutes RDS database creation: 30 minutes Secrets Manager configuration: 15 minutes Lambda function development: 45 minutes API Gateway setup: 40 minutes Cognito configuration: 45 minutes Integration and testing: 45 minutes Workshop Structure This workshop is divided into the following sections:\nPart 1: VPC and Network Setup Create VPC for database isolation Configure subnets (we will set up 1 Availability Zone for this workshop) Set up security groups for database access Part 2: RDS Database Setup Create RDS PostgreSQL instance Configure database parameters Create database schema and tables Set up database user and permissions Part 3: AWS Secrets Manager Configuration Store database credentials securely Configure secret rotation (optional) Grant Lambda access to secrets Create VPC Endpoint for Lambda to call AWS Secrets Manager Create role for Lambda to access to RDS and AWS Secrets Manager Part 4: Lambda Functions Development Create Lambda execution role with proper permissions Write Lambda functions for CRUD operations Package and deploy Lambda functions Configure environment variables Connect Lambda to RDS via VPC Test Lambda Part 5: API Gateway Setup Create REST API Define resources and methods Configure Lambda proxy integration Set up CORS for frontend integration Deploy API to a stage Part 6: Amazon Cognito Configuration Create Cognito user pool Configure user attributes and policies Set up app client for your application Configure user pool domain Test user registration and authentication Part 7: API Security with Cognito Create Cognito authorizer in API Gateway Secure API endpoints with authentication Test authenticated API calls Handle authorization tokens in Lambda Part 8: Integration Testing Test unauthenticated endpoints Test authenticated endpoints with tokens Verify database operations Test error handling (Optional) Integrate with Part 1: Frontend Deployment frontend Part 9: Monitoring and Logging View Lambda CloudWatch Logs Monitor API Gateway metrics Track Cognito user activity Set up CloudWatch alarms Part 10: Cleanup Delete resources in correct order Verify cost elimination Save configurations for future use "},{"uri":"https://thienluhoan.github.io/workshop-template/2-proposal/","title":"Proposal","tags":[],"description":"","content":"Real-Time Typing Challenge Platform A Multiplayer Monkeytype Clone Built on AWS Serverless Architecture\n1. Executive Summary The Real-Time Typing Challenge Platform is an interactive web application that replicates the core experience of Monkeytype while introducing multiplayer functionality for live competitive or collaborative typing sessions. Designed as a showcase of real-time web technologies and scalable cloud architecture, the platform combines a modern frontend experience with a serverless backend powered by AWS.\nUsers can create or join typing rooms, compete in real time, and view performance metrics such as Words Per Minute (WPM), accuracy, and rankings. The application leverages Next.js for the frontend, AWS Lambda and API Gateway (WebSocket) for real-time synchronization, and Amazon DynamoDB for player and session data. Amazon Cognito secures user access and authentication. The solution demonstrates how cloud-native services can deliver fast, scalable, and cost-efficient real-time applications without the need for traditional server management.\n2. Problem Statement What‚Äôs the Problem? Existing typing platforms are often limited to single-player functionality, lacking real-time multiplayer interaction or open implementation examples. Most multiplayer solutions require dedicated servers or complex infrastructure, making them costly and difficult to maintain. For developers and enthusiasts, there is no accessible, serverless example demonstrating real-time synchronization, event-driven updates, and secure user management in one integrated system.\nThe Solution This project provides a serverless, real-time typing platform that allows multiple users to connect, type simultaneously, and see instant feedback on their progress. It is designed to be lightweight, cost-efficient, and scalable:\nAWS API Gateway (WebSocket): Enables bi-directional communication for live match updates. AWS Lambda: Handles game logic, score calculation, and event broadcasting. Amazon DynamoDB: Stores user profiles, ongoing sessions, and leaderboards with low latency. Next.js with AWS Amplify: Delivers a modern, responsive frontend optimized for performance. Amazon Cognito: Manages authentication, allowing users to register, sign in, and track personal stats securely. Key features include:\nReal-time multiplayer rooms Individual and team typing modes Live leaderboards Performance history tracking 3. Benefits and Return on Investment The project serves as both a developer learning platform and a user-facing application. It demonstrates best practices in event-driven architecture, WebSocket implementation, and cloud-based scalability ‚Äî all at minimal operational cost.\nFor users, it provides an engaging, social typing experience. For developers, it offers an educational reference for building serverless real-time systems. The estimated running cost, based on AWS‚Äôs free tier and minimal Lambda/DynamoDB usage, is under $1 per month.\nThe platform requires no ongoing server maintenance, ensuring:\nLong-term sustainability Rapid scalability Low operational overhead This makes it ideal for workshops, demos, or portfolio projects.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/5-workshop/5.1-frontend-deployment/5.1.2-s3-hosting/","title":"S3 Static Website Hosting","tags":[],"description":"","content":"Overview In this section, you\u0026rsquo;ll set up Amazon S3 to host your static website. S3 (Simple Storage Service) provides a cost-effective and highly durable solution for hosting static content like HTML, CSS, JavaScript, and images.\nWhat you\u0026rsquo;ll accomplish:\nClone the sample application repository Build the frontend application Create and configure an S3 bucket Upload your website files to S3 Enable static website hosting Test your website Estimated time: 30 minutes\nCosts Considerations Free-tier: S3 does not have free-tier benefits Paid-tier Even paid tier cost is minimal for our workshop Overall: \u0026lt;$0 (clean up immediately after finish workshop) Step 1: Prepare Your Application 1.1 Clone the Sample Repository Open your terminal or command prompt and run:\ngit clone https://github.com/Icyretsz/fcj-workshop-serverless-frontend.git 1.2 Install Dependencies The sample application uses Node.js and npm. Install the required dependencies:\nnpm install Troubleshooting:\nIf you don\u0026rsquo;t have Node.js installed, download it from https://nodejs.org/ (LTS version recommended) Verify installation: node --version and npm --version Minimum required versions: Node.js 16.x or higher 1.3 Build the Application Navigate to the root directory and build the production-ready version:\nnpm run build The command will:\nThe build process compiled your source code Optimized assets for production (minification, bundling) Created a dist/ directory with all deployable files 1.4 Verify Build Output Check the contents of your build directory:\nls -la dist/ You should see:\ndist/ ‚îú‚îÄ‚îÄ index.html ‚îú‚îÄ‚îÄ favicon.ico ‚îú‚îÄ‚îÄ static/ ‚îÇ ‚îú‚îÄ‚îÄ css/ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ main.def456.css ‚îÇ ‚îî‚îÄ‚îÄ js/ ‚îÇ ‚îî‚îÄ‚îÄ main.abc123.js ‚îî‚îÄ‚îÄ assets/ ‚îî‚îÄ‚îÄ images/ Step 2: Create an S3 Bucket 2.1 Navigate to S3 Console Log in to the AWS Management Console In the search bar at the top, type \u0026ldquo;S3\u0026rdquo; Click on S3 under Services 2.2 Create New Bucket Click the Create bucket button Configure the following settings: General Configuration:\nBucket name: workshop-frontend-[your-name]-[random-string] Example: workshop-frontend-john-a1b2c3 Must be globally unique across all AWS accounts Use only lowercase letters, numbers, and hyphens Note: Write down your bucket name - you\u0026rsquo;ll need it throughout the workshop 2.3 Configure Bucket Settings Object Ownership:\nKeep default: ACLs disabled (recommended) Block Public Access settings:\nUNCHECK \u0026ldquo;Block all public access\u0026rdquo; Check the acknowledgment box: \u0026ldquo;I acknowledge that the current settings might result in this bucket and the objects within becoming public\u0026rdquo; ‚ö†Ô∏è Security Note: We\u0026rsquo;re making this bucket public for website hosting. In production, you\u0026rsquo;d use CloudFront to access the bucket privately, which we\u0026rsquo;ll configure in Part 2.\nBucket Versioning:\nKeep default: Disable Tags (Optional but recommended):\nKey: Project, Value: ServerlessWorkshop Key: Workshop, Value: Frontend Default encryption:\nKeep default: Server-side encryption with Amazon S3 managed keys (SSE-S3) Advanced settings:\nKeep all defaults 2.4 Create the Bucket Scroll to the bottom and click Create bucket You should see a success message: \u0026ldquo;Successfully created bucket \u0026lsquo;workshop-frontend-[your-name]-[random-string]\u0026rsquo;\u0026rdquo; Step 3: Configure Static Website Hosting 3.1 Enable Website Hosting Click on your newly created bucket name Navigate to the Properties tab Scroll down to Static website hosting section Click Edit 3.2 Configure Hosting Settings Static website hosting:\nSelect Enable Hosting type:\nSelect Host a static website Index document:\nEnter: index.html Error document (Optional):\nEnter: index.html This allows client-side routing to work properly (for React, Vue, Angular apps) Click Save changes 3.3 View website endpoint Scroll back down to Static website hosting section Copy the Bucket website endpoint URL Example: http://workshop-frontend-john-a1b2c3.s3-website-us-east-1.amazonaws.com Save this URL - you\u0026rsquo;ll use it to test the website Step 4: Upload Website Files 4.1 Upload via AWS Console Navigate to the Objects tab in your bucket Click Upload 4.2 Add Files Option A: Drag and Drop\nOpen your file explorer/finder Navigate to your frontend/dist/ directory Select ALL files and folders inside the build directory Drag them into the upload area Option B: Browse Files\nClick Add files and Add folder Navigate to frontend/dist/ Select all contents ‚ö†Ô∏è Important: Upload the contents of the dist folder, not the dist folder itself. Your S3 bucket root should have index.html at the top level.\n4.3 Configure Upload Settings Permissions:\nKeep defaults (inherited from bucket) Properties:\nKeep defaults Storage class:\nKeep default: Standard 4.4 Complete Upload Scroll down and click Upload Wait for the upload to complete You should see \u0026ldquo;Upload succeeded\u0026rdquo; with a list of uploaded files Click Close 4.5 Verify Upload Back in your bucket, you should now see:\nindex.html favicon.ico static/ folder assets/ folder (if applicable) Step 5: Configure Bucket Policy for Public Access 5.1 Create Bucket Policy Navigate to the Permissions tab Scroll down to Bucket policy section Click Edit 5.2 Add Policy JSON Copy and paste the following policy, replacing YOUR-BUCKET-NAME with your actual bucket name:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;PublicReadGetObject\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::YOUR-BUCKET-NAME/*\u0026#34; } ] } Example with actual bucket name:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;PublicReadGetObject\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::workshop-frontend-thien-bucket/*\u0026#34; } ] } What this policy does:\nAllows anyone (\u0026quot;Principal\u0026quot;: \u0026quot;*\u0026quot;) to read (s3:GetObject) any object in your bucket Required for public website hosting 5.3 Save Policy Click Save changes Step 6: Test Your Website 6.1 Access Your Website Use the Bucket website endpoint URL you saved earlier Open it in your web browser Example: http://workshop-frontend-john-a1b2c3.s3-website-us-east-1.amazonaws.com Expected result:\nThe website should load successfully You should see the homepage of the application 6.2 Test Navigation Click through different pages of your application Verify images and styles load correctly Check browser developer console for any errors (F12 or right-click ‚Üí Inspect) 6.3 Test Direct Object Access You can also access individual files directly:\nhttp://your-bucket-endpoint/index.html http://your-bucket-endpoint /css/main.def456.css Troubleshooting Issue: \u0026ldquo;403 Forbidden\u0026rdquo; Error Cause: Bucket policy not configured correctly or bucket not public\nSolution:\nVerify bucket policy is correct and saved Check that \u0026ldquo;Block all public access\u0026rdquo; is disabled Ensure the Resource ARN in the policy matches your bucket name Clear your browser cache and try again Issue: \u0026ldquo;404 Not Found\u0026rdquo; Error Cause: File not uploaded or incorrect URL\nSolution:\nVerify files are in the bucket root (not in a subfolder) Check that index.html exists at the bucket root Verify the website endpoint URL is correct Try accessing http://your-endpoint/index.html directly Issue: Styles or JavaScript Not Loading Cause: Incorrect content types or file paths\nSolution:\nCheck browser console for 404 errors Verify file paths in your HTML match the uploaded structure If using CLI, ensure content types are set correctly Check that all files from the build directory were uploaded Issue: \u0026ldquo;Bucket name already exists\u0026rdquo; Cause: S3 bucket names are globally unique\nSolution:\nChoose a different bucket name Add more random characters or your AWS account ID Example: workshop-frontend-john-20241126-a1b2c3 Summary Congratulations! You\u0026rsquo;ve successfully:\nCloned and built the sample application Created an S3 bucket Configured static website hosting Uploaded your website files Set up public access with bucket policy Tested the live website What You\u0026rsquo;ve Deployed The website is now:\nHosted on AWS S3 Publicly accessible via the S3 website endpoint Serving static files (HTML, CSS, JavaScript) Ready to be integrated with CloudFront in the next section Current Limitations Right now, the website:\nOnly uses HTTP (not HTTPS) Has no CDN/caching for global users Has no DDoS protection or WAF Uses a non-memorable S3 endpoint URL In the next sections, we\u0026rsquo;ll address these by adding CloudFront and WAF.\nNext Steps Proceed to Part 2: CloudFront Distribution Setup to add global content delivery and improve performance.\nQuick Reference Your Resources:\nBucket Name: _______________________________ Website Endpoint: _______________________________ Region: _______________________________ Useful Commands (AWS CLI):\n# Update website content cd frontend npm run build aws s3 sync ./build/ s3://YOUR-BUCKET-NAME/ --delete # List bucket contents aws s3 ls s3://YOUR-BUCKET-NAME/ --recursive # Delete all objects (for cleanup) aws s3 rm s3://YOUR-BUCKET-NAME/ --recursive Ready to continue? Let\u0026rsquo;s move on to adding CloudFront for global content delivery!\n"},{"uri":"https://thienluhoan.github.io/workshop-template/5-workshop/5.2-serverless-backend/5.2.2-vpc/","title":"VPC and Network Setup","tags":[],"description":"","content":"Overview In this section, you\u0026rsquo;ll create the network foundation for your serverless backend. You\u0026rsquo;ll set up a Virtual Private Cloud (VPC) with private subnets to securely host your RDS database and Lambda functions, ensuring your data layer is isolated from direct internet access.\nWhat you\u0026rsquo;ll accomplish:\nUnderstand VPC architecture for serverless applications Create a custom VPC with proper CIDR configuration Set up private subnets in different availability zones Configure security groups for database access Establish internet connectivity for Lambda functions Prepare network infrastructure for RDS and Lambda deployment Estimated time: 30 minutes\nWhy VPC for Serverless Backend? Security Benefits Private Subnets:\nDatabase not accessible from internet Lambda functions communicate privately with RDS Additional layer of defense against attacks Network Isolation:\nSeparate your database from public internet Control traffic flow with security groups Meet compliance requirements for data protection Architecture Pattern Internet ‚Üì NAT Gateway (for Lambda outbound) ‚Üì Private Subnet (Lambda Functions) ‚Üì Private Subnet (RDS Database) ‚îî‚îÄ‚îÄ Isolated, no direct internet access Lambda and VPC:\nBy default, Lambda functions run in an AWS-managed VPC with internet access. When you attach Lambda to your custom VPC:\nLambda can access resources in private subnets (like RDS)\nLambda loses direct internet access by default\nRequired for connecting to databases in VPC\nUnderstanding the Network Architecture What We\u0026rsquo;ll Build VPC (10.0.0.0/16) ‚îú‚îÄ‚îÄ Private Subnet 1 (10.0.128.0/20) - AZ: ap-southeast-1a ‚îÇ ‚îî‚îÄ‚îÄ For Lambda Functions ‚îÇ ‚îú‚îÄ‚îÄ Private Subnet 2 (10.0.144.0/20) - AZ: ap-southeast-1b ‚îÇ ‚îî‚îÄ‚îÄ No use for this subnet ‚îÇ ‚îú‚îÄ‚îÄ Private Subnet 3 (10.0.160.0/20) - AZ: ap-southeast-1a ‚îÇ ‚îî‚îÄ‚îÄ For RDS Database (multi-AZ requirement) ‚îÇ ‚îú‚îÄ‚îÄ Private Subnet 4 (10.0.176.0/20) - AZ: ap-southeast-1b ‚îÇ ‚îî‚îÄ‚îÄ For RDS Database (multi-AZ requirement) Why 4 subnets across 2 Availability Zones? Private Subnet 1 is preserved for a Lambda function\nPrivate Subnet 3 and Private Subnet 4 is preserved for an RDS instance.\nIt is required that your VPC must have at least two subnets. These subnets must be in two different Availability Zones in the AWS Region where you want to deploy your DB instance. This ensures high availability and allows RDS to create a Multi-AZ deployment or automatic failover setup.\nWe won\u0026rsquo;t use Private Subnet 2\nStep 1: Create VPC 1.1 Navigate to VPC Console Log in to AWS Management Console In the search bar, type \u0026ldquo;VPC\u0026rdquo; Click on VPC under Services 1.2 Create VPC Click Create VPC VPC settings: Select VPC and more\nName tag: workshop-backend\nIPv4 CIDR block: 10.0.0.0/16\nIPv6 CIDR block: No IPv6 CIDR block\nTenancy: Default\nNumber of Availability Zones (AZs): 2\nNumber of public subnets: 0\nNumber of private subnets: 4\nNAT gateways ($) - updated: None\nVPC Endpoints: None\nVerify your VPC structure under the Preview Click Create VPC\nWait a few seconds for the system to initialize your VPC. When finished, click View VPC\nYou will be redirected to your new VPC console Step 2: Create Security Groups Security groups act as virtual firewalls controlling inbound and outbound traffic.\n2.1 Create Security Group for VPC endpoint This security group is for a VPC endpoint required for our Lambda to access to Secrets Manager to fetch RDS secret. We will set up the endpoint in 5.2.4 AWS Secrets Manager Configuration\nIn the VPC console left navigation, click Security Groups Click Create security group Security group name: workshop-endpoint-sm-sg\nDescription: Security group for Secret Manager endpoint\nVPC: Select workshop-backend-vpc\nInbound rules:\nClick Add rule Type: HTTPS Protocol: TCP Port range: 443 Source: Custom Source: type in our VPC\u0026rsquo;s CIDR 10.0.0.0/16 Outbound rules:\nKeep default: All traffic (0.0.0.0/0) allowed Click Create security group 2.1 Create Security Group for Lambda In the VPC console left navigation, click Security Groups Click Create security group Security group name: workshop-lambda-sg\nDescription: Security group for Lambda functions\nVPC: Select workshop-backend-vpc\nInbound rules:\nClick Add rule Type: HTTPS Protocol: TCP Port range: 443 Source: Custom Source: Select the endpoint security group: workshop-endpoint-sm-sg Outbound rules:\nKeep default: All traffic (0.0.0.0/0) allowed This allows Lambda to: Connect to RDS Call AWS services (Secrets Manager, CloudWatch) Click Create security group 6.2 Create Security Group for RDS Click Create security group Security group name: workshop-rds-sg\nDescription: Security group for RDS database\nVPC: Select workshop-backend-vpc\nInbound rules:\nClick Add rule Type: PostgreSQL Protocol: TCP Port range: 5432 (auto-filled) Source: Custom Source: Select the Lambda security group: workshop-lambda-sg Start typing \u0026ldquo;workshop\u0026rdquo; to filter Select the SG ID (sg-xxxxxxxxxxxxx) What this does: Only allows PostgreSQL connections (port 5432) from resources that have the Lambda security group attached.\nOutbound rules:\nKeep default: All traffic allowed (for database maintenance) Click Create security group Security Group Best Practice:\nWe\u0026rsquo;re using security group references instead of IP addresses:\nMore flexible (no need to update if Lambda IP changes)\nMore secure (only Lambda with the correct SG can access)\nEasier to manage (add more Lambda functions without updating rules)\nStep 3: Verify Network Configuration Verify you have:\nVPC created with 10.0.0.0/16 CIDR 4 private subnets created: Private subnet 1 (10.0.128.0/20) in ap-southeast-1a Private subnet 2 (10.0.144.0/20) in ap-southeast-1b Private subnet 3 (10.0.160.0/20) in ap-southeast-1a Private subnet 4 (10.0.176.0/20) in ap-southeast-1b Lambda security group created (outbound all traffic) RDS security group created (inbound PostgreSQL from Lambda SG) Summary Congratulations! You\u0026rsquo;ve successfully:\nCreated a custom VPC with 4 private subnets with proper CIDR configuration Set up security groups for Lambda and RDS with proper rules Established secure network foundation for serverless backend Next Steps Proceed to Part 2: RDS Database Setup to create your PostgreSQL database within this secure VPC infrastructure.\nReady to continue? Your network foundation is now ready to host secure database and serverless compute resources! üéâ\n"},{"uri":"https://thienluhoan.github.io/workshop-template/1-worklog/1.10-week10/","title":"Week 10 Worklog","tags":[],"description":"","content":" ‚ö†Ô∏è Note: The following information is for reference purposes only. Please do not copy verbatim for your own report, including this warning.\nWeek 10 Objectives: Connect and get acquainted with members of First Cloud Journey. Understand basic AWS services, how to use the console \u0026amp; CLI. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Get acquainted with FCJ members - Read and take note of internship unit rules and regulations 08/11/2025 08/11/2025 3 - Learn about AWS and its types of services + Compute + Storage + Networking + Database + \u0026hellip; 08/12/2025 08/12/2025 https://cloudjourney.awsstudygroup.com/ 4 - Create AWS Free Tier account - Learn about AWS Console \u0026amp; AWS CLI - Practice: + Create AWS account + Install \u0026amp; configure AWS CLI + How to use AWS CLI 08/13/2025 08/13/2025 https://cloudjourney.awsstudygroup.com/ 5 - Learn basic EC2: + Instance types + AMI + EBS + \u0026hellip; - SSH connection methods to EC2 - Learn about Elastic IP 08/14/2025 08/15/2025 https://cloudjourney.awsstudygroup.com/ 6 - Practice: + Launch an EC2 instance + Connect via SSH + Attach an EBS volume 08/15/2025 08/15/2025 https://cloudjourney.awsstudygroup.com/ Week 10 Achievements: Understood what AWS is and mastered the basic service groups:\nCompute Storage Networking Database \u0026hellip; Successfully created and configured an AWS Free Tier account.\nBecame familiar with the AWS Management Console and learned how to find, access, and use services via the web interface.\nInstalled and configured AWS CLI on the computer, including:\nAccess Key Secret Key Default Region \u0026hellip; Used AWS CLI to perform basic operations such as:\nCheck account \u0026amp; configuration information Retrieve the list of regions View EC2 service Create and manage key pairs Check information about running services \u0026hellip; Acquired the ability to connect between the web interface and CLI to manage AWS resources in parallel.\n\u0026hellip;\n"},{"uri":"https://thienluhoan.github.io/workshop-template/1-worklog/1.11-week11/","title":"Week 11 Worklog","tags":[],"description":"","content":" ‚ö†Ô∏è Note: The following information is for reference purposes only. Please do not copy verbatim for your own report, including this warning.\nWeek 11 Objectives: Connect and get acquainted with members of First Cloud Journey. Understand basic AWS services, how to use the console \u0026amp; CLI. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Get acquainted with FCJ members - Read and take note of internship unit rules and regulations 08/11/2025 08/11/2025 3 - Learn about AWS and its types of services + Compute + Storage + Networking + Database + \u0026hellip; 08/12/2025 08/12/2025 https://cloudjourney.awsstudygroup.com/ 4 - Create AWS Free Tier account - Learn about AWS Console \u0026amp; AWS CLI - Practice: + Create AWS account + Install \u0026amp; configure AWS CLI + How to use AWS CLI 08/13/2025 08/13/2025 https://cloudjourney.awsstudygroup.com/ 5 - Learn basic EC2: + Instance types + AMI + EBS + \u0026hellip; - SSH connection methods to EC2 - Learn about Elastic IP 08/14/2025 08/15/2025 https://cloudjourney.awsstudygroup.com/ 6 - Practice: + Launch an EC2 instance + Connect via SSH + Attach an EBS volume 08/15/2025 08/15/2025 https://cloudjourney.awsstudygroup.com/ Week 11 Achievements: Understood what AWS is and mastered the basic service groups:\nCompute Storage Networking Database \u0026hellip; Successfully created and configured an AWS Free Tier account.\nBecame familiar with the AWS Management Console and learned how to find, access, and use services via the web interface.\nInstalled and configured AWS CLI on the computer, including:\nAccess Key Secret Key Default Region \u0026hellip; Used AWS CLI to perform basic operations such as:\nCheck account \u0026amp; configuration information Retrieve the list of regions View EC2 service Create and manage key pairs Check information about running services \u0026hellip; Acquired the ability to connect between the web interface and CLI to manage AWS resources in parallel.\n\u0026hellip;\n"},{"uri":"https://thienluhoan.github.io/workshop-template/1-worklog/1.12-week12/","title":"Week 12 Worklog","tags":[],"description":"","content":" ‚ö†Ô∏è Note: The following information is for reference purposes only. Please do not copy verbatim for your own report, including this warning.\nWeek 12 Objectives: Connect and get acquainted with members of First Cloud Journey. Understand basic AWS services, how to use the console \u0026amp; CLI. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Get acquainted with FCJ members - Read and take note of internship unit rules and regulations 08/11/2025 08/11/2025 3 - Learn about AWS and its types of services + Compute + Storage + Networking + Database + \u0026hellip; 08/12/2025 08/12/2025 https://cloudjourney.awsstudygroup.com/ 4 - Create AWS Free Tier account - Learn about AWS Console \u0026amp; AWS CLI - Practice: + Create AWS account + Install \u0026amp; configure AWS CLI + How to use AWS CLI 08/13/2025 08/13/2025 https://cloudjourney.awsstudygroup.com/ 5 - Learn basic EC2: + Instance types + AMI + EBS + \u0026hellip; - SSH connection methods to EC2 - Learn about Elastic IP 08/14/2025 08/15/2025 https://cloudjourney.awsstudygroup.com/ 6 - Practice: + Launch an EC2 instance + Connect via SSH + Attach an EBS volume 08/15/2025 08/15/2025 https://cloudjourney.awsstudygroup.com/ Week 12 Achievements: Understood what AWS is and mastered the basic service groups:\nCompute Storage Networking Database \u0026hellip; Successfully created and configured an AWS Free Tier account.\nBecame familiar with the AWS Management Console and learned how to find, access, and use services via the web interface.\nInstalled and configured AWS CLI on the computer, including:\nAccess Key Secret Key Default Region \u0026hellip; Used AWS CLI to perform basic operations such as:\nCheck account \u0026amp; configuration information Retrieve the list of regions View EC2 service Create and manage key pairs Check information about running services \u0026hellip; Acquired the ability to connect between the web interface and CLI to manage AWS resources in parallel.\n\u0026hellip;\n"},{"uri":"https://thienluhoan.github.io/workshop-template/5-workshop/5.1-frontend-deployment/5.1.3-cloudfront-setup/","title":"CloudFront Distribution Setup","tags":[],"description":"","content":"Overview In this section, you\u0026rsquo;ll configure Amazon CloudFront as a Content Delivery Network (CDN) in front of your S3 bucket. CloudFront will cache your content at edge locations around the world, providing faster load times for users regardless of their geographic location.\nWhat you\u0026rsquo;ll accomplish:\nCreate a CloudFront distribution Configure your S3 bucket as the origin Set up cache behaviors and optimization Configure SSL/TLS with HTTPS Update S3 bucket to restrict direct access Test your CloudFront distribution Estimated time: 45 minutes\nWhy CloudFront? Benefits over direct S3 access:\nPerformance: Content served from edge locations near your users (200+ locations worldwide) Security: HTTPS support, DDoS protection, and integration with AWS WAF Cost: Reduced S3 data transfer costs through caching Scalability: Handles traffic spikes automatically Custom Domains: Use your own domain name with SSL certificate Costs Considerations Free-tier: $0/month Paid-tier $15/month Overall: \u0026lt;$0 or \u0026lt;$1 if Pro (clean up immediately after finish workshop) Step 1: Create CloudFront Distribution 1.1 Navigate to CloudFront Console In the AWS Console search bar, type \u0026ldquo;CloudFront\u0026rdquo; Click on CloudFront under Services Click Create distribution 1.2 Step 1: Choose a plan For this workshop, we will continue with the free plan. Click Next 1.3 Step 2: Get started On this step, we will configure the name of the distribution Distribution name:\nSet as: workshop-frontend-cf Route 53 managed domain (optional):\nIf you already have a Route 53 managed domain, you can specify it here to use the domain instead of CloudFront\u0026rsquo;s generated domain\nLeave the rest as default\nClick Next\n1.4 Step 3: Specify origin Origin type:\nSelect Amazon S3 as origin Origin:\nClick on the Browse S3 button On the appeared modal, select the S3 bucket you created earlier in S3 Static Website Hosting tutorial. Then click Choose You will notice that there will be a warning appear. This is because we have configured our S3 Bucket for static website hosting. You should ignore it as we will disable S3 static website hosting in later steps Understanding the Warning:\nIn S3 Static Website Hosting, we configured the bucket for public access to enable S3 static website hosting. CloudFront has detected this configuration. That is why when you click the Use website endpoint, the URL in the textbox will appear in this format: [your-bucket-name].s3-website-[region].amazonaws.com, this is called the S3 website endpoint.\nWhile S3 static website hosting works well for direct access, it requires public bucket permissions that expose your content to anyone on the internet. A more secure approach is to keep your S3 bucket private and serve content exclusively through CloudFront using Origin Access Control (OAC). Using OAC requires the origin URL as the bucket endpoint, which has this format: [your-bucket-name].s3.[region].amazonaws.com\nWhy OAC is better:\nS3 bucket remains private (no public access) Content only accessible via CloudFront Better security posture Same functionality with improved protection We\u0026rsquo;ll implement this secure configuration in the following steps by switching from the S3 website endpoint to OAC, then disabling public access to the bucket.\nConfirm that the S3 origin URL has this format:\nFormat: [your-bucket-name].s3.[region].amazonaws.com Example: workshop-frontend-thien-bucket.s3.ap-southeast-1.amazonaws.com Origin path: Leave empty\nSettings:\nBe sure to check Allow private S3 bucket access to CloudFront - Recommended as this will allow OAC Leave the rest as default Click Next\n1.5 Step 4: Enable security By default, Web Application Firewall (WAF) is enabled. You should leave the settings in this step as they are. We will configure WAF in more details in later part of this workshop.\nClick Next\n1.6 Step 5: Review and create Review your CloudFront settings Click Create distribution when you are ready You will be redirected to the results page ‚è±Ô∏è Wait Time: CloudFront distribution deployment takes 5-15 minutes. While waiting, let\u0026rsquo;s proceed with configuring our S3 Bucket to support OAC\nStep 2: Secure Your S3 Bucket (Restrict Direct Access) Now that CloudFront is serving your content, let\u0026rsquo;s prevent users from bypassing CloudFront and accessing S3 directly.\n2.1 Navigate to Your S3 Bucket Go to S3 console Click on your bucket name Go to Permissions tab 2.2 Block Public Access Scroll to Block public access (bucket settings) Click Edit Check all four options: Block public access to buckets and objects granted through new access control lists (ACLs) Block public access to buckets and objects granted through any access control lists (ACLs) Block public access to buckets and objects granted through new public bucket or access point policies Block public access to buckets and objects granted through any public bucket or access point policies Click Save changes Type confirm when prompted Click Confirm 2.3 Update Bucket Policy Scroll to Bucket policy You will notice that permissions for CloudFront-only access policy was automatically created. Those permissions allow CloudFront to access our S3 Bucket We should now remove the PublicReadGetObject permission we created in S3 Static Website Hosting\nClick Edit\nDelete this statement:\n{ \u0026#34;Sid\u0026#34;: \u0026#34;PublicReadGetObject\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::[your-bucket-name]/*\u0026#34; } Click Save changes 2.4 Disable S3 Static Website Hosting From your Bucket, go to Properties tab Scroll down to Static website hosting section, click Edit Under Static website hosting, check Disable Click Save changes With this change, we will no longer be able to access our website via S3 website endpoint in S3 Static Website Hosting\nStep 3: View CloudFront Origin Settings (Optional) If you want, you can view CloudFront\u0026rsquo;s origin settings to better understand how CloudFront connect to our S3 Bucket\nGo to CloudFront console -\u0026gt; Distributions Select your newly-created distribution in the list Go to Origins tab Under Origins, select your origin S3 bucket. Then click Edit In the next screen, you will see the Origin\u0026rsquo;s settings. There are several notable settings: Origin domain: your S3 Bucket Endpoint Origin access: access method to the origin. Here you should see the option Origin access control settings (recommended) selected Origin access control: you should see an OAC created by CloudFront pre-selected. It should have name follow this format: oac-[your-bucket-name].s3.[region]-[random-string] You may also see the message \u0026ldquo;You must allow access to CloudFront using this policy statement. Learn more about giving CloudFront permission to access the S3 bucket\u0026rdquo;. This message means that you must add required policy statements in your S3 Bucket for CloudFront to access the S3 bucket you created in S3 Static Website Hosting tutorial to host the sample website. But as of 26/11/2025, in the CloudFront creation process, particularly 1.4 Step 3: Specify origin, we selected Allow private S3 bucket access to CloudFront - Recommended. This option will automatically insert required policy statements for CloudFront to access the S3 bucket, as we already saw in 2.3 Update Bucket Policy. So you can ignore this message.\nStep 3: Test Your CloudFront Distribution 3.1 Access via CloudFront Domain Go back to your Distribution\u0026rsquo;s page, on the top panel you will see your website\u0026rsquo;s endpoint under Distribution domain name. You can access this endpoint to go to you website Open a new browser tab Navigate to: https://[your-cloudfront-domain].cloudfront.net Example: https://d1234abcd.cloudfront.net Note: Use HTTPS, not HTTP Expected result:\nYour website loads successfully Browser shows connection is secure (HTTPS) Content loads from CloudFront, not S3 directly 3.2 Verify Direct S3 Access is Blocked Try accessing your old S3 website endpoint:\nExample: http://workshop-frontend-john-a1b2c3.s3-website-us-east-1.amazonaws.com Expected result:\n404 Not Found error This confirms S3 is now protected, the S3 Website Endpoint is no longer exists and our website is now only accessible via CloudFront 3.3 Test HTTPS Redirect Try accessing with HTTP: http://[your-cloudfront-domain].cloudfront.net Expected result:\nAutomatically redirects to HTTPS Browser URL changes to https://... 3.4 Check Response Headers Open browser Developer Tools (F12) Go to Network tab Refresh the page Click on the first request (usually the document) Look at Response Headers You should see:\nx-amz-cf-id: CloudFront request ID x-cache: Shows cache status (Miss from cloudfront, Hit from cloudfront, etc.) age: Time in seconds the object has been in the cache 3.5 Test From Different Locations (Optional) Use an online tool to test your site from multiple global locations:\nTools:\nhttps://www.webpagetest.org/ https://tools.pingdom.com/ https://www.dotcom-tools.com/website-speed-test What to look for:\nFast load times from various geographic locations CloudFront serving from nearby edge locations Step 4: Configure Custom Domain with Route 53 (Optional) Skip if you\u0026rsquo;re not using a custom domain.\n4.1 Update DNS Records If the domain name is purchased from an external DNS provider:\nGo to Route 53 console Click on your hosted zone Click Create hosted zone Configure: Domain name: your domain name Type: Public hosted zone Click Create hosted zone You will be redirected to the hosted zone page. Under Records, note the NS type nameservers (total 4 of them) Go to your external DNS provider. Find the Nameservers settings, then add 4 nameservers you got from Route 53 earlier Wait up to 24 hours for changes to propagate. In the meantime, let\u0026rsquo;s set up CloudFront to use the custom domain Go to your newly-created distribution page, under Alternate domain names, click Add domain Under Domains to serve, input the domain name that you purchased. Click Next On the next screen, click on Create certificate. A new SSL certificate will be created for you On the next screen, review changes then click Add domains Now you can access the sample website using the custom domain 4.2 Test Custom Domain Wait 5-10 minutes for DNS propagation Navigate to: https://www.yourdomain.com Expected result:\nYour website loads via your custom domain HTTPS works with your SSL certificate No certificate warnings 4.3 Verify DNS Propagation Use a DNS checker tool:\nhttps://dnschecker.org/ Enter your domain name Check that it resolves to your CloudFront distribution Step 5: Cache Invalidation When you update your website, CloudFront caches the old version. Learn how to clear the cache.\n5.1 Create an Invalidation Go to CloudFront console Click on your distribution ID Go to Invalidations tab Click Create invalidation 5.2 Specify Paths to Invalidate Object paths:\nFor all files:\n/* For specific files:\n/index.html /css/* /js/* For a single file:\n/index.html Click Create invalidation Note: Invalidations usually complete in 1-2 minutes\n5.3 Invalidation Costs First 1,000 invalidation paths per month: FREE After that: $0.005 per path Best practices:\nUse versioned filenames (e.g., main.abc123.js) to avoid frequent invalidations Invalidate only specific files when possible For complete rebuilds, /* is acceptable Step 6: Performance Verification 6.1 Test Loading Speed Open your website in an incognito/private window Open Developer Tools (F12) Go to Network tab Refresh the page Check the DOMContentLoaded and Load times at the bottom Good benchmarks:\nDOMContentLoaded: \u0026lt; 1 second Full page load: \u0026lt; 2 seconds First Contentful Paint: \u0026lt; 1 second 6.2 Check CloudFront Cache Hit Ratio Go to CloudFront console Click on your distribution Go to Monitoring tab Check the Cache hit rate graph Target: 80%+ cache hit rate after initial traffic\n6.3 Verify Compression In Developer Tools Network tab Click on a CSS or JS file request Look at Response Headers Verify content-encoding: gzip or content-encoding: br (brotli) File size comparison:\nWithout compression: ~100 KB With compression: ~25 KB (75% reduction) Troubleshooting Issue: CloudFront serves old/cached content after update Solution:\nCreate a cache invalidation for affected paths Or, implement cache-busting with versioned filenames Verify your build process generates unique filenames Issue: \u0026ldquo;The request could not be satisfied\u0026rdquo; error Causes:\nCloudFront can\u0026rsquo;t reach S3 origin Origin configuration incorrect S3 bucket policy blocking CloudFront Solution:\nCheck CloudFront origin settings point to correct S3 endpoint Verify S3 bucket policy allows CloudFront access Ensure Origin Access Control is configured correctly Check S3 bucket exists and has content Issue: SSL certificate not showing in CloudFront Solution:\nVerify certificate is in us-east-1 region Check certificate status is Issued (not Pending) Wait a few minutes and refresh the CloudFront page Ensure certificate covers the domains in CNAME settings Issue: Custom domain not working Solution:\nVerify DNS records are correct (CNAME pointing to CloudFront) Check DNS propagation with dnschecker.org Ensure SSL certificate includes your custom domain Wait up to 48 hours for full DNS propagation (usually much faster) Issue: \u0026ldquo;Access Denied\u0026rdquo; when accessing via CloudFront Solution:\nCheck S3 bucket policy includes correct distribution ARN Verify Origin Access Control is created and associated Ensure bucket policy allows CloudFront service principal Try creating a new cache invalidation Issue: Slow initial load, then fast subsequent loads This is expected behavior:\nFirst request: Cache miss, CloudFront fetches from S3 (slower) Subsequent requests: Cache hit, served from edge (fast) This is normal and improves with more traffic Summary Congratulations! You\u0026rsquo;ve successfully:\nCreated a CloudFront distribution Configured S3 as the origin Enabled HTTPS with SSL/TLS Secured S3 to only allow CloudFront access (Optional) Set up a custom domain Tested cache performance Learned cache invalidation What You\u0026rsquo;ve Achieved Your website now has:\nGlobal Distribution: Served from 200+ edge locations worldwide HTTPS Security: Encrypted traffic with SSL/TLS Better Performance: Reduced latency through caching DDoS Protection: Built-in AWS Shield Standard Cost Optimization: Reduced S3 data transfer costs Scalability: Automatic handling of traffic spikes Architecture So Far Internet Users ‚Üì CloudFront (HTTPS) ‚Üì S3 Bucket (Private) What\u0026rsquo;s Next In Part 3, we\u0026rsquo;ll configure AWS WAF to protect your application from:\nSQL injection attacks Cross-site scripting (XSS) Bot traffic and scraping Geographic restrictions Rate limiting Useful AWS CLI Commands:\n# Invalidate entire cache aws cloudfront create-invalidation \\ --distribution-id YOUR-DISTRIBUTION-ID \\ --paths \u0026#34;/*\u0026#34; # Invalidate specific paths aws cloudfront create-invalidation \\ --distribution-id YOUR-DISTRIBUTION-ID \\ --paths \u0026#34;/index.html\u0026#34; \u0026#34; /css/*\u0026#34; # Get distribution status aws cloudfront get-distribution \\ --id YOUR-DISTRIBUTION-ID \\ --query \u0026#34;Distribution.Status\u0026#34; # Update website and invalidate cd frontend npm run build aws s3 sync ./build/ s3://YOUR-BUCKET-NAME/ --delete aws cloudfront create-invalidation \\ --distribution-id YOUR-DISTRIBUTION-ID \\ --paths \u0026#34;/*\u0026#34; Ready to continue? Let\u0026rsquo;s proceed to Part 3: AWS WAF Configuration to add security protection!\n"},{"uri":"https://thienluhoan.github.io/workshop-template/5-workshop/5.2-serverless-backend/5.2.3-rds/","title":"RDS Database Setup","tags":[],"description":"","content":"Overview In this section, you\u0026rsquo;ll create an Amazon RDS PostgreSQL database instance within your VPC. The database will be deployed in a private subnet, making it inaccessible from the internet while still allowing your Lambda functions to connect securely.\nWhat you\u0026rsquo;ll accomplish:\nUnderstand RDS architecture and configuration options Create a DB subnet group for RDS deployment Configure and launch an RDS PostgreSQL instance Set up database parameters and options Create initial database schema and tables Verify database connectivity Understand RDS security and backup settings Estimated time: 35-40 minutes (includes 10-15 min database creation wait time)\nWhy Amazon RDS? Benefits Over Self-Managed Databases Managed Service:\nAutomated backups and point-in-time recovery Automated software patching and updates Monitoring and metrics built-in High availability options (Multi-AZ) Read replicas for scaling reads Operational Simplicity:\nNo server provisioning or OS management Easy scaling of compute and storage Automated failover for Multi-AZ deployments CloudWatch integration for monitoring Cost Efficiency:\nPay only for what you use Reserved instances for production workloads Storage auto-scaling available Understanding RDS Configuration Costs considerations For this workshop, we\u0026rsquo;ll use db.t3.micro:\n2 vCPUs, 1 GB RAM Burstable performance (suitable for dev/test) Free Tier eligible (750 hours/month for first 12 months) $0.017/hour (~$12.41/month) outside Free Tier Overall: $0 (free-tier) or \u0026lt;$2 (if clean up immediately after workshop) Single-AZ vs Multi-AZ Single-AZ (Workshop Setup):\nDatabase in one Availability Zone Lower cost Good for development/testing ~5 minutes downtime for maintenance Multi-AZ (Production):\nSynchronous replication to standby in different AZ Automatic failover (~1-2 minutes) Higher cost (~2x) Better for production workloads Storage Configuration Storage Type: General Purpose SSD (gp3)\nBalance of price and performance Burstable IOPS Suitable for most workloads Allocated Storage: 20 GB\nMinimum for PostgreSQL Free Tier includes 20 GB Can be increased later without downtime Step 1: Create DB Subnet Group RDS requires a DB subnet group that defines which subnets the database can be deployed in.\n1.1 Navigate to RDS Console In AWS Console search bar, type \u0026ldquo;RDS\u0026rdquo; Click on RDS under Services In the left navigation, click Subnet groups 1.2 Create DB Subnet Group Click Create DB subnet group Subnet group details:\nName: workshop-db-subnet-group\nDescription: Subnet group for workshop RDS database\nVPC: Select workshop-backend-vpc\n1.3 Add Subnets Availability Zones:\nSelect 2 availability zones that you create the subnets in the VPC setup in the previous section Select: ap-southeast-1a and ap-southeast-1b Subnets:\nSelect 2 private subnets, each from different Availability Zone: workshop-backend-subnet-private3-ap-southeast-1a workshop-backend-subnet-private4-ap-southeast-1b Why Two Subnets?\nEven though we\u0026rsquo;re deploying a single-AZ database, RDS requires the subnet group to have at least two subnets in different Availability Zones. This is an AWS requirement that:\nAllows easy migration to Multi-AZ later Provides flexibility for read replicas Ensures consistent configuration practices The database will only use one subnet (we\u0026rsquo;ll specify which one during instance creation).\n1.4 Create Subnet Group Click Create You should see success message Subnet group appears in the list with status Complete Step 2: Create RDS PostgreSQL Instance 2.1 Start Database Creation In RDS console left navigation, click Databases Click Create database 2.2 Choose Database Creation Method Database creation method:\nSelect Full configuration Provides full configuration options More control than Easy create 2.3 Engine Options Engine type:\nSelect PostgreSQL Engine Version:\nSelect PostgreSQL 17. (or latest available) Use default unless you need a specific version PostgreSQL Version:\nWe recommend PostgreSQL 17 or later for this workshop as it includes:\nBetter JSON support Improved performance Enhanced security features For production, choose an LTS (Long-Term Support) version and test your application thoroughly before upgrading.\n2.4 Templates Templates:\nSelect Sandbox (or Free tier if applicable) Availability and durability\nSelect Single-AZ DB instance deployment (1 instances) Multi-AZ for Production:\nFor production workloads, enable Multi-AZ deployment:\nAutomatic failover to standby instance\nSynchronous replication\n~1-2 minute failover time\n~2x cost of Single-AZ\nChange to Multi-AZ later with minimal downtime via database modification.\n2.5 Settings DB instance identifier: workshop-postgres-db\nThis is the name of your RDS instance Must be unique in your AWS account per region Credentials Settings:\nMaster username: postgres\nDefault PostgreSQL admin user Cannot be changed after creation Credentials management:\nSelect Managed in AWS Secrets Manager - most secure Under Select the encryption key, select aws/secretmanager(default) AWS Secrets Manager will generate and store our database credentials so that we don\u0026rsquo;t have to hardcode our secrets in the Lambda function that query our database\n2.6 Instance Configuration DB instance class:\nSelect Burstable classes (includes t classes) Select db.t3.micro 2 vCPUs, 1 GB RAM Free Tier eligible Sufficient for workshop and small applications 2.7 Storage Storage type:\nSelect General Purpose SSD (gp3) (if available) Or General Purpose SSD (gp2) (Free Tier default) Allocated storage: 20 GB\nMinimum for PostgreSQL Free Tier includes 20 GB Storage autoscaling:\nKeep Enable storage autoscaling checked Maximum storage threshold: 100 GB Database automatically grows if needed (charged for additional storage) 2.8 Connectivity Compute resource:\nSelect Don\u0026rsquo;t connect to an EC2 compute resource We\u0026rsquo;ll manually configure VPC settings Network type:\nKeep IPv4 selected Virtual private cloud (VPC):\nSelect workshop-backend-vpc DB subnet group:\nSelect workshop-db-subnet-group Public access:\nSelect No Database will not be accessible from internet Only accessible from within VPC VPC security group:\nSelect Choose existing Remove the default security group Select workshop-rds-sg (created in Part 1) Availability Zone:\nSelect ap-southeast-1a This matches where workshop-private-subnet-3 is located Why Specify Availability Zone?\nAlthough our DB subnet group includes both AZs, we\u0026rsquo;re explicitly choosing us-east-1b to ensure the database is created in workshop-private-subnet-3. This provides:\nPredictable placement for troubleshooting\nSame availability zone with our Lambda\u0026rsquo;s subnet Better organization of resources\n2.10 Database Authentication Database authentication:\nKeep Password authentication selected We\u0026rsquo;ll use username/password for simplicity Other options (not using in workshop):\nPassword and IAM database authentication: More secure, uses IAM roles Password and Kerberos authentication: For enterprise Active Directory integration 2.11 Monitoring Database Insights: select standard\nPerformance history will be retained for 7 days Turn on Performance Insights:\nKeep Enabled for this workshop This monitoring option shows the source of database load like SQL queries, so you can tune SQL statements or increase system resources. Enable Enhanced monitoring:\nKeep disabled for this workshop Provides OS-level metrics For production: Enable both for better observability.\n2.12 Additional Configuration Click Additional configuration to expand settings.\nDatabase options:\nInitial database name: workshopdb\nCreates a database upon instance creation If left empty, no database is created (you\u0026rsquo;d have to create it manually) DB parameter group:\nKeep default: default.postgres17 Option group:\nKeep default: default:postgres-17 Backup:\nEnable automated backups:\nKeep enabled Free within retention period Backup retention period: 7 days\nFree Tier includes backups up to DB instance storage size Sufficient for development/testing Backup window:\nSelect No preference (AWS chooses optimal time) Or select specific time if you have preferences Enable Backup replication:\nKeep disabled Replicates backups to another region (additional cost) Encryption:\nEnable encryption:\nKeep enabled (selected by default) Uses AWS KMS for encryption at rest No additional cost (uses AWS managed key) AWS KMS key:\nSelect (default) aws/rds AWS-managed key, no key management required Encryption Best Practice:\nAlways enable encryption for databases containing sensitive data:\nEncrypts data at rest\nEncrypts automated backups\nEncrypts read replicas\nCannot be disabled after creation\nMinimal performance impact\nMaintenance:\nEnable auto minor version upgrade:\nKeep enabled PostgreSQL minor version updates applied automatically Applied during maintenance window Recommended for security patches Maintenance window:\nSelect No preference Or choose specific time (e.g., weekends for production) Deletion protection:\nKeep disabled for this workshop Prevents accidental deletion Enable in production 2.13 Estimate Costs Before creating, review the estimated monthly cost:\nLocated at the bottom right of the page Free Tier estimate: $0 (within 750 hours/month) Outside Free Tier: ~$20-25/month for db.t3.micro 2.14 Create Database Review all settings Click Create database You\u0026rsquo;ll see a success banner Database creation time: 10-15 minutes\nStatus progression:\nCreating ‚Üí Backing-up ‚Üí Available Step 3: Monitor Database Creation 3.1 Check Status Stay in RDS console ‚Üí Databases Find your database: workshop-postgres-db Monitor the Status column Status indicators:\nCreating: Initial provisioning Backing-up: Initial automated backup Available: Ready to use 3.2 View Database Details Once status is Available:\nClick on the database identifier: workshop-postgres-db You\u0026rsquo;ll see detailed information Important information to note:\nEndpoint \u0026amp; port:\nEndpoint: workshop-postgres-db.xxxxxxxxxx.[region].rds.amazonaws.com Port: 5432 Copy the endpoint - you\u0026rsquo;ll need it for Lambda connections Connectivity \u0026amp; security:\nVPC: workshop-backend-vpc Subnets: Both private subnets Security groups: workshop-rds-sg Public accessibility: No Configuration:\nDB instance class: db.t3.micro Storage: 20 GB gp3 (or gp2) Multi-AZ: No RDS Best Practices Security Implemented in this workshop:\nDatabase in private subnet (no public access) Security group restricting access to Lambda only Encryption at rest enabled Secrets Manager for storing database credentials For production, also implement:\nIAM database authentication Secrets Manager with automatic rotation Enhanced monitoring and logging Regular security patches (auto minor version upgrade enabled) CloudWatch alarms for anomalies Performance Implemented:\nAppropriate instance class for workload gp3 storage for balanced performance Indexes on commonly queried columns For production, also consider:\nRead replicas for read-heavy workloads Connection pooling (RDS Proxy) Query performance insights Proper database configuration tuning Availability Implemented:\nAutomated backups (7-day retention) DB subnet group in multiple AZs For production, also implement:\nMulti-AZ deployment for automatic failover Cross-region read replicas for DR Longer backup retention (30 days) Backup replication to another region Cost Optimization Implemented:\nFree tier (if applicable) Right-sized instance (db.t3.micro) Single-AZ deployment Standard backup retention For production, also consider:\nReserved instances for predictable workloads (up to 69% savings) Stop database instances during non-business hours (dev/test) Storage autoscaling instead of over-provisioning Regular review of CloudWatch metrics Summary Congratulations! You\u0026rsquo;ve successfully:\nCreated a DB subnet group for RDS deployment Launched an RDS PostgreSQL database instance Configured the database in a private subnet Set up security groups for Lambda access Enabled encryption and automated backups Prepared database schema for application Obtained database endpoint for Lambda connections Next Steps Proceed to Part 3: AWS Secrets Manager Configuration to securely store and manage your database credentials.\nReady to continue? Your database is now ready to receive connections from Lambda functions! üéâ\n"},{"uri":"https://thienluhoan.github.io/workshop-template/3-blogstranslated/","title":"Translated Blogs","tags":[],"description":"","content":"Blog 1 - SportsCapital launches real-time event detection for sports trading powered by AWS This blog introduces how SportsCapital built a real-time event detection system for sports trading using AWS SageMaker and Amazon Bedrock. The system processes unstructured sports news and reports in real time using cloud pipelines and generative AI, helping sportsbooks quickly react to events like player injuries.\nBlog 2 - Introducing Upgraded Build Instances on Amplify Hosting This blog introduces how to start building a data lake in the healthcare sector by applying a microservices architecture. You will learn why data lakes are important for storing and analyzing diverse healthcare data (electronic medical records, lab test data, medical IoT devices‚Ä¶), how microservices help make the system more flexible, scalable, and easier to maintain. The article also guides you through the steps to set up the environment, organize the data processing pipeline, and ensure compliance with security \u0026amp; privacy standards such as HIPAA.\nBlog 3 - Enhanced Performance for Whisper Audio Transcription on AWS Batch and AWS Inferentia This blog introduces how to start building a data lake in the healthcare sector by applying a microservices architecture. You will learn why data lakes are important for storing and analyzing diverse healthcare data (electronic medical records, lab test data, medical IoT devices‚Ä¶), how microservices help make the system more flexible, scalable, and easier to maintain. The article also guides you through the steps to set up the environment, organize the data processing pipeline, and ensure compliance with security \u0026amp; privacy standards such as HIPAA.\n"},{"uri":"https://thienluhoan.github.io/workshop-template/5-workshop/5.2-serverless-backend/5.2.4-sercrets-manager/","title":"AWS Secrets Manager Configuration","tags":[],"description":"","content":"Overview In this section, you\u0026rsquo;ll configure AWS Secrets Manager to securely store your database credentials. Instead of hardcoding passwords in Lambda functions, you\u0026rsquo;ll retrieve them dynamically from Secrets Manager, following security best practices.\nWhat you\u0026rsquo;ll accomplish:\nUnderstand AWS Secrets Manager and its benefits Store RDS database credentials as a secret Configure secret structure for database connections Set up IAM permissions for Lambda to access secrets Test secret retrieval Understand secret rotation (optional configuration) Estimated time: 15-20 minutes\nWhy AWS Secrets Manager? Security Benefits Never Hardcode Credentials:\nCredentials stored encrypted at rest Access controlled via IAM policies Audit trail of who accessed secrets No credentials in application code or environment variables Automatic Rotation:\nPeriodic credential rotation without downtime Reduces risk of credential compromise Lambda functions automatically use new credentials Centralized Management:\nSingle source of truth for credentials Easy to update across multiple applications Version history of secret values Cost Considerations Pricing:\n$0.40 per secret per month $0.05 per 10,000 API calls VPC Endpoint (PrivateLink): $0.013/hour For this workshop:\n1 secret for database credentials Minimal API calls from Lambda Estimated cost: \u0026lt;$1 (assume clean up immediately after workshop) Step 1: View Database Secret In previous section - RDS Database Setup, during database creation, we have selected the option Managed in AWS Secrets Manager - most secure and used the default (aws/secretmanager(default)). This option create a RDS-managed secret for us. Let\u0026rsquo;s view it\n1.1 Navigate to Secrets Manager Console In AWS Console search bar, type \u0026ldquo;Secrets Manager\u0026rdquo; Click on Secrets Manager under Services 1.2 View Secret In the Secrets Manager dashboard, you will see the RDS-managed secret in the list 1.3 View Secret Details Click on your secret name You\u0026rsquo;ll see detailed information Secret ARN:\nCopy this ARN - you\u0026rsquo;ll need it for IAM policies Secret value (encrypted):\nClick Retrieve secret value to view 1.4 View rotation behavior Go to the Rotation tab You can see the rotation behaviors Rotation status: true - enabled Rotation schedule: 7 days - the secret will be rotated every 7 days Last rotated date and Next rotation data: dates indicate the last rotation and the next rotation Click Edit rotation to modify behavior On the Edit rotation configuration modal, you can see several notable settings: Automatic rotation: Enables or disables automatic password/secret rotation. When turned on, Secrets Manager will rotate the secret based on the schedule you define. Rotation schedule: Controls when and how often the secret is rotated. You can choose time unit and amount of time units for rotation You can select Schedule expression for complex rotation schedules Windows duration - optional: The amount of time (in hours) during which Secrets Manager is allowed to perform the rotation. This is often used to avoid maintenance windows or prevent rotations during peak hours. Rotate immediately when the secret is stored (checkbox) If checked, Secrets Manager will rotate the secret immediately after it is created or stored. After that, it follows the regular rotation schedule. Step 2: Create IAM Role for Lambda Access Lambda functions need permission to read this secret. We\u0026rsquo;ll create a custom IAM role for our Lambda function to assume.\n2.1 Navigate to IAM Console In AWS Console search bar, type \u0026ldquo;IAM\u0026rdquo; Click on IAM under Services In left navigation, click Roles 2.2 Create Role Click Create role 2.3 Select trusted entity Trusted entity type: select AWS service Service or use case: select Lambda Click Next 2.4 Add permissions Permission policies: In the search field, search and select AWSLambdaVPCAccessExecutionRole and SecretsManagerReadWrite Click Next 2.5 Name, review and create Role name: workshop-lamda-secretsmng-role Description: Allows Lambda functions to call Secrets Manager to fetch secrets. Understanding the IAM Role AWSLambdaVPCAccessExecutionRole { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34;, \u0026#34;ec2:CreateNetworkInterface\u0026#34;, \u0026#34;ec2:DescribeNetworkInterfaces\u0026#34;, \u0026#34;ec2:DeleteNetworkInterface\u0026#34;, \u0026#34;ec2:AssignPrivateIpAddresses\u0026#34;, \u0026#34;ec2:UnassignPrivateIpAddresses\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:logs:*:*:*\u0026#34; } Create and write to CloudWatch Log Groups Essential for debugging and monitoring Create ENIs (Elastic Network Interfaces) in VPC Required for Lambda to connect to RDS in private subnet Manages network connectivity SecretsManagerReadWrite This policy includes all permissions related to Secrets Manager and allow Lambda to reach Secrets Manager to connect to RDS instance\nHow Lambda Uses These Permissions Lambda Function Execution ‚Üì 1. Create ENI in VPC (VPCAccessExecutionRole) ‚Üì 2. Retrieve DB credentials (WorkshopLambdaSecretsPolicy) ‚Üì 3. Connect to RDS via ENI ‚Üì 4. Execute database queries ‚Üì 5. Write logs to CloudWatch (BasicExecutionRole) ‚Üì 6. Return response Security Best Practices Principle of Least Privilege:\nPolicy only grants read access (not write/delete) Scoped to specific secret (not all secrets) No wildcard permissions Resource-Based Restrictions:\nUses specific ARN pattern Can\u0026rsquo;t accidentally access other secrets Easier to audit and troubleshoot Step 3: Create VPC endpoint for Lambda function For a Lambda function reside inside a private subnet to access Secrets Manager secrets, it must go through a VPC endpoint. We\u0026rsquo;ll create a VPC endpoint now in VPC console\n3.1 Navigate to VPC Console In AWS Console search bar, type \u0026ldquo;VPC\u0026rdquo; Click on VPC under Services In left navigation, under PrivateLink and Lattice, click Endpoints Click Create Endpoint 3.2 Endpoint creation Name tag - optional: workshop-lambda-secretsmng-endpoint Type:: AWS services Services: in the search field, type secrets. You will see a service named com.amazonaws.[region].secretsmanager. Select it Network settings:\nVPC: select workshop-backend-vpc Subnet: Select the subnet that is inside the same availability zone as our RDS\u0026rsquo;s subnet Recall that in VPC and Network Setup) we decided to put Lambda in private subnet 1, RDS in private subnet 3, both reside in ap-southeast-1a availability zone In this case, we will select apse1-az2 (ap-southeast-1a) Subnet ID: select workshop-backend-subnet-private1-ap-southeast-1a Security groups: select workshop-endpoint-sm-sg security group that we created in VPC and Network Setup Policy: full access. This allows Lambda to use all Secrets Manager operations (allowed in the role we just created) through the endpoint Click Create endpoint\n3.3 Verify Endpoint Once status is Available:\nClick on the endpoint ID Note the DNS names - Lambda will use these automatically Verify Subnets shows workshop-private-subnet-1 Verify Security groups shows workshop-lambda-sg Cost Savings with VPC Endpoints:\nInterface VPC Endpoint costs: ~$7.20/month + $0.01/GB data processed\nWithout VPC Endpoint:\nLambda ‚Üí NAT Gateway ‚Üí Internet ‚Üí Secrets Manager NAT Gateway cost: ~$32/month + $0.045/GB With VPC Endpoint:\nLambda ‚Üí VPC Endpoint ‚Üí Secrets Manager (private) Lower latency, more secure, lower cost for high-traffic applications For this workshop with minimal traffic, the difference is small, but it demonstrates production best practices.\nSummary Congratulations! You\u0026rsquo;ve successfully:\nView RDS secret in detail in AWS Secrets Manager Created IAM role for Lambda to access the secret Created VPC endpoint for Lambda to read secrets in AWS Secrets Manager Next Steps Proceed to Part 4: Lambda Functions Development to create Lambda functions and connect the pieces together (VPC endpoint, Lambda role) that will use these secrets to connect to your RDS database.\nReady to continue? Your credentials are now securely stored and your Lambda functions will have proper permissions to access them! üîê\n"},{"uri":"https://thienluhoan.github.io/workshop-template/5-workshop/5.1-frontend-deployment/5.1.4-waf/","title":"AWS WAF Configuration","tags":[],"description":"","content":"Overview In this section, you\u0026rsquo;ll configure AWS WAF (Web Application Firewall) to protect your CloudFront distribution from common web exploits and malicious traffic. WAF provides a layer of security that inspects incoming requests and blocks those that match defined rules.\nWhat you\u0026rsquo;ll accomplish:\nUnderstand AWS WAF concepts and rule types View and understand WAF included with your CloudFront distribution Test and verify WAF protection Monitor blocked requests Estimated time: 45 minutes\nWhy AWS WAF? Protection against:\nSQL injection attacks: Prevents database compromise Cross-site scripting (XSS): Blocks malicious script injection Bot traffic: Filters automated requests and scrapers DDoS attacks: Rate limiting to prevent resource exhaustion Geographic restrictions: Block/allow traffic from specific countries Known bad inputs: Protects against common attack patterns Benefits:\nReal-time protection at the edge (CloudFront) Highly customizable rules Detailed logging and monitoring Pay only for what you use No infrastructure to manage Costs Considerations Free-tier: $0/month Paid-tier Resource Type Price Web ACL $5.00 per month (prorated hourly) Rule $1.00 per month (prorated hourly) Request $0.60 per 1 million requests Overall: $0 or \u0026lt; $1 if Paid-tier (assume immediate clean up after workshop) Understanding WAF Concepts Web ACL (Access Control List) A Web ACL is the core resource that contains all your security rules. It\u0026rsquo;s associated with your CloudFront distribution to inspect and filter traffic.\nRule Types 1. Managed Rules\nPre-configured rule sets maintained by AWS or AWS Marketplace sellers Regularly updated for new threats Easy to implement (no configuration needed) 2. Custom Rules\nRules you create for specific requirements Full control over match conditions and actions Useful for application-specific protection 3. Rule Groups\nCollections of related rules Can be managed rules or custom rule groups Evaluated in priority order Rule Actions Allow: Request passes through Block: Request is blocked (returns 403 Forbidden) Count: Request is counted but allowed (useful for testing) CAPTCHA: Presents a CAPTCHA challenge Challenge: Presents a silent browser challenge Rule Capacity Units (WCU) Each rule consumes a certain number of WCUs Maximum 1,500 WCUs per Web ACL Simple rules: 1-5 WCUs Complex managed rules: 50-100+ WCUs Step 1: Navigate to AWS WAF Console 1.1 Access WAF Service In the AWS Console search bar, type \u0026ldquo;WAF\u0026rdquo; Click on WAF \u0026amp; Shield under Services 1.2 Understand the Dashboard You\u0026rsquo;ll see:\nWeb ACLs: Your firewall configurations IP sets: Reusable IP address lists Regex pattern sets: Reusable regex patterns Rule groups: Custom rule collections Application integration Add-on protection Step 2: View a Web ACL 2.1 View the Web ACL created by CloudFront In the left navigation, click Protection packs (web ACLs) You can see a Web ACL created by CloudFront that you set up in Cloudfront Distribution Setup This WAF configuration is included as part of the CloudFront pricing Free plan for the distribution we created in Cloudfront Distribution Setup\nClick the Web ACL name to open a sidebar to view actions You can view which CloudFront distribution created the Web ACL in the sidebar Click Manage details, here we can see the properties and behavior of this protection pack Click Download protection pack (web ACL) as JSON. Then open it to see the web ACL You can view the sample Web ACL JSON and explanation in this section Under Protection pack (web ACL) behavior, you can modify Default action, if set to allow, allow all requests that are not caught by web ACL rules, and vice versa Under Challenge configurations is for adjusting challenges (CAPTCHA) behaviors like default immunity time (time before having to solve next CAPTCHA) or token domains (for persisting challenge immunity between domains) Custom response: customize what is returned in the response when requests are blocked Back to the main page, click Manage rules On this page, you can see existing rules which was created along with CloudFront Click on a rule to manage: Inspection: apply rule to All requests or requests that Match statement All requests: the Override rule groups checkbox if checked, the entire rule group will primarily operate in Count mode. Rules that in Block mode will stop blocking, instead, they only count requests that match criteria Match statement: define criteria to block requests, such as IP block or Geo-block Click the Add rule button to add a rule You can choose between Custom rule and AWS Managed rule groups In custom rule, you can create criteria such as IP-based rule (IP block), Geo-based rule (Location block), Rate-based rule (Rate limiting) and Custom rule (combining with logical operators) For example, let\u0026rsquo;s create a Rate-based rule, if there are more than 1000 requests within 5 minutes, block all subsequent requests after the 1000th Click the Edit rule order to modify order of rules Higher rules will block all requests without them to access lower rules Let\u0026rsquo;s modify our new Rate-based rule to be the highest Drag the new rule to the top, then click Save rule order We will test this rule in the next step (Step 3) Back to the main page, click Manage resources\nOn this section, we can modify which AWS resources for this web ACL to protect. Free-tier CloudFront associated web ACL can not be assigned to other resources or un-assigned from its designated CloudFront distribution We will cover View dashboard, logs and sampled requests and Configure logging and sampled requests sections later\nStep 3: Test WAF Protection 3.1 Test Normal Access Open your website: https://[your-cloudfront-domain].cloudfront.net Navigate through different pages Verify the site works normally Expected result: Site loads without issues\n3.2 Test SQL Injection Protection Try accessing your site with a SQL injection pattern in the URL:\nhttps://[your-cloudfront-domain].cloudfront.net/?id=1\u0026#39; OR \u0026#39;1\u0026#39;=\u0026#39;1 Expected result:\n403 Forbidden error Request blocked by WAF 3.3 Test XSS Protection Try accessing with a cross-site scripting pattern:\nhttps://[your-cloudfront-domain].cloudfront.net/?search=\u0026lt;script\u0026gt;alert(\u0026#39;xss\u0026#39;)\u0026lt;/script\u0026gt; Expected result:\n403 Forbidden error Request blocked by WAF 3.4 Test Rate Limiting You can test rate limiting rule we created earlier with a simple script or tool:\nUsing curl (bash/terminal):\n$url = \u0026#34;https://d3b2qa4f4hqtdb.cloudfront.net/\u0026#34; $count = 1100 # Loop from 1 to 1100 for ($i = 1; $i -le $count; $i++) { # Invoke-WebRequest sends the request # -Uri specifies the URL $response = Invoke-WebRequest -Uri $url -Method GET -MaximumRedirection 0 -TimeoutSec 10 -ErrorAction SilentlyContinue | Select-Object -First 1 # Check if a response object was returned if ($response -ne $null) { # Output the HTTP Status Code $response.StatusCode } else { # Output a message if the request failed \u0026#34;Request failed or timed out\u0026#34; } } Expected result:\nFirst ~1,000 requests: HTTP 200 After 1,000 requests: HTTP 403 Rate limit triggered Testing Rate Limits:\nThe rate limit counts requests over a 5-minute window. After being blocked, wait 5 minutes for the counter to reset. In production, set appropriate limits based on your expected traffic patterns:\nPublic websites: 2,000-10,000 requests per 5 minutes\nAPIs: 100-1,000 requests per 5 minutes (depends on use case)\nAdmin panels: 50-100 requests per 5 minutes\n3.5 Alternative: Use Browser Developer Tools For simpler testing without scripts:\nOpen Developer Tools (F12) Go to Network tab Rapidly refresh the page multiple times (Hold Ctrl+R or Cmd+R) After 2,000+ requests, you should see 403 responses Step 8: Monitor WAF Activity 8.1 View Web ACL Overview Go to AWS WAF -\u0026gt; Protection packs (web ACLs) Click on View under the Dashboard column Or you can click the Web ACL name and in the sidebar, click View dashboard, logs and sampled requests You\u0026rsquo;ll see the Dashboard Metrics shown:\nTotal: total requests received Allowed requests: Requests that passed all rules Blocked requests: Requests blocked by rules CAPTCHA: Requests that were matched by a rule and presented with a visual or audio puzzle requiring human interaction to solve. Challenged: Requests that were matched by a rule and subjected to a silent browser interrogation 8.2 Analyze Protection pack (web ACL) activity Scroll down to Protection pack (web ACL) activity section You\u0026rsquo;ll see a graph displaying requests handled by each rule. Hover on each section to see detailed count of allowed, blocked\u0026hellip; requests of each rule 8.3 Analyze overview Scroll down to the bottom, you can see charts, you can select criteria to filter data for the chart such as: Request locations Type of attacks Client devices Rules characteristics\u0026hellip; Useful for:\nIdentifying attack patterns Understanding traffic trends Setting up alarms for unusual activity Step 9: Create CloudWatch Alarms (Optional) To follow this section, you must upgrade your CloudFront to Pro-tier. You will be charged $15/month in Pro-tier and you can only switch back to free-tier after 5 days. Furthermore, you can only delete your Pro-tier distribution after the first billing cycle\n9.1 Enable logging destination in WAF Go to WAF console -\u0026gt; Protection packs (web ACLs) In your web ACL, under Logging \u0026amp; metrics, you should see that it is Not enabled, click on Not enabled -\u0026gt; Configure to configure logging On the next screen, under Logging, click Enable, then select Logging destination On the sidebar that appeared, under Amazon Cloudwatch Logs log group, you can use existing log groups and create a new one. We will create and use a log group called aws-waf-logs-workshop1, then click Create Back to Logging destination sidebar, select you newly-created log groups Then click Save 9.1 Set Up Blocked Request Alarm Go to CloudWatch console Click Alarms -\u0026gt; All alarms in the left navigation Click Create alarm Configure alarm:\nSelect metric:\nClick Select metric You should see WAFV2 in the list, click on it to show list of metrics Select any metrics you want to create an alarm for. I will create one for XSS Blocked attacks: click ManagedRuleGroup, ManagedRuleGroupRule, WebACL, then select AWSManagedRulesCommonRuleSet, then click Select metric Click Select metric Specify conditions:\nStatistic: Sum Period: 5 minutes Threshold type: Static Whenever BlockedRequests is: Greater than 2 This triggers when more than 2 requests are blocked in 5 minutes Configure actions:\nChoose to create In alarm Click Create new topic (for SNS notification) Topic name: Default_CloudWatch_Alarms_Topic Email: Enter your email address Click Create topic You will now see you topic selected Click Next Alarm name:\nName: WAF-High-Blocked-Requests Description: Alert when WAF blocks more than 100 requests in 5 minutes Click Create alarm 9.2 Confirm SNS Subscription Check your email Click the confirmation link in the SNS subscription email You\u0026rsquo;ll start receiving alerts when the alarm triggers 9.3 Test alarm Now let\u0026rsquo;s simulate a XSS attack 2 more times to trigger the alarm\nTry accessing with a cross-site scripting pattern:\nhttps://[your-cloudfront-domain].cloudfront.net/?search=\u0026lt;script\u0026gt;alert(\u0026#39;xss\u0026#39;)\u0026lt;/script\u0026gt; Step 10: Fine-Tune Rules (Optional) 10.1 Handle False Positives If legitimate requests are being blocked:\nGo to WAF console Click on your Web ACL Click Rules tab Find the rule causing false positives (check sampled requests) Options:\nOption 1: Set rule to Count mode\nClick Edit on the rule group Click Override all rule actions Select Count This logs matches without blocking (testing mode) Option 2: Exclude specific rules\nClick Edit on the rule group Expand Rules Find the problematic rule Select Override to Count for that specific rule Option 3: Add scope-down statement\nClick Edit on the rule group Add conditions to narrow when the rule applies Example: Only apply to specific paths or query parameters Troubleshooting Issue: Legitimate requests being blocked (False Positives) Solution:\nCheck sampled requests to identify which rule is blocking Set that specific rule to Count mode temporarily Add scope-down statements to narrow rule application Or exclude specific sub-rules causing issues Issue: WAF not blocking test attacks Causes:\nWAF still deploying to edge locations (wait 5 minutes) Rule priority incorrect Rule set to Count instead of Block Solution:\nVerify Web ACL status is Active Check rule actions are set to Block Verify CloudFront association is complete Check rule priority order Clear CloudFront cache and test again Issue: Cannot see Web ACL in CloudFront Solution:\nEnsure you created WAF in Global (CloudFront) region Regional WAF (for ALB/API Gateway) won\u0026rsquo;t appear for CloudFront Recreate Web ACL in correct region if needed Issue: Rate limit not working Solution:\nVerify rate limit rule is enabled and priority is correct Check you\u0026rsquo;re testing from same IP (different IPs have separate counters) Remember rate limit is per 5-minute window Test with enough requests (e.g., 2,100+ for 2,000 limit) Issue: High WAF costs Solution:\nReview which managed rules you actually need Consider using fewer rule groups Use custom rules instead of multiple managed rules where possible Remove Web ACL when not actively using Summary Congratulations! You\u0026rsquo;ve successfully:\nCreated an AWS WAF Web ACL Configured AWS managed rule groups for protection Set up custom rate limiting rules Associated WAF with CloudFront Tested and verified WAF protection Learned to monitor and troubleshoot WAF activity (Optional) Set up logging and CloudWatch alarms What You\u0026rsquo;ve Achieved Your application is now protected against:\nSQL injection attacks: Database exploitation attempts blocked Cross-site scripting (XSS): Malicious script injection prevented Known bad inputs: Invalid and malicious patterns filtered Rate-based attacks: Automated abuse and DDoS mitigated IP reputation threats: Known malicious IPs blocked Complete Architecture Internet Users ‚Üì AWS WAF (Security Rules) ‚Üì CloudFront (HTTPS + Caching) ‚Üì S3 Bucket (Private, Static Content) Security Layers Now in Place Network Layer: CloudFront with DDoS protection (AWS Shield Standard) Application Layer: AWS WAF with managed rules and rate limiting Transport Layer: HTTPS encryption with SSL/TLS Storage Layer: Private S3 bucket with OAC Best Practices Summary For Production:\nStart with managed rule groups for baseline protection Use Count mode to test rules before blocking Monitor sampled requests regularly for false positives Set up CloudWatch alarms for unusual activity Enable logging for audit and compliance Review and update rules based on traffic patterns Use IP sets for dynamic allow/block lists Implement appropriate rate limits for your use case Document rule changes and exceptions Security Monitoring:\nCheck WAF dashboard weekly Review blocked requests for attack patterns Investigate spikes in blocked traffic Update rules as new threats emerge Keep managed rules enabled for auto-updates Next Steps You\u0026rsquo;ve completed the frontend deployment! Your static website is now:\nGlobally distributed with CloudFront Protected by AWS WAF Served over HTTPS Secured with private S3 access Proceed to Workshop 2 to build the backend:\nAPI Gateway for RESTful APIs Lambda functions for business logic RDS for database storage Cognito for user authentication Secrets Manager for credentials Useful Commands:\n# Get Web ACL details aws wafv2 get-web-acl \\ --scope CLOUDFRONT \\ --id YOUR-WEBACL-ID \\ --name workshop-frontend-waf # List Web ACLs aws wafv2 list-web-acls \\ --scope CLOUDFRONT # Get sampled requests aws wafv2 get-sampled-requests \\ --web-acl-arn YOUR-WEBACL-ARN \\ --rule-metric-name RateLimitRule \\ --scope CLOUDFRONT \\ --time-window StartTime=1234567890,EndTime=1234567900 \\ --max-items 100 # Update rule action to Count (testing) aws wafv2 update-web-acl \\ --scope CLOUDFRONT \\ --id YOUR-WEBACL-ID \\ --name workshop-frontend-waf \\ --default-action Allow={} \\ # ... (additional parameters) WAF Dashboard URLs:\nWeb ACL Overview: https://console.aws.amazon.com/wafv2/homev2/web-acl/workshop-frontend-waf/ CloudWatch Metrics: https://console.aws.amazon.com/cloudwatch/home?region=us-east-1#metricsV2:query=~(metricName~'BlockedRequests) Congratulations! You\u0026rsquo;ve successfully deployed and secured a production-ready serverless frontend application on AWS! üéâ\nUnderstanding Web ACL JSON { \u0026#34;ARN\u0026#34;: \u0026#34;arn:aws:wafv2:us-east-1:362324939369:global/webacl/CreatedByCloudFront-cf37def6/78a29ce4-287f-47a4-b108-886bfc3ae748\u0026#34;, \u0026#34;Capacity\u0026#34;: 925, \u0026#34;DefaultAction\u0026#34;: { \u0026#34;Allow\u0026#34;: {} }, \u0026#34;Description\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;78a29ce4-287f-47a4-b108-886bfc3ae748\u0026#34;, \u0026#34;LabelNamespace\u0026#34;: \u0026#34;awswaf:362324939369:webacl:CreatedByCloudFront-cf37def6:\u0026#34;, \u0026#34;ManagedByFirewallManager\u0026#34;: false, \u0026#34;Name\u0026#34;: \u0026#34;CreatedByCloudFront-cf37def6\u0026#34;, \u0026#34;OnSourceDDoSProtectionConfig\u0026#34;: { \u0026#34;ALBLowReputationMode\u0026#34;: \u0026#34;ACTIVE_UNDER_DDOS\u0026#34; }, \u0026#34;RetrofittedByFirewallManager\u0026#34;: false, \u0026#34;Rules\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;AWS-AWSManagedRulesAmazonIpReputationList\u0026#34;, \u0026#34;OverrideAction\u0026#34;: { \u0026#34;None\u0026#34;: {} }, \u0026#34;Priority\u0026#34;: 0, \u0026#34;Statement\u0026#34;: { \u0026#34;ManagedRuleGroupStatement\u0026#34;: { \u0026#34;Name\u0026#34;: \u0026#34;AWSManagedRulesAmazonIpReputationList\u0026#34;, \u0026#34;VendorName\u0026#34;: \u0026#34;AWS\u0026#34; } }, \u0026#34;VisibilityConfig\u0026#34;: { \u0026#34;CloudWatchMetricsEnabled\u0026#34;: true, \u0026#34;MetricName\u0026#34;: \u0026#34;AWS-AWSManagedRulesAmazonIpReputationList\u0026#34;, \u0026#34;SampledRequestsEnabled\u0026#34;: true } }, { \u0026#34;Name\u0026#34;: \u0026#34;AWS-AWSManagedRulesCommonRuleSet\u0026#34;, \u0026#34;OverrideAction\u0026#34;: { \u0026#34;None\u0026#34;: {} }, \u0026#34;Priority\u0026#34;: 1, \u0026#34;Statement\u0026#34;: { \u0026#34;ManagedRuleGroupStatement\u0026#34;: { \u0026#34;Name\u0026#34;: \u0026#34;AWSManagedRulesCommonRuleSet\u0026#34;, \u0026#34;VendorName\u0026#34;: \u0026#34;AWS\u0026#34; } }, \u0026#34;VisibilityConfig\u0026#34;: { \u0026#34;CloudWatchMetricsEnabled\u0026#34;: true, \u0026#34;MetricName\u0026#34;: \u0026#34;AWS-AWSManagedRulesCommonRuleSet\u0026#34;, \u0026#34;SampledRequestsEnabled\u0026#34;: true } }, { \u0026#34;Name\u0026#34;: \u0026#34;AWS-AWSManagedRulesKnownBadInputsRuleSet\u0026#34;, \u0026#34;OverrideAction\u0026#34;: { \u0026#34;None\u0026#34;: {} }, \u0026#34;Priority\u0026#34;: 2, \u0026#34;Statement\u0026#34;: { \u0026#34;ManagedRuleGroupStatement\u0026#34;: { \u0026#34;Name\u0026#34;: \u0026#34;AWSManagedRulesKnownBadInputsRuleSet\u0026#34;, \u0026#34;VendorName\u0026#34;: \u0026#34;AWS\u0026#34; } }, \u0026#34;VisibilityConfig\u0026#34;: { \u0026#34;CloudWatchMetricsEnabled\u0026#34;: true, \u0026#34;MetricName\u0026#34;: \u0026#34;AWS-AWSManagedRulesKnownBadInputsRuleSet\u0026#34;, \u0026#34;SampledRequestsEnabled\u0026#34;: true } } ], \u0026#34;VisibilityConfig\u0026#34;: { \u0026#34;CloudWatchMetricsEnabled\u0026#34;: true, \u0026#34;MetricName\u0026#34;: \u0026#34;CreatedByCloudFront-cf37def6\u0026#34;, \u0026#34;SampledRequestsEnabled\u0026#34;: true } } ARN (Amazon Resource Name) \u0026#34;ARN\u0026#34;: \u0026#34;arn:aws:wafv2:us-east-1:362324939369:global/webacl/CreatedByCloudFront-cf37def6/78a29ce4-287f-47a4-b108-886bfc3ae748\u0026#34; What it is: A unique identifier for your Web ACL across all of AWS.\nBreaking down the ARN:\nwafv2: Service (AWS WAF version 2) us-east-1: Region where metadata is stored (all CloudFront WAF uses us-east-1) 362324939369: Your AWS Account ID global: Scope (CloudFront resources are global) webacl: Resource type CreatedByCloudFront-cf37def6: Web ACL name 78a29ce4-287f-47a4-b108-886bfc3ae748: Unique Web ACL ID Capacity \u0026#34;Capacity\u0026#34;: 925 What it means: This Web ACL is using 925 out of the maximum 1,500 Web ACL Capacity Units (WCUs).\nCapacity breakdown:\nAmazon IP Reputation List: ~25 WCUs Common Rule Set: ~700 WCUs Known Bad Inputs: ~200 WCUs Total: 925 WCUs Remaining capacity: 575 WCUs (you can add more rules) About WCU Capacity: Each rule and managed rule group consumes WCUs based on its complexity. The 1,500 WCU limit ensures optimal performance. If you need more capacity, you can:\nRemove unused rules\nCreate multiple Web ACLs for different distributions\nUse custom rule groups to optimize capacity usage\nDefault Action \u0026#34;DefaultAction\u0026#34;: { \u0026#34;Allow\u0026#34;: {} } What it means: Requests that don\u0026rsquo;t match any rules are allowed by default.\nThis is the recommended approach because:\nRules explicitly block malicious traffic Legitimate traffic passes through by default Reduces risk of blocking valid users Alternative: Setting default action to \u0026ldquo;Block\u0026rdquo; would require explicit Allow rules for all legitimate traffic (not recommended for most use cases).\nID and Name \u0026#34;Id\u0026#34;: \u0026#34;78a29ce4-287f-47a4-b108-886bfc3ae748\u0026#34;, \u0026#34;Name\u0026#34;: \u0026#34;CreatedByCloudFront-cf37def6\u0026#34; ID: Unique identifier used in API calls Name: Human-readable name (auto-generated if created via CloudFront console) Label Namespace \u0026#34;LabelNamespace\u0026#34;: \u0026#34;awswaf:362324939369:webacl:CreatedByCloudFront-cf37def6:\u0026#34; What it is: A prefix for labels applied by rules in this Web ACL.\nLabels are tags that rules can add to requests. Other rules can then match on these labels for advanced logic. For example:\nOne rule labels a request as \u0026ldquo;suspicious\u0026rdquo; Another rule blocks all \u0026ldquo;suspicious\u0026rdquo; labeled requests Firewall Manager Settings \u0026#34;ManagedByFirewallManager\u0026#34;: false, \u0026#34;RetrofittedByFirewallManager\u0026#34;: false What it means: This Web ACL is not managed by AWS Firewall Manager.\nAWS Firewall Manager is a service for centrally managing security policies across multiple AWS accounts. Since these are false:\nYou have full control to modify this Web ACL Changes won\u0026rsquo;t be overridden by organizational policies You\u0026rsquo;re managing security at the individual account level DDoS Protection Configuration \u0026#34;OnSourceDDoSProtectionConfig\u0026#34;: { \u0026#34;ALBLowReputationMode\u0026#34;: \u0026#34;ACTIVE_UNDER_DDOS\u0026#34; } What it is: Configuration for how WAF handles traffic from low-reputation sources during DDoS attacks.\nACTIVE_UNDER_DDOS mode:\nDuring normal operations: All traffic processed normally During active DDoS attack: WAF applies additional scrutiny to requests from IPs with low reputation scores This provides an extra layer of protection when your application is under attack About AWS Shield: This configuration works in conjunction with AWS Shield Standard, which is automatically included with CloudFront at no extra cost. Shield Standard provides:\nDDoS protection at network and transport layers\nAutomatic detection and mitigation\nAlways-on protection\nFor enhanced protection, you can upgrade to AWS Shield Advanced (additional cost).\nRules Configuration Your Web ACL contains 3 managed rule groups, evaluated in priority order (0 ‚Üí 1 ‚Üí 2).\nRule 1: Amazon IP Reputation List (Priority 0) { \u0026#34;Name\u0026#34;: \u0026#34;AWS-AWSManagedRulesAmazonIpReputationList\u0026#34;, \u0026#34;Priority\u0026#34;: 0, \u0026#34;Statement\u0026#34;: { \u0026#34;ManagedRuleGroupStatement\u0026#34;: { \u0026#34;Name\u0026#34;: \u0026#34;AWSManagedRulesAmazonIpReputationList\u0026#34;, \u0026#34;VendorName\u0026#34;: \u0026#34;AWS\u0026#34; } }, \u0026#34;OverrideAction\u0026#34;: { \u0026#34;None\u0026#34;: {} }, \u0026#34;VisibilityConfig\u0026#34;: { \u0026#34;CloudWatchMetricsEnabled\u0026#34;: true, \u0026#34;MetricName\u0026#34;: \u0026#34;AWS-AWSManagedRulesAmazonIpReputationList\u0026#34;, \u0026#34;SampledRequestsEnabled\u0026#34;: true } } What it does:\nBlocks requests from IP addresses known for malicious activity AWS maintains a constantly updated list of bad IPs based on threat intelligence Includes IPs associated with: Botnets Spam campaigns Malware distribution DDoS attacks Priority 0: Evaluated first - if a request comes from a known bad IP, it\u0026rsquo;s blocked immediately without checking other rules.\nOverrideAction: None:\nUses the default action defined in the managed rule group (Block) No overrides applied All rules within this group remain active VisibilityConfig:\nCloudWatchMetricsEnabled: true - Metrics sent to CloudWatch MetricName - Used in CloudWatch for filtering/alerting SampledRequestsEnabled: true - Stores sample requests for analysis in WAF console Rule 2: Common Rule Set (Priority 1) { \u0026#34;Name\u0026#34;: \u0026#34;AWS-AWSManagedRulesCommonRuleSet\u0026#34;, \u0026#34;Priority\u0026#34;: 1, \u0026#34;Statement\u0026#34;: { \u0026#34;ManagedRuleGroupStatement\u0026#34;: { \u0026#34;Name\u0026#34;: \u0026#34;AWSManagedRulesCommonRuleSet\u0026#34;, \u0026#34;VendorName\u0026#34;: \u0026#34;AWS\u0026#34; } }, \u0026#34;OverrideAction\u0026#34;: { \u0026#34;None\u0026#34;: {} }, \u0026#34;VisibilityConfig\u0026#34;: { \u0026#34;CloudWatchMetricsEnabled\u0026#34;: true, \u0026#34;MetricName\u0026#34;: \u0026#34;AWS-AWSManagedRulesCommonRuleSet\u0026#34;, \u0026#34;SampledRequestsEnabled\u0026#34;: true } } What it does:\nProvides broad protection against common web exploits Based on OWASP Top 10 vulnerabilities Protects against: Cross-Site Scripting (XSS): Malicious script injection Local File Inclusion (LFI): Unauthorized file access Remote File Inclusion (RFI): Loading external malicious files Command Injection: OS command execution attempts Path Traversal: Directory traversal attacks (e.g., ../../etc/passwd) SQL Injection: Basic SQL injection patterns Session Fixation: Session hijacking attempts Priority 1: Evaluated after IP reputation check. If the request passes the IP check, it\u0026rsquo;s then inspected for common attack patterns.\nWhy it\u0026rsquo;s important:\nThis is the most comprehensive rule group Covers the majority of common web attacks Regularly updated by AWS security team Uses 700 WCUs (the largest rule group) Rule 3: Known Bad Inputs (Priority 2) { \u0026#34;Name\u0026#34;: \u0026#34;AWS-AWSManagedRulesKnownBadInputsRuleSet\u0026#34;, \u0026#34;Priority\u0026#34;: 2, \u0026#34;Statement\u0026#34;: { \u0026#34;ManagedRuleGroupStatement\u0026#34;: { \u0026#34;Name\u0026#34;: \u0026#34;AWSManagedRulesKnownBadInputsRuleSet\u0026#34;, \u0026#34;VendorName\u0026#34;: \u0026#34;AWS\u0026#34; } }, \u0026#34;OverrideAction\u0026#34;: { \u0026#34;None\u0026#34;: {} }, \u0026#34;VisibilityConfig\u0026#34;: { \u0026#34;CloudWatchMetricsEnabled\u0026#34;: true, \u0026#34;MetricName\u0026#34;: \u0026#34;AWS-AWSManagedRulesKnownBadInputsRuleSet\u0026#34;, \u0026#34;SampledRequestsEnabled\u0026#34;: true } } What it does:\nBlocks requests with patterns that are known to be invalid or exploits Focuses on malformed inputs that should never occur in legitimate traffic Protects against: Malformed request patterns: Requests that violate HTTP standards Invalid characters: Special characters in unexpected places Known exploit patterns: Signatures of well-known vulnerabilities CVE exploits: Patterns matching published Common Vulnerabilities and Exposures Priority 2: Last line of defense. If a request passes IP reputation and common rule checks, this rule group catches any remaining known malicious patterns.\nWhy it\u0026rsquo;s useful:\nVery low false positive rate (rarely blocks legitimate traffic) Catches exploit attempts targeting specific vulnerabilities Complements the Common Rule Set with more specific patterns How Rules are Evaluated Evaluation Flow Request arrives ‚Üì Priority 0: IP Reputation Check ‚îú‚îÄ Match ‚Üí Block (403 Forbidden) ‚îî‚îÄ No match ‚Üí Continue ‚Üì Priority 1: Common Rule Set ‚îú‚îÄ Match ‚Üí Block (403 Forbidden) ‚îî‚îÄ No match ‚Üí Continue ‚Üì Priority 2: Known Bad Inputs ‚îú‚îÄ Match ‚Üí Block (403 Forbidden) ‚îî‚îÄ No match ‚Üí Continue ‚Üì Default Action: Allow ‚Üì Request forwarded to CloudFront Key Points First match wins: When a rule matches, its action is taken immediately (if it\u0026rsquo;s a Block action) Priority matters: Lower numbers are evaluated first (0 before 1 before 2) Managed rules are efficient: Even with 700 WCUs, the Common Rule Set evaluates very quickly Default action only applies if no rules match: Most requests will either match a rule or reach the default Allow Visibility and Monitoring \u0026#34;VisibilityConfig\u0026#34;: { \u0026#34;CloudWatchMetricsEnabled\u0026#34;: true, \u0026#34;MetricName\u0026#34;: \u0026#34;CreatedByCloudFront-cf37def6\u0026#34;, \u0026#34;SampledRequestsEnabled\u0026#34;: true } CloudWatch Metrics Enabled Metrics automatically sent to CloudWatch:\nTotal requests Allowed requests Blocked requests Counted requests (if any rules use Count action) Per-rule metrics Access metrics:\nCloudWatch console ‚Üí Metrics ‚Üí WAF Namespace: AWS/WAFV2 Dimensions: WebACL, Rule, Region Sampled Requests Enabled What it captures:\nUp to 100 recent requests per rule Includes both allowed and blocked requests Request details: IP, URI, headers, action taken View sampled requests:\nWAF Console ‚Üí Your Web ACL Scroll to \u0026ldquo;Sampled requests\u0026rdquo; section Click on any request to see full details Use cases:\nTroubleshooting false positives Understanding attack patterns Verifying rule effectiveness "},{"uri":"https://thienluhoan.github.io/workshop-template/4-eventparticipated/","title":"Events Participated","tags":[],"description":"","content":" ‚ö†Ô∏è Note: The information below is for reference purposes only. Please do not copy it verbatim for your report, including this warning.\nIn this section, you should list and describe in detail the events you have participated in during your internship or work experience.\nEach event should be presented in the format Event 1, Event 2, Event 3‚Ä¶, along with the following details:\nEvent name Date and time Location (if applicable) Your role in the event (attendee, event support, speaker, etc.) A brief description of the event‚Äôs content and main activities Outcomes or value gained (lessons learned, new skills, contribution to the team/project) This listing helps demonstrate your actual participation as well as the soft skills and experience you have gained from each event. During my internship, I participated in two events. Each one was a memorable experience that provided new, interesting, and useful knowledge, along with gifts and wonderful moments.\nEvent 1 Event Name: GenAI-powered App-DB Modernization workshop\nDate \u0026amp; Time: 09:00, August 13, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\nEvent 2 Event Name: GenAI-powered App-DB Modernization workshop\nDate \u0026amp; Time: 09:00, August 13, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\n"},{"uri":"https://thienluhoan.github.io/workshop-template/5-workshop/5.2-serverless-backend/5.2.5-lambda/","title":"Lambda Functions Development","tags":[],"description":"","content":"Overview In this section, you\u0026rsquo;ll create AWS Lambda functions that serve as the business logic layer of your serverless backend. These functions will handle API requests, retrieve database credentials from Secrets Manager, interact with your RDS database, and return responses to API Gateway.\nWhat you\u0026rsquo;ll accomplish:\nUnderstand Lambda function architecture and execution Develop Lambda functions for CRUD operations Connect Lambda to RDS PostgreSQL database Retrieve credentials securely from Secrets Manager Configure VPC settings for database access Package and deploy Lambda functions with dependencies Test Lambda functions directly Set up CloudWatch Logs for debugging Initialize database schema via Lambda Estimated time: 60-75 minutes\nLambda Function Architecture What We\u0026rsquo;ll Build API Gateway ‚Üì Lambda Functions (in VPC) ‚îú‚îÄ‚îÄ initDB - Initialize database schema ‚îú‚îÄ‚îÄ createUser - Create new user ‚îú‚îÄ‚îÄ getUsers - List all users ‚îú‚îÄ‚îÄ createTask - Create new task ‚îú‚îÄ‚îÄ getTasks - Get user\u0026#39;s tasks ‚îú‚îÄ‚îÄ updateTask - Update task ‚îî‚îÄ‚îÄ deleteTask - Delete task ‚Üì VPC Endpoint (Secrets Manager) ‚Üì Secrets Manager (get DB credentials) ‚Üì RDS PostgreSQL (execute queries) Costs Considerations Free-tier: 1 million free requests per month 400,000 GB-seconds of compute time per month Applies to both x86 and Graviton2 Lambda functions 100 GiB of HTTP response streaming per month The first 6 MB per request is always free Paid-tier Even paid tier cost is minimal for our workshop Overall: \u0026lt;$1 (clean up immediately after finish workshop) Step 1: Prepare Lambda Development Environment (optional) In this step, you\u0026rsquo;ll set up a local development environment for building and packaging your Lambda function. However, this step is optional. If you prefer not to set up the environment manually, you can skip this step and download source code below. You can download source code for this part here:\nGithub repository: https://github.com/Icyretsz/fcj-workshop-serverless-backend-ver1 Only the zip file for lambda: https://fcj-workshop-files.s3.ap-southeast-1.amazonaws.com/userHandler.zip 1.1 View Project Directory The source code is provided in the above git repository\nThe project structure:\nfcj-workshop-serverless-backend-ver1 ‚îî‚îÄ‚îÄ backend/ ‚îî‚îÄ‚îÄ src/ ‚îî‚îÄ‚îÄ userHandler.ts ‚îî‚îÄ‚îÄ types.ts ‚îú‚îÄ‚îÄ package.json ‚îú‚îÄ‚îÄ tsconfig.json You can choose to organize your Lambda functions in different ways. In production, it is recommended to create separate Lambda functions for each user operation (CREATE, READ, UPDATE, DELETE) to improve maintainability, scalability, and security.\nHowever, for the sake of simplicity in this workshop, we will place all user-related operations into a single Lambda function (userHandler.js).\nThe userHandler.ts Key features of this handler:\nDB Initialization: creates users table and insert mock data automatically if it doesn‚Äôt exist. TypeScript types: uses your User interface and ApiResponse. Secrets Manager: retrieves database credentials at runtime. No connection pool: safe for workshops, simple enough. This Lambda function handles CRUD operations for users in a PostgreSQL database. It\u0026rsquo;s designed to work with API Gateway Lambda Proxy Integration, which provides a specific event structure and expects a specific response format. Supported operations:\nGET /users - Get all users GET /users/{id} - Get single user POST /users - Create new user PUT /users/{id} - Update user DELETE /users/{id} - Delete user You can modify it as you like. When you are ready, move on to next steps to build and deploy our source code to Lambda\nStep 2: Build Lambda Deployment Package 2.1 Install dependencies From root folder, run\nnpm install 2.1 Build TypeScript Code Build\nnpm run build This creates dist folder in root directory\nNow find node_modules folder then copy it to dist folder\nWhen complete, select all files in dist folder, compress them to zip and name it userHandler\nConfirm contents of userHandler.zip\nStep 3: Deploy Lambda Functions Now we\u0026rsquo;ll create Lambda functions in AWS\n3.1 Navigate to Lambda console Navigate to Lambda console Click Create function 3.2 Create Lambda function Function options: Select Author from scratch Basic information: Function name: workshop-lambda-sm-rds Runtime: Nodejs 24.x Architecture: x86_64 Expand Change default execution role Select Use an existing role Select workshop-lamda-secretsmng-role Advanced settings: Expand Advanced settings Check Enable VPC VPC:\nSelect workshop-backend-vpc Subnets:\nSelect workshop-private-subnet-1 (10.0.1.0/24) Security groups:\nSelect workshop-lambda-sg Click Create function Wait a few minutes for the system to create the Lambda function Create successful 3.3 Upload Deployment Package In the function page, in Code tab Click Upload from dropdown Select .zip file Click Upload Select /fcj-serverless-workshop/backend/userHandler.zip Click Save Lambda will start importing our source code (userHandler.zip) The result: you will see the source code files in the left sidebar 3.4 Configure environment variables Go to the Configuration tab On the left sidebar, click Environment variables Click Edit On the next screen, click Add environment variable Add the following variables: RDS-HOST: your RDS endpoint DB_NAME: your RDS database name SECRET_NAME: the secret name of the RDS-managed secret (refer to 5.2.4) REGION: your current AWS region Go back to Code tab, click Deploy 3.5 Test Lambda function Now let\u0026rsquo;s test the Lambda function. We will test the get all users route\nIn the Code tab of your Lambda function, click the Test button or Create new test event on the left sidebar A drawer on the right will appear Configure the test event: Event name: test-get-users Event JSON: { \u0026#34;httpMethod\u0026#34;: \u0026#34;GET\u0026#34;, \u0026#34;pathParameters\u0026#34;: null, \u0026#34;body\u0026#34;: null } Click Save You will see your new test event in the left sidebar, hover on it and then click the play button to start the test If everything goes well, you will see the response with status 200 and a body contains our users Step 4: Monitor Lambda with CloudWatch Logs 4.1 View CloudWatch Logs In Lambda console, click Monitor tab Click View CloudWatch logs Click on the latest Log stream 4.2 Analyze Log Entries You should see detailed logs for each invocation:\n2024-11-29T10:00:00.000Z INFO [users-handler] process start. 2024-11-29T10:00:00.100Z INFO Failed to get secret: Error: Could not retrieve secret 2024-11-29T10:00:00.150Z INFO Connected to RDS PostgreSQL successfully. 2024-11-29T10:00:00.200Z INFO Inserting demo users... 2024-11-29T10:00:00.250Z INFO Demo users inserted. 2024-11-29T10:00:00.300Z INFO [users-handler] process end. Key things to observe:\nSuccessful database connection Table initialization Demo data insertion (first run only) Request method and path Query execution and results 4.3 Understanding Log Output Successful Create User:\nSTART RequestId: abc-123-def [INFO] [users-handler] process start. [INFO] Connected to RDS PostgreSQL successfully. [INFO] Demo users inserted. END RequestId: abc-123-def REPORT RequestId: abc-123-def Duration: 1250.34 ms Billed Duration: 1251 ms Memory Size: 512 MB Max Memory Used: 128 MB Init Duration: 2345.67 ms What each metric means:\nDuration: Actual execution time (1250.34 ms) Billed Duration: Rounded up time you\u0026rsquo;re charged for (1251 ms) Memory Size: Allocated memory (512 MB) Max Memory Used: Peak memory usage (128 MB) Init Duration: Cold start initialization time (2345.67 ms, first invocation only) Error Example:\nSTART RequestId: xyz-789-abc [INFO] [users-handler] process start. [ERROR] Failed to get secret: ResourceNotFoundException: Secret not found [ERROR] RDS connection failed: Error: Connection timeout [INFO] [users-handler] process end. END RequestId: xyz-789-abc REPORT RequestId: xyz-789-abc Duration: 5000.12 ms Billed Duration: 5001 ms Memory Size: 512 MB Max Memory Used: 95 MB 4.4 Filter Logs by Pattern CloudWatch Logs Insights allows you to query logs with SQL-like syntax.\nIn CloudWatch Logs, click Logs Insights in left navigation Select your log group: /aws/lambda/workshop-lambda-sm-rds Enter a query Click Run query Example queries:\nFind all errors:\nfields @timestamp, @message | filter @message like /ERROR/ | sort @timestamp desc | limit 20 Find slow requests (\u0026gt; 2 seconds):\nfields @timestamp, @duration | filter @type = \u0026#34;REPORT\u0026#34; | filter @duration \u0026gt; 2000 | sort @duration desc | limit 20 Count requests by HTTP method:\nfields @timestamp, @message | filter @message like /httpMethod/ | parse @message \u0026#39;\u0026#34;httpMethod\u0026#34;:\u0026#34;*\u0026#34;\u0026#39; as method | stats count() by method Find database connection errors:\nfields @timestamp, @message | filter @message like /RDS connection failed/ | sort @timestamp desc | limit 20 Get average execution time:\nfields @timestamp, @duration | filter @type = \u0026#34;REPORT\u0026#34; | stats avg(@duration) as avg_duration, max(@duration) as max_duration, min(@duration) as min_duration Summary Congratulations! You\u0026rsquo;ve successfully:\nCloned and explored the TypeScript Lambda project Built and packaged the Lambda deployment Deployed Lambda function to AWS Configured VPC, security groups, and environment variables Tested CRUD operations Set up CloudWatch monitoring and logging What You\u0026rsquo;ve Built Your Lambda function now provides:\nComplete CRUD API for user management Database connectivity with automatic initialization Secure credentials via Secrets Manager VPC isolation for security Comprehensive logging for debugging Performance monitoring via CloudWatch Type-safe code with TypeScript Architecture So Far Client Request ‚Üì API Gateway (to be created in Part 5) ‚Üì Lambda Function (workshop-userHandler) ‚îú‚Üí VPC Endpoint ‚Üí Secrets Manager ‚Üí Get DB Credentials ‚îî‚Üí VPC Private Subnet ‚Üí RDS PostgreSQL ‚Üí Execute Queries ‚Üì CloudWatch Logs (monitoring \u0026amp; debugging) Next Steps Proceed to Part 5: API Gateway Setup to create REST API endpoints that will trigger your Lambda function and expose it to the internet.\nReady to continue? Your Lambda function is now fully functional and ready to be exposed via API Gateway! üöÄ\n"},{"uri":"https://thienluhoan.github.io/workshop-template/5-workshop/5.1-frontend-deployment/5.1.5-clean-up/","title":"Part 4: Clean up","tags":[],"description":"","content":"Overview This section covers how to properly clean up the resources you created during frontend deployment. Cleaning up is important to avoid ongoing AWS charges, especially for resources that have monthly costs like WAF Web ACLs.\nWhat you\u0026rsquo;ll learn:\nHow to safely delete resources in the correct order Understanding resource dependencies Cost implications of keeping vs. deleting resources How to preserve configuration for future use Partial cleanup options Estimated time: 15-20 minutes\nShould You Clean Up? Keep Resources If: ‚úÖ You\u0026rsquo;re proceeding immediately to Part 2: Serverless Backend ‚úÖ You want to maintain the working frontend for reference ‚úÖ You\u0026rsquo;re using this for a real project ‚úÖ Costs are acceptable for your use case Clean Up If: ‚úÖ You\u0026rsquo;ve completed the workshop and don\u0026rsquo;t need the resources ‚úÖ You want to minimize AWS costs ‚úÖ You\u0026rsquo;re practicing and will recreate later ‚úÖ You\u0026rsquo;re approaching Free Tier limits Complete Cleanup (Step-by-Step) Follow this order to avoid dependency errors:\nStep 1: Disable and Delete CloudFront Distribution CloudFront distributions must be disabled before deletion.\n1.1 Disable Distribution Go to CloudFront console Select your distribution (check the box) Click Disable Confirm by clicking Disable in the modal Status changes:\nDeploying: Distribution is being disabled Deployed: Disabled successfully Wait time: 5-15 minutes\n1.2 Wait for \u0026ldquo;Deployed\u0026rdquo; Status Stay on the CloudFront distributions page Refresh periodically (every 2-3 minutes) Wait until Status column shows Deployed Last modified field shows a date 2.3 Delete Distribution Select your disabled distribution (check the box) Click Delete Confirm by clicking Delete in the modal Expected result: Distribution is removed from list\nNote: If you upgraded your distribution to Pro, you must wait until the next billing cycle to delete it.\nStep 3: Delete SSL/TLS Certificate (Optional) Only if you created a custom SSL certificate in ACM for custom domains.\n3.1 Check Certificate Usage Before deleting, verify the certificate isn\u0026rsquo;t used elsewhere:\nGo to Certificate Manager console Ensure you\u0026rsquo;re in us-east-1 region Find your certificate Check the In use? column If \u0026ldquo;Yes\u0026rdquo;: Don\u0026rsquo;t delete (still associated with resources) If \u0026ldquo;No\u0026rdquo;: Safe to delete\n3.2 Delete Certificate Select your certificate (check the box) Click Delete Confirm by clicking Delete in the modal Expected result: Certificate is removed from list\nFree Service: ACM certificates are free, so deleting them doesn\u0026rsquo;t save costs. You might want to keep the certificate if:\nYou\u0026rsquo;ll recreate the distribution later\nYou use the same domain for other AWS services\nValidation took a long time (you\u0026rsquo;d have to repeat it)\nStep 4: Delete S3 Bucket S3 buckets must be empty before deletion.\n4.1 Empty the Bucket Go to S3 console Click on your bucket name: workshop-frontend-[your-name]-[random] If there are files, click Empty Type permanently delete to confirm Click Empty 4.2 Delete the Bucket Go back to the S3 buckets list Select your bucket (check the box) Click Delete Type your bucket name to confirm Click Delete bucket Step 5: Delete CloudWatch Alarms Only if you created CloudWatch alarms in the optional section.\nGo to CloudWatch console Click Alarms in left navigation Select alarm(s): WAF-High-Blocked-Requests Click Actions ‚Üí Delete Confirm deletion Step 6: Delete CloudWatch log group Click Logs -\u0026gt; Log groups Select log groups you created in Part 3 aws-waf-logs-workshop1 and select delete Step 7: Delete SNS Topics Go to SNS console Click Topics in left navigation Select topic: Default_CloudWatch_Alarms_Topic Click Delete Type delete me to confirm Click Delete Summary Cleanup Completion Checklist If performing complete cleanup:\nCloudFront distribution disabled and deleted SSL certificate deleted (if created) S3 bucket(s) emptied and deleted CloudWatch alarms deleted SNS topics deleted Verified no remaining charges in Billing Dashboard What\u0026rsquo;s Next? If continuing to Part 2: Serverless backend:\nKeep existing resources OR Proceed with backend deployment Backend will integrate with this frontend infrastructure If finished with workshop:\nAll resources cleaned up No ongoing charges Knowledge and skills gained! üéâ Congratulations! You\u0026rsquo;ve successfully completed Part 1: Frontend Deployment, including proper resource cleanup. You now understand how to deploy, secure, and manage a serverless frontend on AWS! üéâ\n"},{"uri":"https://thienluhoan.github.io/workshop-template/5-workshop/","title":"Workshop","tags":[],"description":"","content":"Building and Deploying Fullstack Serverless Applications on AWS Workshop Overview Welcome to this comprehensive hands-on workshop on building and deploying production-ready fullstack serverless applications on AWS. Over the course of three parts, you\u0026rsquo;ll learn how to architect, secure, and automate the deployment of a modern web application using AWS\u0026rsquo;s serverless services.\nWhat You\u0026rsquo;ll Build By the end of this series, you\u0026rsquo;ll have built a complete serverless application featuring:\nSecure Frontend: A globally distributed, high-performance static website protected by AWS WAF Scalable Backend: RESTful APIs powered by Lambda functions with secure database access User Authentication: Complete user management with sign-up, login, and authorization Automated Deployment: A full CI/CD pipeline that automatically builds and deploys your application Workshop Structure Part 1: Frontend Deployment with CloudFront, WAF, and S3 Learn to deploy and secure a static frontend application using AWS\u0026rsquo;s content delivery network. You\u0026rsquo;ll configure CloudFront for global distribution, implement S3 for reliable storage, and protect your application with AWS WAF rules.\nKey Topics:\nS3 bucket configuration for static website hosting CloudFront distribution setup and optimization AWS WAF rule configuration for security Custom domain and SSL certificate management Part 2: Backend Deployment with API Gateway, Lambda, and RDS Build a secure, scalable backend infrastructure. You\u0026rsquo;ll create RESTful APIs, implement serverless functions, set up a managed database, and integrate user authentication.\nKey Topics:\nAPI Gateway REST API design and deployment Lambda function development and configuration RDS database setup and connection management AWS Secrets Manager for credential security Amazon Cognito for authentication and authorization Securing APIs with Cognito authorizers Prerequisites Required Knowledge:\nBasic understanding of web application architecture Familiarity with JavaScript/Node.js or Python Basic command line/terminal usage Understanding of HTTP and REST APIs Required Tools:\nAWS Account with administrative access AWS CLI installed and configured Text editor or IDE (VS Code recommended) Git installed locally Recommended:\nBasic understanding of SQL Familiarity with JSON Experience with version control (Git) Architecture Overview Learning Outcomes By completing this workshop series, you will be able to:\nDesign and implement serverless architectures on AWS Secure web applications using industry best practices Implement user authentication and authorization flows Manage application secrets and database credentials securely Build and maintain automated deployment pipelines Optimize applications for performance and cost Troubleshoot common serverless deployment issues Cost Considerations This workshop uses AWS services that may incur costs. We\u0026rsquo;ll use AWS Free Tier eligible services where possible, but you should:\nMonitor your AWS billing dashboard regularly Delete resources after completing each workshop if not continuing immediately Set up billing alerts to avoid unexpected charges Estimated cost for completing all workshops: $5-$15 (assuming no existing Free Tier usage)\nGetting Help Throughout the workshops, you\u0026rsquo;ll find:\nStep-by-step instructions with screenshots Code samples and configuration templates Common troubleshooting tips Links to AWS documentation for deeper dives Ready to Start? Let\u0026rsquo;s begin with Part 1: Frontend Deployment and build the foundation of your serverless application!\nContent Part 1: Frontend Deployment: Frontend Deployment with CloudFront, WAF, and S3 Part 2: Serverless Backend: Backend Deployment with API Gateway, Lambda, RDS, and Cognito "},{"uri":"https://thienluhoan.github.io/workshop-template/5-workshop/5.2-serverless-backend/5.2.6-api-gateway/","title":"API Gateway Setup","tags":[],"description":"","content":"Overview In this section, you\u0026rsquo;ll create an Amazon API Gateway REST API that serves as the entry point for your serverless backend. API Gateway will receive HTTP requests from clients, route them to your Lambda function, and return responses.\nWhat you\u0026rsquo;ll accomplish:\nUnderstand API Gateway concepts and integration types Create a REST API in API Gateway Define resources and methods for user operations Configure Lambda proxy integration Enable CORS for frontend integration Deploy API to a stage Test API endpoints with various tools Monitor API usage and performance Understand API Gateway pricing Estimated time: 40-50 minutes\nAPI Gateway Architecture What We\u0026rsquo;ll Build Client (Browser/Mobile/Postman) ‚Üì HTTPS Request ‚Üì API Gateway REST API ‚îú‚îÄ‚îÄ POST /users ‚Üí Lambda (Create User) ‚îú‚îÄ‚îÄ GET /users ‚Üí Lambda (Get All Users) ‚îú‚îÄ‚îÄ GET /users/{id} ‚Üí Lambda (Get Single User) ‚îú‚îÄ‚îÄ PUT /users/{id} ‚Üí Lambda (Update User) ‚îî‚îÄ‚îÄ DELETE /users/{id} ‚Üí Lambda (Delete User) ‚Üì Lambda Function (workshop-userHandler) ‚Üì RDS PostgreSQL Costs Considerations Free-tier: 1M REST API CALLS RECEIVED | 1M HTTP API CALLS RECEIVED | 1M MESSAGES | 750,000 CONNECTION MINUTES per month\nPaid-tier REST API\nAPI Calls (per month) Price (per million) First 333 million $4.25 Next 667 million $3.53 Next 19 billion $3.00 Over 20 billion $1.91 Caching: 0.5GB -\u0026gt; $0.028/hour\nAdditional costs: CloudWatch logs (free-tier eligible)\nOverall: \u0026lt;$5 (clean up immediately after finish workshop)\nAPI Gateway Concepts REST API:\nResource-based API (e.g., /users, /users/{id}) Supports all HTTP methods (GET, POST, PUT, DELETE, etc.) Request/response transformation Built-in throttling and caching Resources:\nURL paths (e.g., /users) Can be nested (e.g., /users/{id}/tasks) Methods:\nHTTP operations on resources (GET, POST, PUT, DELETE) Each method can have different integration Integration Types:\nLambda Proxy: Passes entire request to Lambda (recommended) Lambda: Custom request/response mapping HTTP: Proxy to HTTP endpoint Mock: Returns static response AWS Service: Direct AWS service integration Stages:\nDeployment environments (e.g., dev, staging, prod) Each stage has unique URL Can have different settings per stage Step 1: Create REST API 1.1 Navigate to API Gateway Console Go to AWS Console Search for \u0026ldquo;API Gateway\u0026rdquo; Click API Gateway under Services 1.2 Create API Click Create an API You\u0026rsquo;ll see several API types:\nHTTP API: Simpler, cheaper, faster (70% cost reduction) REST API: Full features, request/response transformation WebSocket API: Real-time bidirectional communication REST API (Private): VPC-only access Under REST API, click Build 1.3 Configure API Settings Choose the protocol: Keep REST selected Create new API: Select New API API details:\nAPI name: workshop-user-api\nDescription: REST API for user management in serverless workshop\nEndpoint Type:\nSelect Regional Deployed in current region Lower latency for users in same region Can add CloudFront later for global distribution Endpoint Types:\nRegional: Deployed in a single region, recommended for most use cases\nEdge Optimized: Automatically distributed via CloudFront (adds latency for regional traffic)\nPrivate: Only accessible within VPC\nFor this workshop, Regional is best. You already have CloudFront from Part 1: Frontend Deployment if you want global distribution.\nSecurity policy Select SecurityPolicy_TLS13_1_2_2021_06 This option protects data in transit between a client and server with TLS 1.3 Click Create API You\u0026rsquo;ll be taken to the API Gateway console showing your new API.\nStep 2: Create Resources and Methods 2.1 Create /users Resource A resource represents a REST API endpoint path.\nIn the API Gateway console, select Resources in left navigation (if not already selected) Click Create Resource Proxy resource:\nEssentially a catch-all resource A proxy resource (often created as {proxy+}) is a special type of resource in API Gateway that forwards all requests to a single backend (such as a Lambda function) ‚Äî regardless of the URL path or HTTP method. We won\u0026rsquo;t be using this for our workshop since our API is simple Resource Path: /\nResource Name: users\nThis becomes the URL path CORS:\nCheck this box Automatically adds OPTIONS method with CORS headers Enable CORS on all child methods Required for browser-based frontends Click Create Resource You\u0026rsquo;ll see /users appear in the resource tree.\n2.2 Create /users/{id} Resource Create a child resource with path parameter for single user operations.\nSelect /users resource (click on it) Click Create method New Child Resource:\nResource Path: user\nSingular, represents a single user Resource Name: {id}\nCurly braces indicate a path parameter CORS:\nCheck this box Click Create Resource Your resource tree now shows:\n2.3 Create POST Method on /users Methods define HTTP operations on resources.\nClick on /users resource Click Create Method Select POST Setup - POST:\nIntegration type:\nSelect Lambda Function Use Lambda Proxy integration:\nCheck this box Passes entire request to Lambda as-is Lambda returns API Gateway-formatted response Lambda Region:\nSelect your region (e.g., ap-southeast-1) Lambda Function:\nType: workshop-lambda-sm-rds Should auto-complete Permission prompt: You\u0026rsquo;ll see a popup: \u0026ldquo;Add Permission to Lambda Function\u0026rdquo;\nThis grants API Gateway permission to invoke your Lambda function.\nClick Create method 2.4 Create GET Method on /users Get all users.\nClick on /users resource Click Create Method Method: GET Setup - GET:\nIntegration type: Lambda Function Use Lambda Proxy integration: Checked Lambda Function: workshop-lambda-sm-rds Click Create method 2.5 Create GET Method on /users/{id} Get single user.\nClick on /users/{id} resource Click Create Method Method: GET Setup - GET:\nIntegration type: Lambda Function Use Lambda Proxy integration: Checked Lambda Function: workshop-lambda-sm-rds Click Create method 2.6 Create PUT Method on /users/{id} Update user.\nClick on /users/{id} resource Click Create Method Method: PUT Setup - PUT:\nIntegration type: Lambda Function Use Lambda Proxy integration: Checked Lambda Function: workshop-lambda-sm-rds Click Create method 2.7 Create DELETE Method on /users/{id} Delete user.\nClick on /users/{id} resource Click Create Method Method: DELETE Setup - DELETE:\nIntegration type: Lambda Function Use Lambda Proxy integration: Checked Lambda Function: workshop-lambda-sm-rds Click Create method 2.8 Verify Resource Structure Your API structure should now look like:\n2.9 Enable CORS on each resources Click /users resource Click Enable CORS Select the methods: GET, POST Access-Control-Allow-Origin: input your CloudFront endpoint to restrict origin, or * for debug Click Save Do the same for /{id} resource (methods: GET, PUT, DELETE) After enabling CORS for those two resources, you will see OPTION method in each resource Click on OPTION method, go to Integration response to see the details Step 3: Deploy API APIs must be deployed to a stage before they\u0026rsquo;re accessible.\n3.1 Create Deployment Click Deploy API Deployment stage:\nSelect [New Stage] Stage name: dev\nShort for development Other common names: prod, staging, test Stage description: Development stage for workshop\nDeployment description: Initial deployment\nClick Deploy 3.2 Get API Endpoint After deployment, you\u0026rsquo;ll see the Stage Editor.\nInvoke URL is your API\u0026rsquo;s base URL:\nhttps://abc123xyz.execute-api.[region].amazonaws.com/dev Step 5: Test API Endpoints 5.1 Test with API Gateway Console API Gateway provides a built-in testing tool.\nTest POST /users (Create User):\nIn the left navigation, click Resources Click on /users ‚Üí POST method Go to *Test tab Request Body:\n{ \u0026#34;cognitoSub\u0026#34;: \u0026#34;test-sub-123\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;Test User\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;test@example.com\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;phoneNumber\u0026#34;: \u0026#34;1234567890\u0026#34; } Click Test Expected Response:\nStatus: 201\nResponse Body:\n{ \u0026#34;success\u0026#34;: true, \u0026#34;data\u0026#34;: { \u0026#34;id\u0026#34;: 3, \u0026#34;cognito_sub\u0026#34;: \u0026#34;test-sub-123\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;Test User\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;test@example.com\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;phone_number\u0026#34;: \u0026#34;1234567890\u0026#34; } } Response Headers:\nContent-Type: application/json Logs: Shows Lambda execution logs inline\nTest GET /users (Get All Users):\nClick on /users ‚Üí GET method Click Test No request body needed Click Test Expected Response:\nStatus: 200\nResponse Body:\n{ \u0026#34;success\u0026#34;: true, \u0026#34;data\u0026#34;: [ { \u0026#34;id\u0026#34;: 1, \u0026#34;cognito_sub\u0026#34;: \u0026#34;demo-sub-1\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;Alice\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;alice@example.com\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;admin\u0026#34;, \u0026#34;phone_number\u0026#34;: \u0026#34;1234567890\u0026#34; }, { \u0026#34;id\u0026#34;: 2, \u0026#34;cognito_sub\u0026#34;: \u0026#34;demo-sub-2\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;Bob\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;bob@example.com\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;phone_number\u0026#34;: \u0026#34;0987654321\u0026#34; }, { \u0026#34;id\u0026#34;: 3, \u0026#34;cognito_sub\u0026#34;: \u0026#34;test-sub-123\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;Test User\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;test@example.com\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;phone_number\u0026#34;: \u0026#34;1234567890\u0026#34; } ] } Test GET /users/{id} (Get Single User):\nClick on /users/{id} ‚Üí GET method Click Test Path Parameters:\nid: 1 Click Test Expected Response:\nStatus: 200\nResponse Body:\n{ \u0026#34;success\u0026#34;: true, \u0026#34;data\u0026#34;: { \u0026#34;id\u0026#34;: 1, \u0026#34;cognito_sub\u0026#34;: \u0026#34;demo-sub-1\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;Alice\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;alice@example.com\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;admin\u0026#34;, \u0026#34;phone_number\u0026#34;: \u0026#34;1234567890\u0026#34; } } 5.2 Test with curl (Command Line) Test your deployed API from terminal:\nSet your API URL:\nAPI_URL=\u0026#34;https://YOUR-API-ID.execute-api.[region].amazonaws.com/dev\u0026#34; Create User:\ncurl -X POST \u0026#34;${API_URL}/users\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;cognitoSub\u0026#34;: \u0026#34;curl-test-456\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;Curl User\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;curl@example.com\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;phoneNumber\u0026#34;: \u0026#34;5551234567\u0026#34; }\u0026#39; Get All Users:\ncurl -X GET \u0026#34;${API_URL}/users\u0026#34; Get Single User:\ncurl -X GET \u0026#34;${API_URL}/users/1\u0026#34; Update User:\ncurl -X PUT \u0026#34;${API_URL}/users/1\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;username\u0026#34;: \u0026#34;Updated Name\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;updated@example.com\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;admin\u0026#34;, \u0026#34;phoneNumber\u0026#34;: \u0026#34;9998887777\u0026#34; }\u0026#39; Delete User:\ncurl -X DELETE \u0026#34;${API_URL}/users/3\u0026#34; 5.3 Test with Postman Postman provides a user-friendly interface for API testing.\nImport API to Postman:\nIn API Gateway console, go to Stages ‚Üí dev Click Stage action ‚Üí Export In the Export API modal, leave all settings as default. Click Export API Download the json file Open Postman, click Import On the opened modal, click files On the next modal, click Import Expand workshop-user-api, select GET /users to test get all users route Click Send View response Step 6: Configure Stage Settings 6.1 Enable CloudWatch Logging In API Gateway console, go to Stages Click dev stage Under Logs and racing card, click Edit CloudWatch Settings:\nCloudWatch Logs:\nSelect Errors and info logs This includes Request received Request body (if enabled) Integration request Integration response Execution summary Errors Data tracing:\nCheck this box (for development) Logs request/response bodies Disable in production (may contain sensitive data) Enable Detailed Metrics:\nCheck this box Provides method-level metrics Small additional cost ($0.50/month per metric) Click Save Changes Grant API Gateway Permission:\nIf this is your first API with logging, you\u0026rsquo;ll need to set up an IAM role:\nIn IAM dashboard, create role with: Trusted entity type: AWS Service Use case: API Gateway Policy: AmazonAPIGatewayPushToCloudWatchLogs Role name: api-gw-push-cloudwatch-logs Copy the Role ARN Go back to API Gateway dashboard On the left sidebar, click Settings In Logging, click Edit Paste the Role ARN to the textbox Click Save changes 6.2 Configure Throttling Protect your API from abuse with rate limiting.\nStill in dev stage settings in Stage details card, click Edit Throttling settings:\nEnabled\nRate: 1000 requests per second\nBurst capacity for temporary spikes Burst: 2000 requests\nTotal requests allowed in burst Throttling Limits:\nWhen limits are exceeded:\nClient receives 429 Too Many Requests Requests are rejected before reaching Lambda Protects backend from overload No Lambda costs for throttled requests Default AWS Account Limits:\n10,000 requests per second per region Can request increase via support ticket For this workshop, 1000 req/s is more than sufficient.\n6.3 Enable Caching (Optional) API caching reduces Lambda invocations and improves performance.\nIn dev stage, click Settings tab Scroll to Cache Settings Provision API cache:\nCheck this box Cache capacity: 0.5 GB\nSmallest size Sufficient for workshop Cache time-to-live (TTL): 300 seconds (5 minutes)\nHow long responses are cached Per-key cache invalidation:\nInvalidate certain data in cache based on a key instead of the whole cache Caching Costs:\nAPI Gateway caching is relatively expensive:\n0.5 GB cache: $0.028/hour (~$20.16/month) For this workshop: Skip caching to avoid costs. It\u0026rsquo;s included here for completeness.\nWhen to use caching:\nHigh read traffic (\u0026gt;1000 req/min) Data doesn\u0026rsquo;t change frequently Latency is critical Cost of Lambda invocations \u0026gt; cost of cache For user data that changes frequently, caching may not be appropriate.\nStep 7: Monitor API Performance 7.1 View API Gateway Metrics In API Gateway console, go to Dashboard (left navigation) Select your API: workshop-user-api Select stage: dev Metrics displayed:\nAPI calls:\nTotal number of requests over time period Broken down by hour/day Integration latency:\nTime spent in Lambda function Excludes API Gateway overhead Latency:\nTotal request time (API Gateway + Lambda) Includes network, integration, and processing time 4XX errors:\nClient errors (bad requests, not found, etc.) Should be low in well-designed APIs 5XX errors:\nServer errors (Lambda errors, timeouts, etc.) Should be monitored closely 7.2 View CloudWatch Logs Go to CloudWatch console Click Log groups Find: API-Gateway-Execution-Logs_{api-id}/dev Click on log group Click on latest log stream Sample log entry:\n(abc-123-def) Method request body before transformations: { \u0026#34;cognitoSub\u0026#34;: \u0026#34;test-123\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;Test User\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;test@example.com\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;phoneNumber\u0026#34;: \u0026#34;1234567890\u0026#34; } (abc-123-def) Endpoint request URI: https://lambda.us-east-1.amazonaws.com/2015-03-31/functions/arn:aws:lambda:us-east-1:123456789012:function:workshop-userHandler/invocations (abc-123-def) Endpoint response body before transformations: { \u0026#34;statusCode\u0026#34;: 201, \u0026#34;headers\u0026#34;: { \u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34; }, \u0026#34;body\u0026#34;: \u0026#34;{\\\u0026#34;success\\\u0026#34;:true,\\\u0026#34;data\\\u0026#34;:{\\\u0026#34;id\\\u0026#34;:1,...}}\u0026#34; } (abc-123-def) Method response body after transformations: { \u0026#34;success\u0026#34;: true, \u0026#34;data\u0026#34;: { \u0026#34;id\u0026#34;: 1, \u0026#34;cognito_sub\u0026#34;: \u0026#34;test-123\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;Test User\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;test@example.com\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;phone_number\u0026#34;: \u0026#34;1234567890\u0026#34; } } (abc-123-def) Method completed with status: 201 Summary Congratulations! You\u0026rsquo;ve successfully:\nCreated REST API in API Gateway Defined resources and methods for CRUD operations Configured Lambda proxy integration Enabled CORS for frontend compatibility Deployed API to dev stage Tested endpoints with multiple tools Configured logging and monitoring Set up throttling for protection What You\u0026rsquo;ve Built Your API Gateway now provides:\nRESTful endpoints for all user operations HTTPS security by default CORS support for frontend integration Request throttling for protection CloudWatch logging for debugging Metrics for monitoring Next Steps Proceed to Part 6: Amazon Cognito Configuration to secure API endpoints with authorization provided by AWS Cognito\nReady to continue? Your API endpoints are now fully functional and ready! üöÄ\n"},{"uri":"https://thienluhoan.github.io/workshop-template/6-self-evaluation/","title":"Self-Assessment","tags":[],"description":"","content":" ‚ö†Ô∏è Note: The information below is for reference purposes only. Please do not copy it verbatim into your report, including this warning.\nDuring my internship at [Company/Organization Name] from [start date] to [end date], I had the opportunity to learn, practice, and apply the knowledge acquired in school to a real-world working environment.\nI participated in [briefly describe the main project or task], through which I improved my skills in [list skills: programming, analysis, reporting, communication, etc.].\nIn terms of work ethic, I always strived to complete tasks well, complied with workplace regulations, and actively engaged with colleagues to improve work efficiency.\nTo objectively reflect on my internship period, I would like to evaluate myself based on the following criteria:\nNo. Criteria Description Good Fair Average 1 Professional knowledge \u0026amp; skills Understanding of the field, applying knowledge in practice, proficiency with tools, work quality ‚úÖ ‚òê ‚òê 2 Ability to learn Ability to absorb new knowledge and learn quickly ‚òê ‚úÖ ‚òê 3 Proactiveness Taking initiative, seeking out tasks without waiting for instructions ‚úÖ ‚òê ‚òê 4 Sense of responsibility Completing tasks on time and ensuring quality ‚úÖ ‚òê ‚òê 5 Discipline Adhering to schedules, rules, and work processes ‚òê ‚òê ‚úÖ 6 Progressive mindset Willingness to receive feedback and improve oneself ‚òê ‚úÖ ‚òê 7 Communication Presenting ideas and reporting work clearly ‚òê ‚úÖ ‚òê 8 Teamwork Working effectively with colleagues and participating in teams ‚úÖ ‚òê ‚òê 9 Professional conduct Respecting colleagues, partners, and the work environment ‚úÖ ‚òê ‚òê 10 Problem-solving skills Identifying problems, proposing solutions, and showing creativity ‚òê ‚úÖ ‚òê 11 Contribution to project/team Work effectiveness, innovative ideas, recognition from the team ‚úÖ ‚òê ‚òê 12 Overall General evaluation of the entire internship period ‚úÖ ‚òê ‚òê Needs Improvement Strengthen discipline and strictly comply with the rules and regulations of the company or any organization Improve problem-solving thinking Enhance communication skills in both daily interactions and professional contexts, including handling situations effectively "},{"uri":"https://thienluhoan.github.io/workshop-template/5-workshop/5.2-serverless-backend/5.2.7-cognito/","title":"Amazon Cognito Configuration","tags":[],"description":"","content":"Overview In this section, you\u0026rsquo;ll configure Amazon Cognito to handle user authentication and authorization for your serverless application. Cognito will manage user sign-up, sign-in, password recovery, and generate JWT tokens that secure your API endpoints.\nWhat you\u0026rsquo;ll accomplish:\nUnderstand Amazon Cognito concepts and architecture Create a Cognito User Pool for user management Configure user attributes and password policies Set up app client for your application Test user registration and authentication flows Integrate Cognito with API Gateway as an authorizer Secure API endpoints with JWT token validation Test authenticated API calls Estimated time: 50-60 minutes\nCognito Architecture What We\u0026rsquo;ll Build User (Browser/Mobile) ‚Üì Sign Up / Sign In ‚Üì Amazon Cognito User Pool ‚îú‚îÄ‚îÄ User Management (sign-up, sign-in, verification) ‚îú‚îÄ‚îÄ Token Generation (ID Token, Access Token, Refresh Token) ‚îî‚îÄ‚îÄ User Attributes (email, phone, custom attributes) ‚Üì JWT Token (ID Token) ‚Üì API Gateway (with Cognito Authorizer) ‚îú‚îÄ‚îÄ Validates JWT Token ‚îú‚îÄ‚îÄ Extracts user claims (sub, email, etc.) ‚îî‚îÄ‚îÄ Passes to Lambda if valid ‚Üì Lambda Function (workshop-lambda-sm-rds) ‚îú‚îÄ‚îÄ Receives user info from authorizer ‚îî‚îÄ‚îÄ Performs authorized operations ‚Üì RDS PostgreSQL Costs Considerations Free for up to 10,000 monthly active users (MAUs) Overall: $0 (assume immediate clean up after workshop) Cognito Concepts User Pool:\nDirectory of users for your application Handles authentication (sign-up, sign-in) Manages user attributes and profiles Issues JWT tokens after successful authentication App Client:\nConfiguration for how your app connects to user pool Defines authentication flows Controls token expiration times JWT Tokens:\nID Token: Contains user identity and attributes (used for API authorization) Access Token: Used to access Cognito user pool APIs Refresh Token: Used to get new ID/Access tokens without re-authentication Hosted UI:\nPre-built sign-up/sign-in pages Customizable branding Handles OAuth 2.0 flows Alternative to building custom auth UI Cognito Authorizer:\nAPI Gateway feature Validates JWT tokens automatically Denies requests with invalid/expired tokens Passes user claims to Lambda Step 1: Create Cognito User Pool 1.1 Navigate to Cognito Console Go to AWS Console Search for \u0026ldquo;Cognito\u0026rdquo; Click Amazon Cognito under Services 1.2 Create User directory Click Get started for free in less than five minutes You\u0026rsquo;ll go through a step-by-step configuration wizard.\nCognito user directory setup 1.3 Define your application Application type Since we use Cognito to authenticate users in the frontend we deployed in Part 1, choose Single-page application (SPA) Name you application Enter name: workshop-cognito-SPA Click Next 1.4 Configure options Options for sign-in identifiers The required attribute for user to log-in. Select Email Self-registration Enabled as default This option allows users to initiate sign-up by themselves. If chose Disable, only admin that has access to Cognito can create new account Required attributes for sign-up Select name and phone_number These are the additional required attributes when sign-up 1.5 Add a return URL (optional) When specified a return URL, our application will redirect user back to said URL after successful log-in. Left blank for now. We will configure this later when we integrate our front-end app Click Create user directory 1.6 View resources After you click Create user directory in the previous step, you will be redirected to another page\nOn this page, you can view:\nBuilt-in log-in and sign-up page by clicking View login page Quick setup guide This provides developers guidance on how to integrate authentication in Front-end apps We will leave this page for now and comeback later when we integrate our front-end\nClick Go to overview at the bottom of the page\n1.7 View User Pool Details After creation, you\u0026rsquo;ll see your user pool overview.\nSave these important details:\nUser pool ID:\nFormat: [region]_abcd1234 User pool ARN:\nFormat: arn:aws:cognito-idp:us-east-1:123456789012:userpool/[region]_abcd1234 Get App client ID:\nOn the left sidebar, click App clients under Applications Copy the Client ID Format: 1234567890abcdefghijklmnop In the middle, you can see Authentication flow session duration: the maximum duration when user initiate authentication Refresh token expiration: duration before refresh token expires Access token expiration: duration before access token is expired and user is required (or not, based on settings) to log-in again To edit these durations and more, click Edit in the same card in the right Edit app client information Authentication flow: authentication flows that your app will support Choice-based sign-in: ALLOW_USER_AUTH: allows multiple sign-in options for users (biometric, OPT\u0026hellip;) Sign in with secure remote password (SRP): ALLOW_USER_SRP_AUTH: sign-in with username and password Get new user tokens from existing authenticated sessions: ALLOW_REFRESH_TOKEN_AUTH: when access token expires, refresh token are used to extend and refetch new access token without the user have to initiate login again Duration and expiration times: you can also modify duration and expiration times here You can also view some notable configurations on the app client page Quick setup guilde: provides developers guidance on how to integrate Cognito to Front-end apps Attribute permissions: view and edit attribute permissions that this app client can read and write You can see that email is not writeable since we chose email as the required sign-up and sign-in attribute Login pages: customize login and logout behaviors Threat protection: Configure threat protection for adaptive authentication and compromised credentials. Analytics Step 2: Test User Registration 2.1 Access Hosted UI In Cognito console, go to your user pool On the left sidebar, click App clients under Applications Click View login page This opens the Cognito-hosted authentication page in a new tab.\n2.2 Sign Up a New User On the Hosted UI page, click Create an account\nFill in the registration form:\nEmail: Your actual email address\nYou\u0026rsquo;ll receive a verification code here Name: Your full name (alphanumeric, case-sensitive)\nPhone number: +1234567890\nFormat: +[country code][number] Example: +84 0123456789 for Vietnam Password:\nMust meet password policy: At least 8 characters Uppercase letter Lowercase letter Number Special character Confirm password\nClick Sign up 3.3 Verify Email Address Check your email inbox\nYou should receive an email from no-reply@verificationemail.com\nSubject: \u0026ldquo;Your verification code\u0026rdquo;\nBody contains: 6-digit verification code\nExample: 123456 Go back to the login page\nEnter the 6-digit code in the Confirmation code field\nClick Confirm Account\nDidn\u0026rsquo;t receive the email?\nCheck spam/junk folder Wait 2-3 minutes (can be delayed) Click \u0026ldquo;Resend code\u0026rdquo; on the verification page Verify email address is correct Check Cognito email sending quota (50/day limit) If still not working:\nGo to Cognito console ‚Üí Users Find your user (status: UNCONFIRMED) Click Actions ‚Üí Confirm account (admin override) After successful verification, you\u0026rsquo;ll be redirected to the return URL page.\nWe will setup return URL later to redirect user to our front-end homepage\n3.4 Login Close the browser page Go back to our app client page, then click View login page again You will see the folowing This is because you have previously signed-in after sign-up After a successful sign-in, Cognito will store httpOnly cookies containing access token and refresh token If those are not expired yet, you won\u0026rsquo;t have to initiate login again (input email and password) Click Sign in as [your email], you will be redirected to the return URL If you want to input email and password, simply click Sign in as a different user? Step 4: View Users in Cognito Console 4.1 View User List In Cognito console, select user pool Click Users in left navigation You should see your newly created user 4.2 View User Details Click on the username: testuser View detailed information: User attributes:\nsub: UUID (unique identifier) email: Your email email_verified: true name: Your name phone_number: +1234567890 phone_number_verified: false (we didn\u0026rsquo;t verify phone) Group memberships:\nNone (we haven\u0026rsquo;t created groups yet) Step 5: View Authentication Tokens We will view how an access token looks like via CloudShell\n5.1 Get access token via CloudShell In the bottom right corner, look for CloudShell When click on CloudShell, a drawer contain a CLI appear from bottom Create a json file on your local machine with the following content: { \u0026#34;UserPoolId\u0026#34;: \u0026#34;{your-user-pool-id}\u0026#34;, \u0026#34;ClientId\u0026#34;: \u0026#34;{your-client-id}\u0026#34;, \u0026#34;AuthFlow\u0026#34;: \u0026#34;ADMIN_NO_SRP_AUTH\u0026#34;, \u0026#34;AuthParameters\u0026#34;: { \u0026#34;USERNAME\u0026#34;: \u0026#34;admin@example.com\u0026#34;, \u0026#34;PASSWORD\u0026#34;: \u0026#34;password123\u0026#34; } } For example\nUserPoolId can be found in your user pool page ClientId can be found in your app client page username and password of your new account you just created Save the json file as auth.json Back to your CloudShell CLI, click Action on the right, click Upload file Select your auth.json file to upload Then in the CLI, run ls. You will see your auth.json file Run the following command aws cognito-idp admin-initiate-auth --region {your-aws-region} --cli-input-json file://auth.json\nIf you encounter this error An error occurred (InvalidParameterException) when calling the AdminInitiateAuth operation: Auth flow not enabled for this client\nGo to your app client page In App client information card, click Edit Under Authentication flows, check Sign in with server-side administrative credentials: ALLOW_ADMIN_USER_PASSWORD_AUTH Save changes Run the command again, you will have the following response\n{ \u0026#34;ChallengeParameters\u0026#34;: {}, \u0026#34;AuthenticationResult\u0026#34;: { \u0026#34;AccessToken\u0026#34;: \u0026#34;eyJraWQiOiJTNVwvTmlNSnorR0VQUzlVNis2dlBjRCttQ2tLZDNOdFFCcEp1NEhRbXhoUT0iLCJhbGciOiJSUzI1NiJ9.eyJzdWIiOiI4OTNhNzVmYy02MGYxLTcwOTYtNWJiYi1mNDNlMDA5ZjJiM2IiLCJpc3MiOiJodHRwczpcL1wvY29nbml0by1pZHAuYXAtc291dGhlYXN0LTEuYW1hem9uYXdzLmNvbVwvYXAtc291dGhlYXN0LTFfVHV1dGRSVExkIiwiY2xpZW50X2lkIjoiNTZtc2RjdHMwcjJ1YWhrdDZjMzBsdWxiZWgiLCJvcmlnaW5fanRpIjoiNWNmOWFiMWUtNDdjZC00MzZlLTk2OWYtZmU5ZDE3YTgxOGNhIiwiZXZlbnRfaWQiOiJkMTM5Y2Y3Zi02YmE3LTQzYzQtYjNiZS0xYWJmMmEyNjNkMzkiLCJ0b2tlbl91c2UiOiJhY2Nlc3MiLCJzY29wZSI6ImF3cy5jb2duaXRvLnNpZ25pbi51c2VyLmFkbWluIiwiYXV0aF90aW1lIjoxNzY0NDg3MDI1LCJleHAiOjE3NjQ0OTA2MjUsImlhdCI6MTc2NDQ4NzAyNSwianRpIjoiNGZhN2RkZjctZmJiYS00MjM3LWE2MzctYTkyMWE1NDZlODlmIiwidXNlcm5hbWUiOiI4OTNhNzVmYy02MGYxLTcwOTYtNWJiYi1mNDNlMDA5ZjJiM2IifQ.bUHsq_dNyxJ2GBARcP5IRY8Qi-AZbpTItD_BkH4uy7b-BYLZxNx03peI68DFmhd2mDpI_exw6DigB2I6hFGeQ2VbUlH0kKxvA0gDXqQNj4bnDnU2KCIzPbj_pIydab_tjxuU6FQi4l5tTxM6ygKciIUowqX3GLgSvyXPWprZzZtQoYgyMETT-rae4EWBhUoT1Em76YAvlXwqxHp0RJi8vwABWaB6Q34buCO1wM4SWzs5ZNfLSy28FK0xLEdGuAXwtXRnu2Myn_wmcePK_K-kiFi7aMX4wEB4Vl7zoPqUhgzI2unSLBCDNHX-svTSRy6sk9IaXZkzp_TbH4bfflFLPA\u0026#34;, \u0026#34;ExpiresIn\u0026#34;: 3600, \u0026#34;TokenType\u0026#34;: \u0026#34;Bearer\u0026#34;, \u0026#34;RefreshToken\u0026#34;: \u0026#34;eyJjdHkiOiJKV1QiLCJlbmMiOiJBMjU2R0NNIiwiYWxnIjoiUlNBLU9BRVAifQ.pHOj9o4WG_bH5rw2E2tF5Oxpx4WbVEOMZb2oVduNH6Wxsl8NE_UfAhS6IVi6rcaGZkdgC1e1DX8Z-zqSwrequpT7eIKsUeb5WDmcu4my1RVfx2vrmmKKCuyHs3fCG8eyopjAe2-9vKnVJI6T-nr_Sg9YJ54EzWie8sHO2_pdLMOkcNgxn4Hhv8f8J0PsrIyovaI62O6uomTul1lMqUQ3Q4AHTRwROZEVqCQlzEYmMnsFBUbVTzHuA0hbEy4v8hRx8jqLjNwcvOf9qqYgyusZt0wiErnMGR11p00AsOgIcJ6A_484DoH4TPu2eqAy7UIZF5g-ak66iTncSedMQermXw.uA8Bb7gC4JfnFcCx.oFSb-D6NM1q2KbP8MGDqcnDOq8OD921MSb-oyirVPIu1taU-iPizZ08IvdGSc_kV-bRSep2-vmD-jKQePXNI4aZ0S6YxTV09XwLJlRkU8DMeiH5Z1LY8_ZMf2KBNCHpfAONb3l3_xQj3hHGgIpc2W2lHX-e9YaKadDKSlU4BTs5P2BOrTq4fkVGRfjp5sC_FlcsSOULCzgM8afHQTCnONzNmMrGHn6k9famKFFDUVX7W9tTI5YwndJ9eW_vU0ZYIETIP_dF4X0DateJb108NtgLfRs5U8eerBVCUh9RnExR9tuPSzqqP0nDCD9JN1QQE_Z-zmQFngVsEvL040d19serbQ7Fjyikzmm2udX5SHgYtQlGWHaFjp3hOQKotJhlFpYR-CmC9StB2BzLl2fA2Wol5FIi0VhrnWOOmnxlgN1m7k1kLAWC7S_hieJgbCw4kSpeG7QLk_9BYllT3dNKjgzyBS7ppYYAaRk1wXtm7f52Yf8nwD0qO-9aksa6rQFRJ5xzYUfdNyZwLbJvHDcTfyxedgcUGEGtRf-wAU7bxmzmKiFtnFr4nrTNsgkfWoDoepc23PzuQqsHZ_J7AYZHzBJmrlxz5NhYG9s6c7WkeEXTogXly7-hJdDen8NFXgEZOW9Aed1W6aQNjdzd726WIVNT_r5UcgvlAQs5y43tiLnsMjKmGpwW7PuWC8VGG4w1UhWCUH_5jZjgAuI4PDeZF2a7w3-O3jDsZhs4u0yBeDxFXtx_NESDA8Uvh_j5IAip8Gm_aO_pACelyGwhKb9aWVaQtixI7GBRLIwY8RptjnRVaLKxkGMsqfvYSOZHugQIeMCADoVMkl1COHv7bHy4289JGGpIPYVOfer-TIS6NzHf3xCqxNWSn0cBuYznJTrzjpwIv6L5t302WleAH5EvF-gyEfNU7oeiZp4q4-e11kppLoP6yFg4LOA8BxPiJBsDMA0qIn3MyfFG7UQmChLxOZyMkQCEWgTQey-WMtwKqAb3En_aoCfW_-IN2b9v0pdwq86B7NTVtrxGPLbhdFmVpF42kPxYTOasFrWymN6QeDgy4DBMcqKpBf3Tz3wGeSYZfsgD8AjyhaE6N56uARAIM23i-eVaNvd-b8-SSG5IOSC0z1kg9nARQmaC89Q-F9tsFeLQfQOGgIPbc9x24VeNAaUBE9TqtKHKofLX2Ea1xsotRK8bliZn1vceLJgrH1ixueFiqVo7UPIuKOw7_v390p1Rg0Jh8CL0iA2uC9jSTfT09-M_wkVmROZPh8Ac4hNlWe-p-N5061f956fxnoGuqcQ_m0fmW0s4K45N94Gevs1nB3JrVTB-llS3fGE5vPR_hB8qTwbJx0-ev.4IY2Y2G57kBAuuYXqaNucA\u0026#34;, \u0026#34;IdToken\u0026#34;: \u0026#34;eyJraWQiOiJWdjVBZXc1bHpZQUNvdWxaNVwvN3ZPSEEwUXBycTB3Sm1peXZQaFI1bVBYbz0iLCJhbGciOiJSUzI1NiJ9.eyJzdWIiOiI4OTNhNzVmYy02MGYxLTcwOTYtNWJiYi1mNDNlMDA5ZjJiM2IiLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwiaXNzIjoiaHR0cHM6XC9cL2NvZ25pdG8taWRwLmFwLXNvdXRoZWFzdC0xLmFtYXpvbmF3cy5jb21cL2FwLXNvdXRoZWFzdC0xX1R1dXRkUlRMZCIsInBob25lX251bWJlcl92ZXJpZmllZCI6ZmFsc2UsImNvZ25pdG86dXNlcm5hbWUiOiI4OTNhNzVmYy02MGYxLTcwOTYtNWJiYi1mNDNlMDA5ZjJiM2IiLCJvcmlnaW5fanRpIjoiNWNmOWFiMWUtNDdjZC00MzZlLTk2OWYtZmU5ZDE3YTgxOGNhIiwiYXVkIjoiNTZtc2RjdHMwcjJ1YWhrdDZjMzBsdWxiZWgiLCJldmVudF9pZCI6ImQxMzljZjdmLTZiYTctNDNjNC1iM2JlLTFhYmYyYTI2M2QzOSIsInRva2VuX3VzZSI6ImlkIiwiYXV0aF90aW1lIjoxNzY0NDg3MDI1LCJuYW1lIjoiVHJhbiBNaW5oIFRoaWVuIiwicGhvbmVfbnVtYmVyIjoiKzg0MDc4MzQ3NjM0MSIsImV4cCI6MTc2NDQ5MDYyNSwiaWF0IjoxNzY0NDg3MDI1LCJqdGkiOiIyODY4NjgwNy03YTg0LTQ5MDctOTE3OC00YTNhMDZiYjM3NzAiLCJlbWFpbCI6InRoaWVuLnRtMjcyN0BnbWFpbC5jb20ifQ.rplRmMWbQFNyVXswjDecit4hbg3niMgxti0Xr6uFgjy0NBScI1t_vcd2M2N262KWnQzzki-ovYE8YKA14RUAdbz5lo9Xllqn0OHxTqWSTQnjqf4tYT7_SjWbH3_bSgarAzxT89-sK0dAMfZZYPrGfbRZeptCWWwyJxeEtffk09Pc7p8FAxszTFKro9pTnmlHYMUjADRW6ULfzdI7wNoBsRo1MNtIjXfxq9rtVPeVNQ4MvFraRzP9Fv9oZ9H_hgH1mC3XRXYyy5YyraY4bPFxBqLMrhTHRmhMrkUB8HRuOOiaYRmsf40aHp3qpsSpR0zy7WkiUE8W6FahBCgXoTSY5g\u0026#34; } } Note your AccessToken and IdToken, we will use this to authorize 5.2 Decode JWT Token (Understanding What\u0026rsquo;s Inside) To understand what information is in the token:\nGo to https://jwt.io/ Paste your AccessToken in the Encoded value box (left side) View the decoded Payload (right side): { \u0026#34;sub\u0026#34;: \u0026#34;893a75fc-60f1-7096-5bbb-f43e009f2b3b\u0026#34;, \u0026#34;iss\u0026#34;: \u0026#34;https://cognito-idp.ap-southeast-1.amazonaws.com/ap-southeast-1_TuutdRTLd\u0026#34;, \u0026#34;client_id\u0026#34;: \u0026#34;56msdcts0r2uahkt6c30lulbeh\u0026#34;, \u0026#34;origin_jti\u0026#34;: \u0026#34;5cf9ab1e-47cd-436e-969f-fe9d17a818ca\u0026#34;, \u0026#34;event_id\u0026#34;: \u0026#34;d139cf7f-6ba7-43c4-b3be-1abf2a263d39\u0026#34;, \u0026#34;token_use\u0026#34;: \u0026#34;access\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;aws.cognito.signin.user.admin\u0026#34;, \u0026#34;auth_time\u0026#34;: 1764487025, \u0026#34;exp\u0026#34;: 1764490625, \u0026#34;iat\u0026#34;: 1764487025, \u0026#34;jti\u0026#34;: \u0026#34;4fa7ddf7-fbba-4237-a637-a921a546e89f\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;893a75fc-60f1-7096-5bbb-f43e009f2b3b\u0026#34; } Paste your IdToken { \u0026#34;sub\u0026#34;: \u0026#34;893a75fc-60f1-7096-5bbb-f43e009f2b3b\u0026#34;, \u0026#34;email_verified\u0026#34;: true, \u0026#34;iss\u0026#34;: \u0026#34;https://cognito-idp.ap-southeast-1.amazonaws.com/ap-southeast-1_TuutdRTLd\u0026#34;, \u0026#34;phone_number_verified\u0026#34;: false, \u0026#34;cognito:username\u0026#34;: \u0026#34;893a75fc-60f1-7096-5bbb-f43e009f2b3b\u0026#34;, \u0026#34;origin_jti\u0026#34;: \u0026#34;5cf9ab1e-47cd-436e-969f-fe9d17a818ca\u0026#34;, \u0026#34;aud\u0026#34;: \u0026#34;56msdcts0r2uahkt6c30lulbeh\u0026#34;, \u0026#34;event_id\u0026#34;: \u0026#34;d139cf7f-6ba7-43c4-b3be-1abf2a263d39\u0026#34;, \u0026#34;token_use\u0026#34;: \u0026#34;id\u0026#34;, \u0026#34;auth_time\u0026#34;: 1764487025, \u0026#34;name\u0026#34;: \u0026#34;Tran Minh Thien\u0026#34;, \u0026#34;phone_number\u0026#34;: \u0026#34;+840783476341\u0026#34;, \u0026#34;exp\u0026#34;: 1764490625, \u0026#34;iat\u0026#34;: 1764487025, \u0026#34;jti\u0026#34;: \u0026#34;28686807-7a84-4907-9178-4a3a06bb3770\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;Your email here\u0026#34; } You can see information of your user Key claims explained:\nsub: User\u0026rsquo;s unique identifier (UUID) - use this as cognito_sub in your database email: User\u0026rsquo;s email address email_verified: Email verification status (true/false) name: User\u0026rsquo;s full name cognito:username: Username chosen during sign-up phone_number: User\u0026rsquo;s phone number exp: Expiration time (Unix timestamp) - token expires after this time iat: Issued at time (Unix timestamp) - when token was created aud: Audience (your app client ID) iss: Issuer (Cognito user pool URL) This information will be available to your Lambda function when requests are authenticated.\nStep 6: Integrate Cognito with API Gateway Now let\u0026rsquo;s secure your API by requiring valid Cognito JWT tokens.\nHow it works:\nAfter signed-in, access token will be stored as httpOnly cookies When initiate API calls, we will send this access token in the request header API Gateway will verify this access token to authorize users 6.1 Create Cognito Authorizer in API Gateway Go to API Gateway console Select your API: workshop-user-api Click Authorizers in left navigation Click Create an authorizer Create Authorizer:\nName: CognitoUserPoolAuthorizer\nType: Select Cognito\nCognito User Pool:\nClick in the field Select your region Select your user pool: workshop-user-pool Token Source: Authorization\nThis is the HTTP header where the token will be sent Format: Authorization: Bearer \u0026lt;id_token\u0026gt; Token Validation:\nLeave blank (optional regex to validate token format) Click Create authorizer 6.2 Test the Authorizer Before applying to methods, let\u0026rsquo;s test it works:\nIn the authorizer page In Token value field, paste your ID token from Step 5 The full JWT string starting with eyJ... Click Test authorizer Expected result:\nYou will see the same information as the jwt decoder from above\nSuccess! The authorizer validated your token and extracted the claims.\nThese claims will be passed to your Lambda function in event.requestContext.authorizer.claims.\nTest Failed?\nError: \u0026ldquo;Unauthorized\u0026rdquo;\nCauses:\nToken expired (tokens last 1 hour) Wrong user pool selected Token from different user pool Malformed token (check you copied the entire string) Solution:\nRun token fetching command again to get fresh token Verify user pool ID matches Ensure you copied the complete token (no spaces, no line breaks) Check token hasn\u0026rsquo;t expired (decode at jwt.io and check exp claim) 5.3 Apply Authorizer to API Methods Now secure your API endpoints with the authorizer.\nSecure GET /users:\nClick Resources in left navigation\nExpand /users resource\nClick GET method\nClick Method Request tab\nClick the Edit button in the Method request settings card\nSelect CognitoUserPoolAuthorizer from the dropdown You\u0026rsquo;ll see \u0026ldquo;Authorization: CognitoUserPoolAuthorizer\u0026rdquo; displayed. Section Purpose Authorization Require Cognito JWT Scopes Restrict access by OAuth scope Validator Validate input (body/params/headers) API Key Require x-api-key if enabled Operation Name Label for logs/metrics Query Params Validate URL parameters Headers Validate header fields Request Body Validate JSON body Repeat for all other methods:\nApply the same authorizer to:\nPOST /users (Create a user) GET /users/{id} (Get single user) PUT /users/{id} (Update user) DELETE /users/{id} (Delete user) Which Methods to Secure?\nFor this workshop: Secure ALL methods to demonstrate full authentication.\nFor production: Consider your requirements:\nAlways secure: POST, PUT, DELETE (write operations) Sometimes public: GET (read operations might be public data) Authorization logic: Even if authenticated, check if user has permission (covered later) Example:\nPublic: GET /users (list all users - public directory) Authenticated: POST /users (create user - must be logged in) Authorized: PUT /users/{id} (update user - must be owner or admin) Authorized: DELETE /users/{id} (delete user - must be owner or admin) 5.4 Deploy API with Authentication Click Deploy API . Deployment stage: dev Deployment description: Added Cognito authentication Click Deploy Your API is now secured!\nAll requests must include a valid JWT token in the Authorization header.\nStep 6: Test Authenticated API Calls 6.1 Test Without Token (Should Fail) Try calling the API in Postman without authentication:\nExpected response:\n{ \u0026#34;message\u0026#34;: \u0026#34;Unauthorized\u0026#34; } Status code: 401 Unauthorized\nPerfect! The API rejected the unauthenticated request.\n6.2 Test With Valid Token (Should Succeed) Call the API with your ID token:\nGo to Authorization tab Auth type: select Bearer Token Token: paste your IdToken Click Send again You will now see all users fetched with status 200 Step 7: Configure App Client Settings We will now edit App Client settings\n7.1 Update App Client Go back to your app client page in Amazon Cognito Go to *Login pages tab Click Edit in Managed login pages configuration card 7.2 Configure Allowed Callback URLs After successful authentication, Cognito redirects users to these URLs.\nIf you have a deployed frontend (from 5.1.3-Cloudfront-setup):\nhttps://d1234abcd.cloudfront.net/callback Callback URLs Explained:\nAfter successful authentication, Cognito redirects users to a callback URL with authentication tokens in the URL fragment.\nFormat:\nhttps://yourdomain.com/callback#id_token=eyJraWQi...\u0026amp;access_token=eyJraWQi... Examples:\nDevelopment: http://localhost:3000/callback Production: https://app.yourdomain.com/callback Cloudfront: https://d1234abcd.cloudfront.net/callback You can add multiple callback URLs for different environments.\n7.3 Configure Allowed Sign-out URLs URLs where users are redirected after sign-out.\nIf you have a deployed frontend:\nhttps://d1234abcd.cloudfront.net 7.4 Configure OAuth 2.0 Settings Identity providers:\nKeep Cognito user pool checked OAuth 2.0 grant types:\nAuthorization code grant Implicit grant (only enable this if you want the token exposed in the callback URL, not recommended) OpenID Connect scopes:\nOpenID Email Phone Click Save changes 7.5 Test the callback URL Still in your app client page, click View login page In the new tab, sign in with your created user If sign-in is successful, you will be redirected to your frontend that you setup in 5.1 Step 8: Access User Info in Lambda 8.1 Understanding Authorizer Context When API Gateway validates a token with the Cognito authorizer, it automatically passes user claims to your Lambda function.\nWhere to find claims:\nevent.requestContext.authorizer.claims Available claims:\n{ sub: \u0026#34;12345678-1234-1234-1234-123456789012\u0026#34;, email: \u0026#34;test@example.com\u0026#34;, email_verified: \u0026#34;true\u0026#34;, name: \u0026#34;Test User\u0026#34;, \u0026#34;cognito:username\u0026#34;: \u0026#34;testuser\u0026#34;, phone_number: \u0026#34;+1234567890\u0026#34;, phone_number_verified: \u0026#34;false\u0026#34;, ... } 8.2 Example: Log Authenticated User Add logging to see who\u0026rsquo;s making requests:\nexport const handler = async (event: APIGatewayEvent): Promise\u0026lt;LambdaResponse\u0026gt; =\u0026gt; { console.log(\u0026#39;Received event:\u0026#39;, JSON.stringify(event, null, 2)); // Log authenticated user const claims = event.requestContext.authorizer?.claims; if (claims) { console.log(\u0026#39;Authenticated user:\u0026#39;, { cognitoSub: claims.sub, username: claims[\u0026#39;cognito:username\u0026#39;], email: claims.email }); } else { console.log(\u0026#39;Unauthenticated request (authorizer not configured or bypassed)\u0026#39;); } // ... rest of handler logic }; 8.3 Auto-populate cognitoSub from Token Instead of requiring cognitoSub in request body, extract it from the authenticated user: Modify your lambda code\nasync function createUser(body) { const client = await connectToRds(); try { const data = JSON.parse(event.body); // Get authenticated user\u0026#39;s cognito sub from token const claims = event.requestContext.authorizer?.claims; if (!claims || !claims.sub) { return createResponse(401, { success: false, error: \u0026#39;Authentication required\u0026#39; }); } const cognitoSub = claims.sub; // From JWT token const email = claims.email; // From JWT token const username = claims[\u0026#39;cognito:username\u0026#39;]; // From JWT token const role = data.role || \u0026#39;user\u0026#39;; // Default to \u0026#39;user\u0026#39; role const phoneNumber = claims.phone_number; // From JWT token const result = await client.query(`INSERT INTO users (cognito_sub, username, email, role, phone_number) VALUES ($1, $2, $3, $4, $5) RETURNING *`, [cognitoSub, username, email, role, phoneNumber]); return respond(201, { success: true, data: result.rows[0] }); } catch (err) { return respond(400, { success: false, error: err.message }); } finally { await client.end(); } } Update handler to pass event:\nconst handler = async (event) =\u0026gt; { log(\u0026#34;[users-handler] process start.\u0026#34;); const method = event.httpMethod; const id = event.pathParameters?.id; try { switch (method) { case \u0026#34;POST\u0026#34;: return createUser(event); //update event here case \u0026#34;GET\u0026#34;: return id ? getUser(id) : getAllUsers(); case \u0026#34;PUT\u0026#34;: if (!id) return respond(400, { success: false, error: \u0026#34;Missing user ID\u0026#34; }); return updateUser(id, event.body); case \u0026#34;DELETE\u0026#34;: if (!id) return respond(400, { success: false, error: \u0026#34;Missing user ID\u0026#34; }); return deleteUser(id); default: return respond(400, { success: false, error: `Unsupported HTTP method: ${method}` }); } } catch (err) { return respond(500, { success: false, error: err.message }); } finally { log(\u0026#34;[users-handler] process end.\u0026#34;); } }; You can download fully working source code that includes the above changes here:\nGithub repository: https://github.com/Icyretsz/fcj-workshop-serverless-backend-ver2 Only the zip file for lambda: https://fcj-workshop-files.s3.ap-southeast-1.amazonaws.com/userHandler-final.zip Note that this repo is different from the repo in 5.2.5 After upload the zip to Lambda, you should find the response function and modify Access-Control-Allow-Origin from * to your CloudFront endpoint to only allow requests from your CloudFront Summary Congratulations! You\u0026rsquo;ve successfully:\nCreated Amazon Cognito User Pool Configured sign-in, sign-up, and verification settings Set up Cognito hosted UI Registered and verified test users Obtained JWT tokens from CLI Created Cognito authorizer in API Gateway Secured API endpoints with authentication Tested authenticated API calls Extracted user information from JWT tokens in Lambda Understood Cognito pricing model What You\u0026rsquo;ve Built Your application now has:\nUser Authentication: Sign-up, sign-in, email verification JWT Token Generation: Secure tokens for API access API Authorization: API Gateway validates tokens automatically User Identity: Lambda functions know who\u0026rsquo;s making requests Scalable Auth: Handles millions of users with Cognito Secure by Default: No passwords stored in your database "},{"uri":"https://thienluhoan.github.io/workshop-template/7-feedback/","title":"Sharing and Feedback","tags":[],"description":"","content":" ‚ö†Ô∏è Note: The information below is for reference purposes only. Please do not copy verbatim for your report, including this warning.\nHere, you can freely share your personal opinions about your experience participating in the First Cloud Journey program. This will help the FCJ team improve any shortcomings based on the following aspects:\nOverall Evaluation 1. Working Environment\nThe working environment is very friendly and open. FCJ members are always willing to help whenever I encounter difficulties, even outside working hours. The workspace is tidy and comfortable, helping me focus better. However, I think it would be nice to have more social gatherings or team bonding activities to strengthen relationships.\n2. Support from Mentor / Team Admin\nThe mentor provides very detailed guidance, explains clearly when I don‚Äôt understand, and always encourages me to ask questions. The admin team supports administrative tasks, provides necessary documents, and creates favorable conditions for me to work effectively. I especially appreciate that the mentor allows me to try and solve problems myself instead of just giving the answer.\n3. Relevance of Work to Academic Major\nThe tasks I was assigned align well with the knowledge I learned at university, while also introducing me to new areas I had never encountered before. This allowed me to both strengthen my foundational knowledge and gain practical skills.\n4. Learning \u0026amp; Skill Development Opportunities\nDuring the internship, I learned many new skills such as using project management tools, teamwork skills, and professional communication in a corporate environment. The mentor also shared valuable real-world experiences that helped me better plan my career path.\n5. Company Culture \u0026amp; Team Spirit\nThe company culture is very positive: everyone respects each other, works seriously but still keeps things enjoyable. When there are urgent projects, everyone works together and supports one another regardless of their position. This made me feel like a real part of the team, even as an intern.\n6. Internship Policies / Benefits\nThe company provides an internship allowance and offers flexible working hours when needed. In addition, having the opportunity to join internal training sessions is a big plus.\nAdditional Questions What did you find most satisfying during your internship? What do you think the company should improve for future interns? If recommending to a friend, would you suggest they intern here? Why or why not? Suggestions \u0026amp; Expectations Do you have any suggestions to improve the internship experience? Would you like to continue this program in the future? Any other comments (free sharing): "},{"uri":"https://thienluhoan.github.io/workshop-template/5-workshop/5.2-serverless-backend/5.2.8-frontend-integration/","title":"Frontend Integration","tags":[],"description":"","content":"Overview In this section, you\u0026rsquo;ll finally combine what we have built so far in the backend to connect to our CloudFront frontend we setup in the previous part.\nWhat you\u0026rsquo;ll accomplish:\nConfigure Lambda function to include CORS headers Configure API Gateway CORS settings Configure Cognito callback URL and login URL to your CloudFront endpoint Test the application CRUD operations Estimated time: 30 minutes\nStep 1: Configure Lambda function Since we are calling our APIs from a different origin (CloudFront) , we have to configure CORS headers properly\nGo to Lambda console, select workshop-lambda-sm-rds View the response function, this function will inlude proper CORS headers in the responses Make sure the Access-Control-Allow-Origin is set with your CloudFront endpoint function respond(statusCode, payload) { return { statusCode, headers: { \u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34;, \u0026#34;Access-Control-Allow-Headers\u0026#34;: \u0026#34;Content-Type\u0026#34;, \u0026#34;Access-Control-Allow-Origin\u0026#34;: \u0026#34;https://[cloudfront-id].cloudfront.net\u0026#34;, //add your CloudFront endpoint here \u0026#34;Access-Control-Allow-Methods\u0026#34;: \u0026#34;OPTIONS,POST,GET,DELETE\u0026#34; }, body: JSON.stringify(payload), }; } This makes sure that the APIs are only allow to be called from trusted origin (which is your CloudFront front-end) Step 2: Configure API Gateway CORS settings of resources Make sure that you have set the correct CORS settings in our /users and /{id} resouces. We have already done this in 5.2.6 - API Gateway setup Step 3: Configure Cognito callback URL and login URL to your CloudFront endpoint We already done this in 5.2.7 - Cognito Step 4: Test the application Go to your CloudFront endpoint Click Sign in You will be redirected to the hosted login UI Upon succesful login, you will be redirected to the homepage. The homepage will display your information and tokens, along with the user list fetched from RDS You can test CRUD operations This concludes our workshop "},{"uri":"https://thienluhoan.github.io/workshop-template/5-workshop/5.2-serverless-backend/5.2.9-clean-up/","title":"Clean up","tags":[],"description":"","content":"Overview This section covers how to properly clean up the resources you created during Part 2: Serverless Backend. Cleaning up is important to avoid ongoing AWS charges, especially for resources that have monthly costs like RDS.\nWhat you\u0026rsquo;ll learn:\nHow to safely delete resources in the correct order Understanding resource dependencies Cost implications of keeping vs. deleting resources How to preserve configuration for future use Partial cleanup options Estimated time: 15-20 minutes\nShould You Clean Up? Keep Resources If: You\u0026rsquo;re proceeding immediately to Part 2: Serverless Backend You want to maintain the working frontend for reference You\u0026rsquo;re using this for a real project Costs are acceptable for your use case Clean Up If: You\u0026rsquo;ve completed the workshop and don\u0026rsquo;t need the resources You want to minimize AWS costs You\u0026rsquo;re practicing and will recreate later You\u0026rsquo;re approaching Free Tier limits Complete Cleanup (Step-by-Step) Follow this order to avoid dependency errors:\nStep 1 Delete RDS instance and subnet group 1.1 Delete RDS instance Go to Aurora and RDS dashboard In the left sidebar, click Databases Click on workshop-posgresql-db On the right, click Action button, then click Delete Uncheck Create final snapshot and Retain automated backup as these two will incur charges even after you deleted your RDS instance Check I acknowledge that upon instance deletion, automated backups, including system snapshots and point-in-time recovery, will no longer be available. Type delete me when prompted click Delete 1.2 Delete subnet group Still in Aurora and RDS dashboard, in the left sidebar, click Subnet group Select workshop-db-subnet-group On the right, click Delete Click Delete in the modal Wait for the instance delete to complete, then proceed to delete subnet group in next step Step 2 Delete Lambda function Go to Lambda dashboard Select workshop-lambda-sm-rds On the right, click Action button Click Delete in the dropdown Type delete when prompted and click Delete Step 3 Delete secret in AWS Secrets Manager Go to Secrets Manager dashboard In the secrets list, click on the secret name of RDS On the right, click Action button, then click *Delete in the dropdown A modal appear, choose your Waiting period, after this period, the secret will be deleted Click Schedule deletion Step 4 Delete API Gateway resources Go to API Gateway dashboard On the left sidebar, click APIs Select workshop-user-api On the right, click Delete Type confirm when prompted Click Delete Step 5 Delete Cognito user pool Go to Cognito dashboard On the left sidebar, click User pools In the list, select User pool - id Check two checkboxes, then type in the Cognito user pool name when prompted Click Delete Step 6 Delete VPC and VPC endpoint 6.1 Delete VPC endpoint Go to VPC dashboard On the left sidebar, click Endpoints Select workshop-lambda-secretsmng-endpoint On the right, click Action button, then select Delete in the dropdown Type in delete when prompted and click Delete Wait for deletion to complete before proceed to VPC deletion 6.2 Delete VPC On the left sidebar, click Your VPCs Select workshop-backend-vpc On the right, click Action button, then click Delete VPC Step 7 Delete CloudWatch log groups Go to CloudWatch dashboard On the left sidebar, click Log groups Delete all log groups of our resources Step 8 Delete roles Go to IAM dashboard On the left sidebar, click Roles Delete these roles api-gw-push-cloudwatch-logs workshop-lamda-secretsmng-role Summary Cleanup Completion Checklist If performing complete cleanup:\nRDS: No databases or subnet groups Lambda: No workshop-lambda-sm-rds function Secrets Manager: Secret scheduled for deletion API Gateway: No workshop-user-api Cognito user pool VPC Endpoints: No workshop-secretsmng-endpoint VPC: No workshop-backend-vpc CloudWatch: No workshop log groups IAM: No workshop roles/policies "},{"uri":"https://thienluhoan.github.io/workshop-template/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://thienluhoan.github.io/workshop-template/tags/","title":"Tags","tags":[],"description":"","content":""}]